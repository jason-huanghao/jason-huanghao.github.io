<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>github 图床 + typora 自动上传</title>
    <url>/2021/05/03/Blog%20Building/github%20%E5%9B%BE%E5%BA%8A%20typora%20%E8%87%AA%E5%8A%A8%E4%B8%8A%E4%BC%A0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="配置-github-repository">配置 Github Repository</h1>
<p>创建仓库 (Repository)，注意选择为 public，设置为 private，可以上传，但是图片链接没办法访问。</p>
<p>注意如果你的Picgo中配置的分支是 “master“，你一定把新建的分支改名为 ”master”。否则，会报错： <figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">StatusCodeError</span>: <span class="number">404</span> - &#123;<span class="string">&quot;message&quot;</span>:<span class="string">&quot;Branch master not found&quot;</span>,<span class="string">&quot;documentation_url&quot;</span>:<span class="string">&quot;https://docs.github.com/rest/reference/repos#create-or-update-file-contents&quot;</span>&#125;</span><br></pre></td></tr></table></figure> <span id="more"></span></p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210508220511.png" /></p>
<h1 id="配置-picgo">配置 Picgo</h1>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210508214232.png" /> <figure class="highlight xl"><table><tr><td class="code"><pre><span class="line">说明</span><br><span class="line"><span class="number">1</span>. 设置仓库名：你的 Github 账号名/你的放图片的仓库名称</span><br><span class="line"><span class="number">2</span>. 设置分支名：这里填的是 <span class="function"><span class="title">master</span>，一定要检查你的仓库新建之后一定要更改你原有的分支名称 main -&gt;</span> master. 也可以直接用 main 分支填在这里</span><br><span class="line"><span class="number">3</span>. 设置T<span class="function"><span class="title">oken</span>：进入你的 GitHub 账号 -&gt;</span> <span class="function"><span class="title">settting</span> -&gt;</span> D<span class="function"><span class="title">eveloper</span> settings -&gt;</span> P<span class="function"><span class="title">ersonal</span> access tokens -&gt;</span> <span class="function"><span class="title">generate</span> new token -&gt;</span> Generate token 绿色按钮</span><br><span class="line"><span class="number">4</span>. 指定存储路径：在你的仓库中放图片的文件夹（会自动新建）</span><br><span class="line"><span class="number">5</span>. 设置自定义域名：一个免费的CDN服务器，用于加速你的 Github 访问速度。设置地址为：https:<span class="comment">//cdn.jsdelivr.net/gh/你的 Github 账号名/你的放图片的仓库名称</span></span><br><span class="line"></span><br></pre></td></tr></table></figure> 第 3 步中的截图 <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210508214915.png" /></p>
<h1 id="为-typora-设置-picgo-自动上传">为 typora 设置 PicGo 自动上传</h1>
<p>typora 使用 Picgo 要先设置语言为中文，才能有 Picgo 选项，否则只有 Picgo-Core (commend line) 选项。 <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210508220617.png" /></p>
<h1 id="参考-references">参考 (References)</h1>
<ol type="1">
<li>typora 官方图片上传 PicGo.app (Chinese Language Only) https://support.typora.io/Upload-Image/#option-2-config-via-cli</li>
<li>https://cloud.tencent.com/developer/article/1651601</li>
</ol>
]]></content>
      <categories>
        <category>Blog Building</category>
      </categories>
      <tags>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo博客界面样式优化</title>
    <url>/2021/05/09/Blog%20Building/hexo%E5%8D%9A%E5%AE%A2%E7%95%8C%E9%9D%A2%E6%A0%B7%E5%BC%8F%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="修改分类页面样式">修改分类页面样式</h1>
<p>在 hexo/source/_data/styles.styl 添加下面内容。(只适合黑色主题) <span id="more"></span></p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">// 分类&amp;&amp;标签 页面样式</span><br><span class="line"><span class="selector-class">.post-block</span><span class="selector-class">.page</span> &#123;</span><br><span class="line">    <span class="attribute">margin-top</span>: <span class="number">10px</span>;</span><br><span class="line">&#125;</span><br><span class="line">// 分类页面page</span><br><span class="line"><span class="selector-class">.category-all-page</span> &#123;</span><br><span class="line">    //<span class="attribute">box-shadow</span>: <span class="number">0px</span> <span class="number">0px</span> <span class="number">10px</span> <span class="number">0px</span> <span class="built_in">rgba</span>(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0.5</span>);</span><br><span class="line">    //<span class="attribute">background-color</span>: none;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">20px</span> <span class="number">30px</span> <span class="number">60px</span> <span class="number">30px</span>;</span><br><span class="line">    <span class="attribute">border-radius</span>: <span class="number">20px</span> <span class="number">20px</span> <span class="number">20px</span> <span class="number">20px</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.category-all-title</span> &#123;</span><br><span class="line">    //<span class="attribute">font-family</span>: Impact;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">24px</span>;</span><br><span class="line">    <span class="attribute">color</span>: white;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.category-list</span> &#123;</span><br><span class="line">    <span class="attribute">overflow</span>: auto;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.category-list</span> <span class="selector-tag">li</span> &#123;</span><br><span class="line">    <span class="attribute">height</span>: <span class="number">100%</span>;</span><br><span class="line">    <span class="attribute">float</span>: left;</span><br><span class="line">    <span class="attribute">border-right</span>: <span class="number">3px</span> solid <span class="number">#fcfcfc</span>;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">0</span> <span class="number">20px</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.category-all</span> <span class="selector-tag">ul</span> <span class="selector-tag">li</span> &#123;</span><br><span class="line">    <span class="attribute">list-style</span>: none<span class="meta">!important</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.category-list</span> <span class="selector-tag">li</span><span class="selector-pseudo">:last-child</span> &#123;</span><br><span class="line">    <span class="attribute">border-right</span>: none;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.category-list</span> <span class="selector-tag">li</span> <span class="selector-tag">a</span> &#123;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">16px</span>;</span><br><span class="line">    <span class="attribute">text-decoration</span>: none;</span><br><span class="line">    <span class="attribute">color</span>: $red;</span><br><span class="line">    <span class="attribute">font-family</span>: Helvetica, Verdana, sans-serif;</span><br><span class="line">    // <span class="attribute">text-transform</span>: uppercase;</span><br><span class="line">    -webkit-<span class="attribute">transition</span>: all <span class="number">0.5s</span> ease;</span><br><span class="line">    -moz-<span class="attribute">transition</span>: all <span class="number">0.5s</span> ease;</span><br><span class="line">    -o-<span class="attribute">transition</span>: all <span class="number">0.5s</span> ease;</span><br><span class="line">    -ms-<span class="attribute">transition</span>: all <span class="number">0.5s</span> ease;</span><br><span class="line">    <span class="attribute">transition</span>: all <span class="number">0.5s</span> ease;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.category-list</span> <span class="selector-tag">li</span> <span class="selector-tag">a</span><span class="selector-pseudo">:hover</span> &#123;</span><br><span class="line">    <span class="attribute">color</span>: white;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.category-list</span> <span class="selector-tag">li</span><span class="selector-class">.active</span> <span class="selector-tag">a</span> &#123;</span><br><span class="line">    <span class="attribute">font-weight</span>: bold;</span><br><span class="line">    <span class="attribute">color</span>: white;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="标签页面样式">标签页面样式</h1>
<p>在 hexo/source/_data/styles.styl 文件加入下面样式。(只使用于黑色主题)</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.tag-cloud-title</span> &#123;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">24px</span>;</span><br><span class="line">    <span class="attribute">color</span>: white;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.tag-cloud</span> <span class="selector-tag">a</span> &#123;</span><br><span class="line">    //<span class="attribute">box-shadow</span>: <span class="number">0</span> <span class="number">1px</span> <span class="number">3px</span> <span class="number">#6f42c1</span>, <span class="number">0</span> <span class="number">1px</span> <span class="number">2px</span> <span class="number">#d9534f</span>;</span><br><span class="line">    //<span class="attribute">font-size</span>: <span class="number">16px</span>;</span><br><span class="line">    <span class="attribute">color</span>: $red;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">2px</span> <span class="number">10px</span>;</span><br><span class="line">    <span class="attribute">margin</span>: <span class="number">8px</span>;</span><br><span class="line">    //<span class="attribute">background</span>: <span class="built_in">rgba</span>(<span class="number">193</span>,<span class="number">66</span>,<span class="number">92</span>,<span class="number">0</span>);</span><br><span class="line">    <span class="attribute">border-bottom</span>: none;</span><br><span class="line">    <span class="attribute">border-radius</span>: <span class="number">20px</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="阅读全文按钮样式">阅读全文按钮样式</h1>
<p>next 在需要显示摘要的地方加上 <!--more--> ，就不会显示全文，在 hexo/source/_data/styles.styl 中写入下面内容，修改默认的 Read More 按钮样式。</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">// <span class="selector-attr">[Read More]</span>按钮样式</span><br><span class="line"><span class="selector-class">.post-button</span> <span class="selector-class">.btn</span> &#123;</span><br><span class="line">    <span class="attribute">color</span>: <span class="number">#555</span> <span class="meta">!important</span>;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="built_in">rgb</span>(<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>);</span><br><span class="line">    <span class="attribute">border-radius</span>: <span class="number">3px</span>;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">15px</span>;</span><br><span class="line">    <span class="attribute">box-shadow</span>: inset <span class="number">0px</span> <span class="number">0px</span> <span class="number">10px</span> <span class="number">0px</span> <span class="built_in">rgba</span>(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0.35</span>);</span><br><span class="line">    <span class="attribute">border</span>: none <span class="meta">!important</span>;</span><br><span class="line">    <span class="attribute">transition-property</span>: unset;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">0px</span> <span class="number">15px</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.post-button</span> <span class="selector-class">.btn</span><span class="selector-pseudo">:hover</span> &#123;</span><br><span class="line">    <span class="attribute">color</span>: <span class="built_in">rgb</span>(<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>) <span class="meta">!important</span>;</span><br><span class="line">    <span class="attribute">border-radius</span>: <span class="number">3px</span>;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">15px</span>;</span><br><span class="line">    <span class="attribute">box-shadow</span>: inset <span class="number">0px</span> <span class="number">0px</span> <span class="number">10px</span> <span class="number">0px</span> <span class="built_in">rgba</span>(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0.35</span>);</span><br><span class="line">    <span class="attribute">background-image</span>: <span class="built_in">linear-gradient</span>(<span class="number">90deg</span>, <span class="number">#a166ab</span> <span class="number">0%</span>, <span class="number">#ef4e7b</span> <span class="number">25%</span>, <span class="number">#f37055</span> <span class="number">50%</span>, <span class="number">#ef4e7b</span> <span class="number">75%</span>, <span class="number">#a166ab</span> <span class="number">100%</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="修改markdown分割线样式">修改Markdown分割线样式</h1>
<p>在<code>blog/themes/next/source/css/_common/scaffolding/base.styl</code>中寻找：</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line"><span class="regexp">//</span>hr &#123;</span><br><span class="line"><span class="regexp">//</span>  background-image: repeating-linear-gradient(-<span class="number">45</span>deg, <span class="variable">$grey</span>-lighter, <span class="variable">$grey</span>-lighter <span class="number">4</span>px, <span class="regexp">//</span>transparent <span class="number">4</span>px, transparent <span class="number">8</span>px);</span><br><span class="line"><span class="regexp">//</span>  border: <span class="number">1</span>;</span><br><span class="line"><span class="regexp">//</span>  height: <span class="number">3</span>px;</span><br><span class="line"><span class="regexp">//</span>  margin: <span class="number">40</span>px <span class="number">0</span>;</span><br><span class="line"><span class="regexp">//</span>&#125;</span><br></pre></td></tr></table></figure>
<p>按照上面的方式注释掉即可</p>
<h1 id="修改博客背景">修改博客背景</h1>
<p>参考网上办法跃跃欲试时发现没有了custom.styl这个文件，查看主题_config.xml后发现可以换个方式实现，于是在根目录source下新建 _data/styles.style</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-tag">body</span> &#123;</span><br><span class="line"> 	<span class="attribute">background</span>:<span class="built_in">url</span>(<span class="string">/images/background.jpg</span>);</span><br><span class="line"> 	<span class="attribute">background-repeat</span>: no-repeat;</span><br><span class="line">    <span class="attribute">background-attachment</span>:fixed;</span><br><span class="line">    <span class="attribute">background-position</span>:<span class="number">50%</span> <span class="number">50%</span>;</span><br><span class="line">    <span class="attribute">background-size</span>:<span class="number">100%</span> <span class="number">100%</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>将主题hexo/themes/next/_config.xml中对应的#去掉后就可以了</p>
<figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line">custom_file_path:</span><br><span class="line">  #head: <span class="keyword">source</span><span class="regexp">/_data/</span>head.swig</span><br><span class="line">  #header: <span class="keyword">source</span><span class="regexp">/_data/</span>header.swig</span><br><span class="line">  #sidebar: <span class="keyword">source</span><span class="regexp">/_data/</span>sidebar.swig</span><br><span class="line">  #postMeta: <span class="keyword">source</span><span class="regexp">/_data/</span>post-meta.swig</span><br><span class="line">  #postBodyEnd: <span class="keyword">source</span><span class="regexp">/_data/</span>post-body-end.swig</span><br><span class="line">  #footer: <span class="keyword">source</span><span class="regexp">/_data/</span>footer.swig</span><br><span class="line">  #bodyEnd: <span class="keyword">source</span><span class="regexp">/_data/</span>body-end.swig</span><br><span class="line">  #variable: <span class="keyword">source</span><span class="regexp">/_data/</span>variables.styl</span><br><span class="line">  #mixin: <span class="keyword">source</span><span class="regexp">/_data/mi</span>xins.styl</span><br><span class="line">  style: <span class="keyword">source</span><span class="regexp">/_data/</span>styles.styl</span><br></pre></td></tr></table></figure>
<h1 id="文章透明阴影和直角圆润">文章透明阴影和直角圆润</h1>
<p>html结构</p>
<figure class="highlight haml"><table><tr><td class="code"><pre><span class="line">container</span><br><span class="line">-<span class="ruby"> header-inner</span></span><br><span class="line"><span class="ruby">- main</span></span><br><span class="line"><span class="ruby">	- main-inner</span></span><br><span class="line"><span class="ruby">		- content-wrap</span></span><br><span class="line"><span class="ruby">			- post-block</span></span><br><span class="line"></span><br><span class="line"><span class="ruby">		- sidebar</span></span><br><span class="line"><span class="ruby">			-sidebar-inner</span></span><br><span class="line"><span class="ruby">		</span></span><br></pre></td></tr></table></figure>
<p>在根目录hexo/source下新建 _data/styles.style，在其中添加</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">//在styles<span class="selector-class">.styl</span>里自定义post, 添加背景图象</span><br><span class="line"><span class="selector-tag">body</span> &#123;</span><br><span class="line">    <span class="attribute">background</span>:<span class="built_in">url</span>(<span class="string">/images/background.jpg</span>);</span><br><span class="line">    <span class="attribute">background-repeat</span>: no-repeat;</span><br><span class="line">    <span class="attribute">background-attachment</span>:fixed;</span><br><span class="line">    <span class="attribute">background-position</span>: center;</span><br><span class="line">    //<span class="attribute">background-size</span>:<span class="number">100%</span> <span class="number">100%</span>;</span><br><span class="line">    //<span class="attribute">background-color</span>: <span class="built_in">rgba</span>(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0.8</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// next自身设置的背景有个<span class="selector-tag">main</span>-inner的属性，颜色是继承post <span class="attribute">content</span> <span class="attribute">color</span>，所以我们的思路是自定义<span class="selector-tag">main</span>-inner的<span class="attribute">background-color</span></span><br><span class="line"><span class="selector-class">.main-inner</span> &#123;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="built_in">rgba</span>(<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">0px</span> <span class="number">40px</span> <span class="number">40px</span> <span class="number">40px</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.post-block</span>&#123;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="built_in">rgba</span>(<span class="number">255</span>, <span class="number">255</span>, <span class="number">255</span>, <span class="number">1</span>);</span><br><span class="line">    //<span class="attribute">margin-top</span>: <span class="number">24px</span>;</span><br><span class="line">    //<span class="attribute">margin-bottom</span>: <span class="number">24px</span>;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">20px</span>;</span><br><span class="line">    <span class="attribute">border-radius</span>: <span class="number">20px</span> <span class="number">20px</span> <span class="number">20px</span> <span class="number">20px</span>;</span><br><span class="line">    <span class="attribute">box-shadow</span>: <span class="number">8px</span> <span class="number">7px</span> <span class="number">2px</span> <span class="number">0</span> <span class="built_in">rgba</span>(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.12</span>), <span class="number">7px</span> <span class="number">4px</span> <span class="number">1px</span> -<span class="number">2px</span> <span class="built_in">rgba</span>(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.06</span>), <span class="number">0</span> <span class="number">1px</span> <span class="number">5px</span> <span class="number">0</span> <span class="built_in">rgba</span>(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.12</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//组件椭圆化</span><br><span class="line"><span class="selector-class">.header-inner</span> &#123;</span><br><span class="line">    <span class="attribute">border-radius</span>: <span class="number">20px</span> <span class="number">20px</span> <span class="number">20px</span> <span class="number">20px</span>;</span><br><span class="line">    <span class="attribute">box-shadow</span>: <span class="number">8px</span> <span class="number">7px</span> <span class="number">2px</span> <span class="number">0</span> <span class="built_in">rgba</span>(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.12</span>), <span class="number">7px</span> <span class="number">4px</span> <span class="number">1px</span> -<span class="number">2px</span> <span class="built_in">rgba</span>(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.06</span>), <span class="number">0</span> <span class="number">1px</span> <span class="number">5px</span> <span class="number">0</span> <span class="built_in">rgba</span>(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.12</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.sidebar-inner</span>&#123;</span><br><span class="line">    <span class="attribute">border-radius</span>: <span class="number">20px</span> <span class="number">20px</span> <span class="number">20px</span> <span class="number">20px</span>;</span><br><span class="line">    <span class="attribute">box-shadow</span>: <span class="number">8px</span> <span class="number">7px</span> <span class="number">2px</span> <span class="number">0</span> <span class="built_in">rgba</span>(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.12</span>), <span class="number">7px</span> <span class="number">4px</span> <span class="number">1px</span> -<span class="number">2px</span> <span class="built_in">rgba</span>(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.06</span>), <span class="number">0</span> <span class="number">1px</span> <span class="number">5px</span> <span class="number">0</span> <span class="built_in">rgba</span>(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.12</span>);    </span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.pagination</span> &#123;</span><br><span class="line">    <span class="attribute">border-radius</span>: <span class="number">30px</span> <span class="number">80px</span> <span class="number">30px</span> <span class="number">80px</span>;</span><br><span class="line">    <span class="attribute">box-shadow</span>: <span class="number">8px</span> <span class="number">7px</span> <span class="number">2px</span> <span class="number">0</span> <span class="built_in">rgba</span>(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.12</span>), <span class="number">7px</span> <span class="number">4px</span> <span class="number">1px</span> -<span class="number">2px</span> <span class="built_in">rgba</span>(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.06</span>), <span class="number">0</span> <span class="number">1px</span> <span class="number">5px</span> <span class="number">0</span> <span class="built_in">rgba</span>(<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0.12</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">//侧边框的透明度设置</span><br><span class="line">//<span class="selector-class">.sidebar-inner</span> &#123;<span class="attribute">background</span>: <span class="built_in">rgba</span>(<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>,<span class="number">0.85</span>);&#125;</span><br><span class="line"></span><br><span class="line">//菜单栏的透明度设置</span><br><span class="line">//<span class="selector-class">.header-inner</span> &#123;<span class="attribute">background</span>: <span class="built_in">rgba</span>(<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>,<span class="number">0.85</span>);&#125;</span><br><span class="line"></span><br><span class="line">//搜索框（local-search）的透明度设置</span><br><span class="line">//<span class="selector-class">.popup</span> &#123;<span class="attribute">opacity</span>: <span class="number">0.9</span>;&#125;</span><br><span class="line"></span><br><span class="line">//文章的圆角设置</span><br><span class="line"><span class="selector-class">.content</span> &#123;</span><br><span class="line">	<span class="attribute">border-radius</span>: <span class="number">20px</span>; //文章背景设置圆角</span><br><span class="line">	<span class="attribute">padding</span>: <span class="number">0px</span> <span class="number">0px</span> <span class="number">30px</span> <span class="number">0px</span>;</span><br><span class="line">	<span class="attribute">background</span>:<span class="built_in">rgba</span>(<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>, <span class="number">0.0</span>) none repeat scroll <span class="meta">!important</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//文章内容的透明度设置</span><br><span class="line"><span class="selector-class">.content-wrap</span> &#123;</span><br><span class="line">  <span class="attribute">opacity</span>: <span class="number">0.95</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.sidebar</span> &#123;</span><br><span class="line">  <span class="attribute">opacity</span>: <span class="number">0.7</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.header-inner</span> &#123;</span><br><span class="line">  <span class="attribute">background</span>: <span class="built_in">rgba</span>(<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>,<span class="number">0.7</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-class">.popup</span> &#123;</span><br><span class="line">  <span class="attribute">opacity</span>: <span class="number">0.7</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="菜单栏和预览文章对齐">菜单栏和预览文章对齐</h1>
<ol type="1">
<li>去掉 headbar 的的颜色，修改文件 hexo/themes/next/source/css/_common/outline/header/headerband.styl 中的内容</li>
</ol>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">.headband &#123;</span><br><span class="line">  <span class="regexp">//</span>background: <span class="variable">$headband</span>-bg;	<span class="regexp">//</span>注释这一行</span><br><span class="line">  height: <span class="variable">$headband</span>-height;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>把上面的 20px 空出来</li>
</ol>
<figure class="highlight scss"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.container</span> &#123;</span><br><span class="line">  <span class="attribute">min-height</span>: <span class="number">100%</span>;</span><br><span class="line">  <span class="attribute">position</span>: relative;</span><br><span class="line">  <span class="attribute">margin-top</span>:<span class="number">20px</span>;    <span class="comment">// 添加这一行</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210508222714.png" /></p>
<ol type="1">
<li>然后对齐左边菜单栏和右边的预览 blog，在 hexo/source/_data/style.styl 中添加</li>
</ol>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.content</span> &#123;</span><br><span class="line">	<span class="attribute">border-radius</span>: <span class="number">20px</span>; </span><br><span class="line">	<span class="attribute">padding</span>: <span class="number">0px</span> <span class="number">30px</span> <span class="number">30px</span> <span class="number">30px</span>;		//原来的设置 <span class="number">30px</span> <span class="number">30px</span> <span class="number">30px</span> <span class="number">30px</span>;</span><br><span class="line">	<span class="attribute">background</span>:<span class="built_in">rgba</span>(<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>, <span class="number">0.0</span>) none repeat scroll <span class="meta">!important</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210508222733.png" /></p>
<ol type="1">
<li>对齐 article 和 comment 区域左右的边距</li>
</ol>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.content</span> &#123;</span><br><span class="line">	<span class="attribute">border-radius</span>: <span class="number">20px</span>; </span><br><span class="line">	<span class="attribute">padding</span>: <span class="number">0px</span> <span class="number">0px</span> <span class="number">30px</span> <span class="number">0px</span>;		//原来的设置 <span class="number">0px</span> <span class="number">30px</span> <span class="number">30px</span> <span class="number">30px</span>;</span><br><span class="line">	<span class="attribute">background</span>:<span class="built_in">rgba</span>(<span class="number">255</span>,<span class="number">255</span>,<span class="number">255</span>, <span class="number">0.0</span>) none repeat scroll <span class="meta">!important</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210508222816.png" /></p>
<ol type="1">
<li>去掉菜单下面的的 siderbar-inner 颜色，习惯 hexo/themes/next/source/css/_common/outline/sidebar/sidebar.styl 文件，如下</li>
</ol>
<figure class="highlight scss"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.sidebar</span> &#123;</span><br><span class="line">  <span class="comment">//background: $black-deep; //注释这行</span></span><br><span class="line">  <span class="attribute">bottom</span>: <span class="number">0</span>;</span><br><span class="line">  if (!hexo-config(&#x27;back2top.sidebar&#x27;))&#123;</span><br><span class="line">    <span class="attribute">box-shadow</span>: inset <span class="number">0</span> <span class="number">2px</span> <span class="number">6px</span> black;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="attribute">position</span>: fixed;</span><br><span class="line">  <span class="attribute">top</span>: <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  +tablet-mobile() &#123;</span><br><span class="line">    if (!hexo-config(&#x27;sidebar.onmobile&#x27;)) &#123;</span><br><span class="line">      <span class="attribute">display</span>: none;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="去掉博客底部-powered-by-hexo">去掉博客底部 powered by hexo</h1>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Powered by Hexo &amp; NexT</span></span><br><span class="line">  <span class="attr">powered:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure>
<h1 id="网站底部加访问量">网站底部加访问量</h1>
<h1 id="github-following">Github Following</h1>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># `Follow me on GitHub` banner in the top-right corner.</span></span><br><span class="line"><span class="attr">github_banner:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">permalink:</span> <span class="string">https://github.com/jason-huanghao</span></span><br><span class="line">  <span class="attr">title:</span> <span class="string">Follow</span> <span class="string">me</span> <span class="string">on</span> <span class="string">GitHub</span></span><br></pre></td></tr></table></figure>
<h1 id="参考-references">参考 (References)</h1>
]]></content>
      <categories>
        <category>Blog Building</category>
      </categories>
  </entry>
  <entry>
    <title>hexo文章内容优化</title>
    <url>/2021/05/09/Blog%20Building/hexo%E6%96%87%E7%AB%A0%E5%86%85%E5%AE%B9%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="数学公式支持">数学公式支持</h1>
<p>安装 <code>hexo-math</code>：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">$ npm <span class="keyword">install</span> hexo-<span class="keyword">math</span> --save</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<p>在Next主题配置文件更改设置为：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Math Formulas Render Support</span></span><br><span class="line"><span class="attr">math:</span></span><br><span class="line">  <span class="comment"># Default (true) will load mathjax / katex script on demand.</span></span><br><span class="line">  <span class="comment"># That is it only render those page which has `mathjax: true` in Front-matter.</span></span><br><span class="line">  <span class="comment"># If you set it to false, it will load mathjax / katex srcipt EVERY PAGE.</span></span><br><span class="line">  <span class="attr">per_page:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># hexo-renderer-pandoc (or hexo-renderer-kramed) required for full MathJax support.</span></span><br><span class="line">  <span class="attr">mathjax:</span></span><br><span class="line">    <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">    <span class="comment"># See: https://mhchem.github.io/MathJax-mhchem/</span></span><br><span class="line">    <span class="attr">mhchem:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure>
<p>在需要加载mathjax的文件的头部加入<code>mathjax: true</code> 或者 <code>mathjax: false</code></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">title:</span> <span class="string">transformer</span></span><br><span class="line"><span class="attr">date:</span> <span class="number">2019-12-10 17:50:42</span></span><br><span class="line"><span class="attr">tags:</span></span><br><span class="line"><span class="attr">mathjax:</span> <span class="literal">true</span></span><br><span class="line"><span class="meta">---</span></span><br></pre></td></tr></table></figure>
<h1 id="实现-read-more-隐藏多余行">实现 Read more 隐藏多余行</h1>
<p><strong>第一种方法</strong></p>
<p>用文本编辑器打开 themes/ 目录下的对应的主题的theme文件夹下的 _config.yml 文件，找到这段代码，如果没有则新建，可能不同的主题会不支持这种方法：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"># Automatically Excerpt. Not recommend.</span><br><span class="line"># Please use <span class="comment">&lt;!-- more --&gt;</span> in the post to control excerpt accurately.</span><br><span class="line">auto_excerpt:</span><br><span class="line">  enable: false</span><br><span class="line">  length: 150</span><br></pre></td></tr></table></figure>
<p>把 enable 的 false 改成 true 就行了，然后 length 是设定文章预览的文本长度。</p>
<p>修改后重启 hexo 就ok了。</p>
<p><strong>第二种方法</strong></p>
<p>在你写 md 文章的时候，可以在内容中加上 <code>&lt;!--more--&gt;</code>，这样首页和列表页展示的文章内容就是 <code>&lt;!--more--&gt;</code> 之前的文字，而之后的就不会显示了。</p>
<p>效果</p>
<p>上面两种方式展示出来的效果是不一样的。</p>
<p>第一种修改 _config.yml 文件的效果是会格式化你文章的样式，直接把文字挤在一起显示，最后会有 …。</p>
<p>而第二种加上 <code>&lt;!--more--&gt;</code>展示出来的就是你原本文章的样式，最后不会有…。</p>
<h1 id="去除首页文章间隔与短横线">去除首页文章间隔与短横线</h1>
<p>这里我不需要这个就需要把它删掉，这里要改的地方 hexo/themes/next/source/css/_common/components/post下的post-footer.styl文件，具体如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210508220828.png" /></p>
<h1 id="文章内链接样式">文章内链接样式</h1>
<p>主题配置文件 <code>next.yml</code> 去除 <code>styles.styl</code> 的注释</p>
<figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line">style: <span class="keyword">source</span><span class="regexp">/_data/</span>styles.styl</span><br></pre></td></tr></table></figure>
<p>在 <code>hexo/source/_data</code> 目录下新建 <code>styles.styl</code> 文件，添加下面内容</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">//文章中链接样式</span><br><span class="line"><span class="selector-class">.post-body</span> <span class="selector-tag">p</span> <span class="selector-tag">a</span>&#123;</span><br><span class="line">  <span class="attribute">color</span>: <span class="number">#0593d3</span>;</span><br><span class="line">  //<span class="attribute">border-bottom</span>: none;</span><br><span class="line">  &amp;<span class="selector-pseudo">:hover</span> &#123;</span><br><span class="line">    <span class="attribute">color</span>: <span class="number">#ff106c</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="selector-tag">a</span>, <span class="selector-tag">span</span><span class="selector-class">.exturl</span> &#123;</span><br><span class="line">  <span class="attribute">border-bottom</span>: none;</span><br><span class="line">  &amp;<span class="selector-pseudo">:hover</span> &#123;</span><br><span class="line">    <span class="attribute">color</span>: <span class="number">#ff106c</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="文章底部增加版权信息">文章底部增加版权信息</h1>
<p>主题配置文件 <code>next.yml</code> 修改 <code>creative_commons</code> 选项。</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">creative_commons:</span></span><br><span class="line">  <span class="attr">license:</span> <span class="string">by-nc-sa</span></span><br><span class="line">  <span class="attr">sidebar:</span> <span class="literal">false</span> <span class="comment"># 不显示在侧边栏</span></span><br><span class="line">  <span class="attr">post:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">language:</span></span><br></pre></td></tr></table></figure>
<p>版权格式 post-copyright.styl</p>
<figure class="highlight scss"><table><tr><td class="code"><pre><span class="line"><span class="selector-class">.post-copyright</span> &#123;</span><br><span class="line">  <span class="comment">//background: var(--card-bg-color);</span></span><br><span class="line">  <span class="attribute">border-left</span>: <span class="number">3px</span> solid <span class="variable">$red</span>;</span><br><span class="line">  <span class="attribute">border-top</span>: <span class="number">1px</span> solid <span class="variable">$red</span>;</span><br><span class="line">  <span class="attribute">border-bottom</span>: <span class="number">1px</span> solid <span class="variable">$red</span>;</span><br><span class="line">  <span class="attribute">border-right</span>: <span class="number">1px</span> solid <span class="variable">$red</span>;</span><br><span class="line">  <span class="attribute">list-style</span>: none;</span><br><span class="line">  <span class="attribute">margin</span>: <span class="number">2em</span> <span class="number">0</span> <span class="number">0</span>;</span><br><span class="line">  <span class="attribute">padding</span>: .<span class="number">5em</span> <span class="number">1em</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="修改文章底部-tag-图标">修改文章底部 tag 图标</h1>
<p>主题配置文件 <code>next.yml</code>，打开底部标签 。</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">tag_icon:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<h1 id="添加代码复制功能-next8.x">添加代码复制功能 (next8.X)</h1>
<p>hexo next 8.X</p>
<p>在 hexo/_config.yml 下开启 highlight</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">highlight:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">line_number:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">auto_detect:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">tab_replace:</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">  <span class="attr">wrap:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">hljs:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure>
<p>修改 hexo/themes/next/_config.yml 选择不同的风格</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">codeblock:</span></span><br><span class="line">  <span class="comment"># Code Highlight theme</span></span><br><span class="line">  <span class="comment"># Available values: normal | night | night eighties | night blue | night bright | solarized | solarized dark | galactic</span></span><br><span class="line">  <span class="comment"># See: https://github.com/chriskempson/tomorrow-theme</span></span><br><span class="line">  <span class="attr">highlight_theme:</span> <span class="string">night</span> <span class="string">eighties</span> <span class="comment"># galactic </span></span><br><span class="line">  <span class="comment"># Add copy button on codeblock</span></span><br><span class="line">  <span class="attr">copy_button:</span></span><br><span class="line">    <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">    <span class="comment"># Show text copy result.</span></span><br><span class="line">    <span class="attr">show_result:</span> <span class="literal">true</span></span><br><span class="line">    <span class="comment"># Available values: default | flat | mac</span></span><br><span class="line">    <span class="attr">style:</span> <span class="string">mac</span></span><br></pre></td></tr></table></figure>
<h1 id="添加代码复制功能-next其他版本">添加代码复制功能 (next其他版本)</h1>
<p>所用工具：<a href="https://clipboardjs.com/">clipboard.js</a></p>
<ol type="1">
<li>下载<a href="https://raw.githubusercontent.com/zenorocha/clipboard.js/master/dist/clipboard.min.js">clipboard.min.js</a>并保存至<code>themes\next\source\js\clipboard.min.js</code></li>
<li>在<code>.\themes\next\source\js\</code>下创建<code>clipboard-use.js</code>,添加如下内容：</li>
</ol>
<figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">copy<span class="comment">/*页面载入完成后，创建复制按钮*/</span></span><br><span class="line">!<span class="function"><span class="keyword">function</span> (<span class="params">e, t, a</span>) </span>&#123; </span><br><span class="line">  <span class="keyword">var</span> initCopyCode = <span class="function"><span class="keyword">function</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="keyword">var</span> copyHtml = <span class="string">&#x27;&#x27;</span>;</span><br><span class="line">    copyHtml += <span class="string">&#x27;&lt;button class=&quot;btn-copy&quot; data-clipboard-snippet=&quot;&quot;&gt;&#x27;</span>;</span><br><span class="line">    <span class="comment">//fa fa-globe可以去字体库替换自己想要的图标</span></span><br><span class="line">    copyHtml += <span class="string">&#x27;  &lt;i class=&quot;fa fa-clipboard&quot;&gt;&lt;/i&gt;&lt;span&gt;copy&lt;/span&gt;&#x27;</span>;</span><br><span class="line">    copyHtml += <span class="string">&#x27;&lt;/button&gt;&#x27;</span>;</span><br><span class="line">    $(<span class="string">&quot;.highlight .code pre&quot;</span>).before(copyHtml);</span><br><span class="line">    <span class="keyword">new</span> ClipboardJS(<span class="string">&#x27;.btn-copy&#x27;</span>, &#123;</span><br><span class="line">        target: <span class="function"><span class="keyword">function</span>(<span class="params">trigger</span>) </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> trigger.nextElementSibling;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;</span><br><span class="line">  initCopyCode();</span><br><span class="line">&#125;(<span class="built_in">window</span>, <span class="built_in">document</span>);</span><br></pre></td></tr></table></figure>
<ol type="1">
<li>在<code>根目录\source\_data\</code>下创建<code>styles.styl</code>，添加如下内容：</li>
</ol>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">copy// 代码块复制按钮</span><br><span class="line">// --------------------------------------------------</span><br><span class="line"><span class="selector-class">.highlight</span>&#123;</span><br><span class="line">  //方便copy代码按钮（btn-copy）的定位</span><br><span class="line">  <span class="attribute">position</span>: relative;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.btn-copy</span> &#123;</span><br><span class="line">    <span class="attribute">display</span>: inline-block;</span><br><span class="line">    <span class="attribute">cursor</span>: pointer;</span><br><span class="line">    <span class="attribute">background-color</span>: <span class="number">#eee</span>;</span><br><span class="line">    <span class="attribute">background-image</span>: <span class="built_in">linear-gradient</span>(<span class="number">#fcfcfc</span>,<span class="number">#eee</span>);</span><br><span class="line">    <span class="attribute">border</span>: <span class="number">1px</span> solid <span class="number">#d5d5d5</span>;</span><br><span class="line">    <span class="attribute">border-radius</span>: <span class="number">3px</span>;</span><br><span class="line">    -webkit-user-select: none;</span><br><span class="line">    -moz-user-select: none;</span><br><span class="line">    -ms-user-select: none;</span><br><span class="line">    user-select: none;</span><br><span class="line">    -webkit-appearance: none;</span><br><span class="line">    <span class="attribute">font-size</span>: <span class="number">13px</span>;</span><br><span class="line">    <span class="attribute">font-weight</span>: <span class="number">700</span>;</span><br><span class="line">    <span class="attribute">line-height</span>: <span class="number">20px</span>;</span><br><span class="line">    <span class="attribute">color</span>: <span class="number">#333</span>;</span><br><span class="line">    -webkit-<span class="attribute">transition</span>: opacity .<span class="number">3s</span> ease-in-out;</span><br><span class="line">    -o-<span class="attribute">transition</span>: opacity .<span class="number">3s</span> ease-in-out;</span><br><span class="line">    <span class="attribute">transition</span>: opacity .<span class="number">3s</span> ease-in-out;</span><br><span class="line">    <span class="attribute">padding</span>: <span class="number">2px</span> <span class="number">6px</span>;</span><br><span class="line">    <span class="attribute">position</span>: absolute;</span><br><span class="line">    <span class="attribute">right</span>: <span class="number">5px</span>;</span><br><span class="line">    <span class="attribute">top</span>: <span class="number">5px</span>;</span><br><span class="line">    <span class="attribute">opacity</span>: <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.btn-copy</span> <span class="selector-tag">span</span> &#123;</span><br><span class="line">    <span class="attribute">margin-left</span>: <span class="number">5px</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="selector-class">.highlight</span><span class="selector-pseudo">:hover</span> <span class="selector-class">.btn-copy</span>&#123;</span><br><span class="line">  <span class="attribute">opacity</span>: <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>4.在<code>source\_data\</code>下创建<code>body-end.swig</code>，添加如下内容：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">copy<span class="comment">&lt;!-- 代码块复制功能 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;text/javascript&quot;</span> <span class="attr">src</span>=<span class="string">&quot;/js/src/clipboard.min.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">type</span>=<span class="string">&quot;text/javascript&quot;</span> <span class="attr">src</span>=<span class="string">&quot;/js/src/clipboard-use.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ol type="1">
<li>在next配置文件中启用<code>styles.styl</code>和<code>body-end.swig</code>：</li>
</ol>
<figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line">copycustom_file_path:</span><br><span class="line">  bodyEnd: <span class="keyword">source</span><span class="regexp">/_data/</span>body-end.swig</span><br><span class="line">  style: <span class="keyword">source</span><span class="regexp">/_data/</span>styles.styl</span><br></pre></td></tr></table></figure>
<h1 id="分页功能">分页功能</h1>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 安装相应的插件</span></span><br><span class="line"><span class="string">npm</span> <span class="string">install</span> <span class="string">--save</span> <span class="string">hexo-generator-index</span></span><br><span class="line"><span class="string">npm</span> <span class="string">install</span> <span class="string">--save</span> <span class="string">hexo-generator-archive</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 更改站点的配置文件</span></span><br><span class="line"><span class="string">cd</span> <span class="string">博客目录</span></span><br><span class="line"><span class="string">vim</span> <span class="string">_config.yml</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这一段默认就有的</span></span><br><span class="line"><span class="attr">index_generator:</span></span><br><span class="line">  <span class="attr">path:</span> <span class="string">&#x27;&#x27;</span></span><br><span class="line">  <span class="attr">per_page:</span> <span class="number">5</span></span><br><span class="line">  <span class="attr">order_by:</span> <span class="string">-date</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 归档页面</span></span><br><span class="line"><span class="attr">archive_generator:</span></span><br><span class="line">  <span class="attr">per_page:</span> <span class="number">50</span></span><br><span class="line">  <span class="attr">yearly:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">monthly:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<h1 id="文章加密">文章加密</h1>
<p>请注意，可npm install hexo-blog-encrypt --save能导致文章目录不显示。</p>
<p>安装 hexo-blog-encrypt 插件。</p>
<figure class="highlight livecodeserver"><table><tr><td class="code"><pre><span class="line">npm install hexo-blog-<span class="built_in">encrypt</span> <span class="comment">--save</span></span><br></pre></td></tr></table></figure>
<p>在需要加密的文章的 header 中添加下面内容。</p>
<figure class="highlight avrasm"><table><tr><td class="code"><pre><span class="line"><span class="symbol">password:</span> <span class="number">123456</span></span><br><span class="line"><span class="symbol">abstract:</span> 加密文章，请输入密码 <span class="number">123456</span> 查看</span><br><span class="line"><span class="symbol">message:</span> 请输入密码</span><br></pre></td></tr></table></figure>
<h1 id="顶部阅读进度条">顶部阅读进度条</h1>
<p>主题配置文件 next.yml 中修改 reading_progress 选项。</p>
<figure class="highlight dts"><table><tr><td class="code"><pre><span class="line"><span class="symbol">reading_progress:</span></span><br><span class="line"><span class="symbol">  enable:</span> true</span><br><span class="line"><span class="symbol">  position:</span> top</span><br><span class="line"><span class="symbol">  color:</span> <span class="string">&quot;#06d633&quot;</span></span><br><span class="line"><span class="symbol">  height:</span> <span class="number">3</span>px</span><br></pre></td></tr></table></figure>
<h1 id="next-主题中文章的目录中文项点击不能跳转">Next 主题中文章的目录中文项点击不能跳转</h1>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210511215643.png" /> 比如上面图片中所有带有的中文的都不能点击跳转到对于的内容，这个问题在 Next github 上已经解决了。 参考链接 https://github.com/kyangc/hexo-theme-next-1/commit/a3f9764ab57e157b3176f27c42481a4713f8cd94 参考链页面修改 next 主题下对应的行，代码中红色行 (带有减号) 是在你博客项目下需要删除的内容；代码中绿色行 (带有加号) 是需要你添加的内容。</p>
<h1 id="hexo-sitemap-报-xmlparseentityref-no-name">Hexo sitemap 报 xmlParseEntityRef: no name</h1>
<p>去掉博客文件名中的特殊字符 “&amp;”</p>
<h1 id="blog-隐藏">Blog 隐藏</h1>
<p>hexo-generator-indexed</p>
<h1 id="参考-references">参考 (References)</h1>
]]></content>
      <categories>
        <category>Blog Building</category>
      </categories>
      <tags>
        <tag>博客</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>博客搭建/hexo 博客环境搭建</title>
    <url>/2021/05/09/Blog%20Building/hexo%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="install-brew">Install Brew</h1>
<p><strong>中科大镜像使用，加速安装</strong></p>
<p><a href="https://mirrors.tuna.tsinghua.edu.cn/help/homebrew/">参考链接</a></p>
<p>首先，需要确保系统中安装了 bash、git 和 curl，对于 macOS 用户需额外要求安装 Command Line Tools (CLT) for Xcode。 <span id="more"></span></p>
<ul>
<li>对于 macOS 用户，系统自带 bash、git 和 curl，在命令行输入 <code>xcode-select --install</code> 安装 CLT for Xcode 即可。</li>
<li>对于 Linux 用户，系统自带 bash，仅需额外安装 git 和 curl。</li>
</ul>
<p>接着，在终端输入以下几行命令设置环境变量：</p>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> [[ <span class="string">&quot;<span class="variable">$(uname -s)</span>&quot;</span> == <span class="string">&quot;Linux&quot;</span> ]]; then <span class="attribute">BREW_TYPE</span>=<span class="string">&quot;linuxbrew&quot;</span>; <span class="keyword">else</span> <span class="attribute">BREW_TYPE</span>=<span class="string">&quot;homebrew&quot;</span>; fi</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HOMEBREW_BREW_GIT_REMOTE</span>=<span class="string">&quot;https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.git&quot;</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HOMEBREW_CORE_GIT_REMOTE</span>=<span class="string">&quot;https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/<span class="variable">$&#123;BREW_TYPE&#125;</span>-core.git&quot;</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HOMEBREW_BOTTLE_DOMAIN</span>=<span class="string">&quot;https://mirrors.tuna.tsinghua.edu.cn/<span class="variable">$&#123;BREW_TYPE&#125;</span>-bottles&quot;</span></span><br></pre></td></tr></table></figure>
<p>最后，在终端运行以下命令以安装 Homebrew / Linuxbrew：</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 从本镜像下载安装脚本并安装 Homebrew / Linuxbrew</span></span><br><span class="line">git clone --depth=<span class="number">1</span> https:<span class="regexp">//mi</span>rrors.tuna.tsinghua.edu.cn<span class="regexp">/git/</span>homebrew/install.git brew-install</span><br><span class="line"><span class="regexp">/bin/</span>bash brew-install/install.sh</span><br><span class="line">rm -rf brew-install</span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可从 GitHub 获取官方安装脚本安装 Homebrew / Linuxbrew</span></span><br><span class="line"><span class="regexp">/bin/</span>bash -c <span class="string">&quot;$(curl -fsSL https://github.com/Homebrew/install/raw/master/install.sh)&quot;</span></span><br></pre></td></tr></table></figure>
<p>检查是否安装成功</p>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">brew update</span><br><span class="line">brew doctor</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="string">&quot;/usr/local/bin:<span class="variable">$PATH</span>&quot;</span></span><br></pre></td></tr></table></figure>
<p><strong>fatal: unable to access 'https://github.com/': Could not resolve proxy: aproxy</strong></p>
<figure class="highlight tcl"><table><tr><td class="code"><pre><span class="line">git config --<span class="keyword">global</span> --<span class="keyword">unset</span> <span class="keyword">http</span>.proxy</span><br><span class="line">git config --<span class="keyword">global</span> --<span class="keyword">unset</span> https.proxy</span><br></pre></td></tr></table></figure>
<p><strong>uninstall brew</strong></p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line"><span class="comment"># uninstall</span></span><br><span class="line">cd `brew --prefix`</span><br><span class="line">rm -rf Cellar</span><br><span class="line">brew prune</span><br><span class="line">rm -rf Library .git .gitignore bin<span class="regexp">/brew README.md share/m</span>an<span class="regexp">/man1/</span>brew</span><br><span class="line">rm -rf ~<span class="regexp">/Library/</span>Caches/Homebrew</span><br><span class="line"></span><br><span class="line"><span class="comment"># uninstall</span></span><br><span class="line"><span class="regexp">/bin/</span>bash -c <span class="string">&quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/uninstall.sh)&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># install</span></span><br><span class="line"><span class="regexp">/bin/</span>bash -c <span class="string">&quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot;</span></span><br></pre></td></tr></table></figure>
<h1 id="install-node-and-npm-by-nvm">Install Node and npm by NVM</h1>
<p><strong>NVM 安装</strong> (node version manager)</p>
<p>install nvm by brew <a href="https://formulae.brew.sh/formula/nvm">link</a></p>
<figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line"><span class="keyword">brew </span><span class="keyword">install </span>nvm</span><br></pre></td></tr></table></figure>
<p>install by</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">curl -o- https:<span class="regexp">//</span>raw.githubusercontent.com<span class="regexp">/nvm-sh/</span>nvm<span class="regexp">/v0.35.3/i</span>nstall.sh | bash</span><br></pre></td></tr></table></figure>
<p><strong>报错 “zsh: command not found: nvm”</strong></p>
<p>原因：安装未成功 创建一个nvm的文件用来装载nvm的内容 在命令行执行：</p>
<figure class="highlight arduino"><table><tr><td class="code"><pre><span class="line">mkdir ~/.nvm</span><br></pre></td></tr></table></figure>
<p>需要在~/.zshrc 文件里面增加以下配置 用vim打开该文件</p>
<figure class="highlight jboss-cli"><table><tr><td class="code"><pre><span class="line">vim ~<span class="string">/.zshrc</span></span><br></pre></td></tr></table></figure>
<p>如果有swp文件妨碍修改，删掉即可 按 i 进入书写模式，黏贴以下代码</p>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line"><span class="builtin-name">export</span> <span class="attribute">NVM_DIR</span>=<span class="string">&quot;<span class="variable">$HOME</span>/.nvm&quot;</span>[ -s <span class="string">&quot;/usr/local/opt/nvm/nvm.sh&quot;</span> ] &amp;&amp; . <span class="string">&quot;/usr/local/opt/nvm/nvm.sh&quot;</span>  # This loads nvm[ -s <span class="string">&quot;/usr/local/opt/nvm/etc/bash_completion&quot;</span> ] &amp;&amp; . <span class="string">&quot;/usr/local/opt/nvm/etc/bash_completion&quot;</span></span><br></pre></td></tr></table></figure>
<p>按 esc 键 :wq 保存退出</p>
<p>执行命令使配置生效：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.zshrc</span><br></pre></td></tr></table></figure>
<p>再次执行brew install nvm</p>
<p><strong>nvm 安装 Node and npm</strong></p>
<p>查看 version</p>
<figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">nvm ls-remote</span></span><br></pre></td></tr></table></figure>
<p>安装版本</p>
<figure class="highlight applescript"><table><tr><td class="code"><pre><span class="line">nvm install &lt;<span class="built_in">version</span>&gt;</span><br></pre></td></tr></table></figure>
<p>查看本地安装的 node 版本</p>
<figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">nvm list</span></span><br></pre></td></tr></table></figure>
<p>指定使用的版本</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">nvm</span> use &lt;version&gt; # v<span class="number">15</span>.<span class="number">12</span>.<span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>检查使用的 node 版本</p>
<figure class="highlight applescript"><table><tr><td class="code"><pre><span class="line">nvm currentornode -<span class="built_in">version</span></span><br></pre></td></tr></table></figure>
<p>卸载版本</p>
<figure class="highlight applescript"><table><tr><td class="code"><pre><span class="line">nvm uninstall &lt;<span class="built_in">version</span>&gt;</span><br></pre></td></tr></table></figure>
<h1 id="install-node-and-npm">Install Node and npm</h1>
<p>不推荐使用官方的安装包安装（https://nodejs.org/en/download/）</p>
<p>原因：since the Node installation process installs npm in a directory with local permissions and can cause permissions errors when you run npm packages globally</p>
<p><strong>Solve EACCES error</strong></p>
<p>If you see an <code>EACCES</code> error when you try to <a href="https://docs.npmjs.com/downloading-and-installing-packages-globally">install a package globally</a>, you can either:</p>
<ol type="1">
<li>Reinstall npm with a node version manager (recommended),</li>
</ol>
<p>do not need to remove your current version of npm or Node.js before installing a node version manager.</p>
<ol start="2" type="1">
<li>Manually change npm's default directory</li>
</ol>
<p><strong>卸载 Node &amp; npm completely</strong></p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line"><span class="keyword">cd</span> /<span class="keyword">cd</span> usrcd localcd <span class="keyword">include</span> sudo <span class="keyword">rm</span> -R nodecd ../libsudo <span class="keyword">rm</span> -R node_modulescd ../binsudo <span class="keyword">rm</span> -R node</span><br></pre></td></tr></table></figure>
<p><strong>use brew install node</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">brew uninstall nodebrew doctorbrew cleanup --prune-prefix<span class="comment"># installbrew install node;which node # =&gt; /usr/local/bin/nodeexport NODE_PATH=&#x27;/usr/local/lib/node_modules&#x27; # &lt;--- add this ~/.bashrc</span></span><br></pre></td></tr></table></figure>
<p><strong>npm 使用</strong></p>
<p>安装 package</p>
<figure class="highlight applescript"><table><tr><td class="code"><pre><span class="line">npm install &lt;pacakge <span class="built_in">name</span>&gt; <span class="comment">--save</span></span><br></pre></td></tr></table></figure>
<p>卸载 package</p>
<figure class="highlight applescript"><table><tr><td class="code"><pre><span class="line">npm uninstall &lt;pacakge <span class="built_in">name</span>&gt;</span><br></pre></td></tr></table></figure>
<h1 id="参考-references">参考 (References)</h1>
]]></content>
      <categories>
        <category>Blog Building</category>
      </categories>
      <tags>
        <tag>博客</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo高级功能</title>
    <url>/2021/05/09/Blog%20Building/hexo%E9%AB%98%E7%BA%A7%E5%8A%9F%E8%83%BD/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="站内搜索">站内搜索</h1>
<p>安装hexo-generator-searchdb</p>
<figure class="highlight ada"><table><tr><td class="code"><pre><span class="line">npm install hexo-generator-searchdb <span class="comment">--save</span></span><br></pre></td></tr></table></figure>
<span id="more"></span>
<p>在 hexo/themes/next/_config.yml 中修改配置<code>local_search</code>：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">local_search:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span>		<span class="comment"># 开启站内搜索</span></span><br><span class="line">  <span class="attr">trigger:</span> <span class="string">auto</span>		<span class="comment"># 自动和手动触发</span></span><br><span class="line">  <span class="attr">top_n_per_article:</span> <span class="number">3</span>  <span class="comment"># 每篇文章显示的搜索结果数量</span></span><br><span class="line">  <span class="attr">unescape:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure>
<h1 id="auto-category">Auto category</h1>
<p>下载 Auto Category</p>
<figure class="highlight ada"><table><tr><td class="code"><pre><span class="line">npm install hexo-auto-category <span class="comment">--save</span></span><br></pre></td></tr></table></figure>
<p>在 hexo/_config.yml 文件后添加下面的语句</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Generate categories from directory-tree</span></span><br><span class="line"><span class="comment"># Dependencies: https://github.com/xu-song/hexo-auto-category</span></span><br><span class="line"><span class="comment"># depth: the max_depth of directory-tree you want to generate, should &gt; 0</span></span><br><span class="line"><span class="attr">auto_category:</span></span><br><span class="line"> <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line"> <span class="attr">depth:</span> </span><br></pre></td></tr></table></figure>
<h1 id="hexo-next-daovoice-实现在线联系-页面不显示问题未解决暂时不用该功能">Hexo Next DaoVoice 实现在线联系 (页面不显示问题未解决！暂时不用该功能)</h1>
<p><strong>DaoVoice 注册</strong></p>
<p><a href="http://dashboard.daovoice.io">register link</a></p>
<h2 id="方法一">方法一</h2>
<p><strong>head.swig 修改</strong></p>
<p>在文件 hexo/themes/next/layout/_partials/head/head.swig 中添加以下语句</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">&#123;% if theme.daovoice %&#125;</span><br><span class="line"> &lt;script&gt;(function(i,s,o,g,r,a,m)&#123;i[&quot;DaoVoiceObject&quot;]=r;i[r]=i[r]||function()&#123;(i[r].q=i[r].q||[]).push(arguments)&#125;,i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset=&quot;utf-8&quot;;m.parentNode.insertBefore(a,m)&#125;)(window,document,&quot;script&quot;,(&#x27;https:&#x27; == document.location.protocol ? &#x27;https:&#x27; : &#x27;http:&#x27;) + &quot;//widget.daovoice.io/widget/b6dbddb6.js&quot;,&quot;daovoice&quot;)</span><br><span class="line"> daovoice(&#x27;init&#x27;, &#123;</span><br><span class="line">  app_id: &quot;APP ID&quot;</span><br><span class="line">&#125;);</span><br><span class="line">daovoice(&#x27;update&#x27;);</span><br><span class="line"> &lt;/script&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure>
<p>其中 “APP ID” 使用你在 DaoVoice 中的 “app_id”</p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210508221613.png" /></p>
<p><strong>config.yml 配置文件修改</strong></p>
<p>在文件 hexo/themes/next/_config.yml 中添加以下语句</p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">daovoice: true</span><br><span class="line">daovoice_app_id: f32df35e</span><br></pre></td></tr></table></figure>
<p><strong>修改聊天图标等设置</strong></p>
<figure class="highlight clean"><table><tr><td class="code"><pre><span class="line">应用设置 -&gt; 聊天设置 -&gt; </span><br></pre></td></tr></table></figure>
<p><strong>部署 DaoVoice</strong></p>
<figure class="highlight text"><table><tr><td class="code"><pre><span class="line">hexo clean &amp;&amp; hexo g &amp;&amp; hexo s</span><br></pre></td></tr></table></figure>
<p><strong>DaoVoice 显示接入成功</strong></p>
<p>![注册</p>
<p>首先需要在 DaoVoice 注册个账号，<a href="http://dashboard.daovoice.io/get-started?invite_code=4e6b4c7f">点击注册</a></p>
<p>注册成功后，进入后台控制台，进入到 应用设置–&gt; 安装到网站 页面，可以得到一个 app_id：</p>
<figure>
<img src="https://leezhiy.github.io/images/daovoice-get-appid.png" alt="获取APPID" /><figcaption aria-hidden="true">获取APPID</figcaption>
</figure>
<h2 id="方法二">方法二</h2>
<p><strong>利用 NexT 主题的 Injects 功能管理 DaoVoice 插件</strong></p>
<p>在 NexT 使用过程中，我们免不了要安装一些 NexT 暂时未集成的插件，但我们又不想修改主题的源码，这时就需要使用 Next 的 <code>theme-inject</code> 功能，它通过注入代码的方式提供多个注入点实现定制内容。 Injects 具体的定义见 <a href="https://theme-next.org/docs/advanced-settings">NexT 文档</a></p>
<p><strong>修改配置文件</strong></p>
<p>首先，打开 主题配置文件 ，在最底部添加</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">script</span></span><br><span class="line"><span class="comment"># DaoVoice</span></span><br><span class="line"><span class="attr">daovoice:</span></span><br><span class="line">  <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">  <span class="attr">app_id:</span> <span class="comment"># 输入你自己的 app_id</span></span><br></pre></td></tr></table></figure>
<p><strong>注入布局</strong></p>
<p>第二步，我们在 Hexo 的 <code>scripts</code> 创建一个 js 文件 plugins.js（用来管理需要修改代码的第三方插件），添加以下内容。只要是这里面的脚本，Hexo 运行时会执行它。</p>
<figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">hexo.extend.filter.register(<span class="string">&#x27;theme_inject&#x27;</span>, <span class="function"><span class="keyword">function</span> <span class="params">(injects)</span></span> &#123;</span><br><span class="line">    // hexo.theme.<span class="built_in">config</span>.daovoice 就是上面配置的值，我们将配置参数传递给 daovoice.swig</span><br><span class="line">    injects.head.file(<span class="string">&#x27;daovoice&#x27;</span>, <span class="string">&#x27;source/_data/DaoVoice.swig&#x27;</span>, &#123;daovoice: hexo.theme.<span class="built_in">config</span>.daovoice&#125;);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>最后，我们创建 <code>Hexo/source/_data/DaoVoice.swig</code> 文件，添加以下内容。</p>
<figure class="highlight django"><table><tr><td class="code"><pre><span class="line"><span class="template-tag">&#123;% <span class="name"><span class="name">if</span></span> daovoice.enabled %&#125;</span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;<span class="name">script</span>&gt;</span></span></span><br><span class="line"><span class="xml">  (function(i,s,o,g,r,a,m)&#123;i[&quot;DaoVoiceObject&quot;]=r;i[r]=i[r]||function()&#123;(i[r].q=i[r].q||[]).push(arguments)&#125;,i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset=&quot;utf-8&quot;;m.parentNode.insertBefore(a,m)&#125;)(window,document,&quot;script&quot;,(&#x27;https:&#x27; == document.location.protocol ? &#x27;https:&#x27; : &#x27;http:&#x27;) + &quot;//widget.daovoice.io/widget/0f81ff2f.js&quot;,&quot;daovoice&quot;)</span></span><br><span class="line"><span class="xml">  daovoice(&#x27;init&#x27;, &#123;</span></span><br><span class="line"><span class="xml">    app_id: &#x27;</span><span class="template-variable">&#123;&#123;daovoice.app_id&#125;&#125;</span><span class="xml">&#x27;,   // 必填，您的 APP 标识</span></span><br><span class="line"><span class="xml">  &#125;);</span></span><br><span class="line"><span class="xml">  daovoice(&#x27;update&#x27;);</span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br><span class="line"><span class="template-tag">&#123;% <span class="name"><span class="name">endif</span></span> %&#125;</span></span><br></pre></td></tr></table></figure>
<p>运行 <code>hexo s</code> , 发现右下角已经出现如图下所示图标，DaoVoice 已经接入成功。</p>
<p><strong>安装 hexo-cake-moon-menu 插件，并添加按钮接管 DaoVoice</strong></p>
<p>安装 hexo-cake-moon-menu 插件, 在 Hexo 目录打开 git bash 并输入命令：</p>
<figure class="highlight applescript"><table><tr><td class="code"><pre><span class="line"><span class="keyword">script</span></span><br><span class="line">$ npm install hexo-cake-moon-menu <span class="comment">--save</span></span><br></pre></td></tr></table></figure>
<p>打开 站点配置文件 ，在最底部添加</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">script</span></span><br><span class="line"><span class="attr">moon_menu:</span></span><br><span class="line">  <span class="attr">back2top:</span></span><br><span class="line">    <span class="attr">enable:</span> <span class="string">ture</span></span><br><span class="line">    <span class="attr">icon:</span> <span class="string">fa</span> <span class="string">fa-chevron-up</span></span><br><span class="line">    <span class="attr">func:</span> <span class="string">back2top</span></span><br><span class="line">    <span class="attr">order:</span> <span class="number">-1</span></span><br><span class="line">  <span class="attr">back2bottom:</span></span><br><span class="line">    <span class="attr">enable:</span> <span class="literal">true</span></span><br><span class="line">    <span class="attr">icon:</span> <span class="string">fa</span> <span class="string">fa-chevron-down</span></span><br><span class="line">    <span class="attr">func:</span> <span class="string">back2bottom</span></span><br><span class="line">    <span class="attr">order:</span> <span class="number">-2</span></span><br></pre></td></tr></table></figure>
<h1 id="next-valine-评论系统">Next Valine 评论系统</h1>
<p><strong>保证 next 版本最新</strong></p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">cd hexo <span class="comment"># 进入你的blog文件根部</span></span><br><span class="line">git clone https:<span class="regexp">//gi</span>thub.com<span class="regexp">/theme-next/</span>hexo-theme-<span class="keyword">next</span> themes/<span class="keyword">next</span></span><br><span class="line">sudo rm -rf .<span class="regexp">/themes/</span><span class="keyword">next</span>/.git <span class="comment"># 删除.git为了主题能同步到github</span></span><br><span class="line">sudo rm -rf .<span class="regexp">/themes/</span><span class="keyword">next</span>/.gitignore <span class="comment"># 删除.gitignore为了主题完整同步到github</span></span><br></pre></td></tr></table></figure>
<p><strong>注册 LeanCloud</strong></p>
<p><a href="https://leancloud.cn/dashboard/login.html#/signin">LeanCloud官网登录入口</a></p>
<p>创建应用，为了获取 AppID 和 AppKey</p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210508221719.png" /></p>
<p>填写 app 信息</p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210508221726.png" /></p>
<p>记录 AppID 和 AppKey</p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210508221735.png" /></p>
<p><strong>Next 主题配置 valine 的配置</strong></p>
<p>打开 hexo/themes/next/_config.yml，找到comments栏目并开启valine。</p>
<figure class="highlight dts"><table><tr><td class="code"><pre><span class="line"><span class="symbol">comments:</span></span><br><span class="line"><span class="symbol">  active:</span> valine</span><br></pre></td></tr></table></figure>
<p>在 hexo/themes/next/_config.yml 搜索 valine，填入appid 和 appkey</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Valine.</span></span><br><span class="line"><span class="comment"># You can get your appid and appkey from https://leancloud.cn</span></span><br><span class="line"><span class="comment"># more info please open https://valine.js.org</span></span><br><span class="line"><span class="attr">valine:</span></span><br><span class="line">  <span class="attr">enable:</span> <span class="literal">true</span> <span class="comment"># 是否开启</span></span><br><span class="line">  <span class="attr">appid:</span> <span class="string">STLjflsxBIAFNnGAcBVgq6Vu-gzGzoHsz</span> <span class="comment"># 上一步获取的 App ID</span></span><br><span class="line">  <span class="attr">appkey:</span> <span class="string">6zO0wFSDgLF6LulPGcifgFOW</span> <span class="comment"># 上一步获取的 App Key</span></span><br><span class="line">  <span class="attr">notify:</span> <span class="literal">false</span> <span class="comment"># 新留言是否需要通知 https://github.com/xCss/Valine/wiki</span></span><br><span class="line">  <span class="attr">verify:</span> <span class="literal">false</span> <span class="comment"># 是否需要验证，验证比较反人类建议false关闭</span></span><br><span class="line">  <span class="attr">placeholder:</span> <span class="string">请在此输入您的留言</span> <span class="comment"># 默认留言框内的文字</span></span><br><span class="line">  <span class="attr">avatar:</span> <span class="string">mm</span> <span class="comment"># 默认头像</span></span><br><span class="line">  <span class="attr">guest_info:</span> <span class="string">nick,mail</span> <span class="comment"># 默认留言框的头部需要访问者输入的信息</span></span><br><span class="line">  <span class="attr">pageSize:</span> <span class="number">10</span> <span class="comment"># pagination size #默认单页的留言条数</span></span><br></pre></td></tr></table></figure>
<p><strong>评论管理</strong></p>
<p>进入 leancloud 官网，找到 <code>控制台</code>-&gt;<code>存储</code>-&gt;<code>commet</code> 中进行管理</p>
<p><strong>评论时报错</strong></p>
<p>在Leancloud -&gt; 设置 -&gt; 安全中心 -&gt; Web 安全域名 把你的域名 (就是你的博客主页地址) 加进去</p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210508221809.png" /></p>
<h1 id="hexo-admin-使用">Hexo Admin 使用</h1>
<p><strong>安装 Hexo Admin</strong></p>
<p>进入 Hexo 根目录</p>
<figure class="highlight applescript"><table><tr><td class="code"><pre><span class="line">npm install -g hexo</span><br><span class="line">cd ~/</span><br><span class="line">hexo init <span class="keyword">my</span>-blog</span><br><span class="line">cd <span class="keyword">my</span>-blog</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">npm install --save hexo-admin</span><br><span class="line">hexo server -d</span><br><span class="line">open http:<span class="regexp">//</span>localhost:<span class="number">4000</span><span class="regexp">/admin/</span></span><br></pre></td></tr></table></figure>
<p><strong>安装报错</strong></p>
<figure class="highlight livescript"><table><tr><td class="code"><pre><span class="line">$ <span class="built_in">npm</span> install --save hexo-admin</span><br><span class="line"><span class="built_in">npm</span> WARN deprecated minimatch@<span class="number">2.0</span>.<span class="number">10</span>: Please update <span class="keyword">to</span> minimatch <span class="number">3.0</span>.<span class="number">2</span> <span class="keyword">or</span> higher <span class="keyword">to</span> avoid a <span class="built_in">RegExp</span> DoS issue</span><br><span class="line">hexo-site@<span class="number">0.0</span>.<span class="number">0</span> E:<span class="string">\git\linjin101.github.io</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">npm</span> WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@^<span class="number">1.0</span>.<span class="number">0</span> (node_modules<span class="string">\chokidar\node_modules\fsevents):</span></span><br><span class="line"><span class="built_in">npm</span> WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform <span class="keyword">for</span> fsevents@<span class="number">1.1</span>.<span class="number">1</span>: wanted &#123;<span class="string">&quot;os&quot;</span>:<span class="string">&quot;darwin&quot;</span>,<span class="string">&quot;arch&quot;</span>:<span class="string">&quot;any&quot;</span>&#125; (current: &#123;<span class="string">&quot;os&quot;</span>:<span class="string">&quot;win32&quot;</span>,<span class="string">&quot;arch&quot;</span>:<span class="string">&quot;x64&quot;</span>&#125;)</span><br></pre></td></tr></table></figure>
<p><strong>解决方法</strong></p>
<figure class="highlight coffeescript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">npm</span> install minimatch@<span class="string">&quot;3.0.2&quot;</span>  </span><br><span class="line"><span class="built_in">npm</span> update -d</span><br></pre></td></tr></table></figure>
<p>升级后依旧报错,重装:</p>
<figure class="highlight coffeescript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">npm</span> update minimatch</span><br><span class="line"><span class="built_in">npm</span> -v minimatch</span><br><span class="line"><span class="built_in">npm</span> install -g <span class="built_in">npm</span>@<span class="number">3</span></span><br></pre></td></tr></table></figure>
<p><strong>访问 Hexo Admin</strong></p>
<p>访问 http://localhost:4000/admin/</p>
<p><strong>hexo deploy 按钮 报错解决</strong> <a href="https://github.com/jaredly/hexo-admin/issues/70">issue</a></p>
<ul>
<li><p>打开 console，进入 hexo 目录，执行语句</p>
<figure class="highlight llvm"><table><tr><td class="code"><pre><span class="line">$ touch hexo-deploy.sh<span class="comment">; chmod a+x hexo-deploy.sh</span></span><br></pre></td></tr></table></figure>
<p>然后 hexo 下自动创建了一个文件 hexo-deploy.sh</p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210508221827.png" /></p></li>
<li><p>打开 hexo-deploy.sh，输入</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env sh</span></span><br><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure></li>
<li><p>编辑 _config.yml，在文件末尾添加</p>
<figure class="highlight jboss-cli"><table><tr><td class="code"><pre><span class="line">admin:</span><br><span class="line">  <span class="keyword">deploy</span>Command: &#x27;<span class="string">./hexo-deploy.sh</span>&#x27;</span><br></pre></td></tr></table></figure></li>
<li><p>重新开启 server，进入 Hexo Admin</p>
<figure class="highlight axapta"><table><tr><td class="code"><pre><span class="line">$ hexo <span class="keyword">server</span> -d</span><br></pre></td></tr></table></figure></li>
<li><p>然后可以😊的进行 deploy 了，✌️✌️✌️</p></li>
</ul>
<h1 id="hexo博客搭建之seo搜索优化">Hexo博客搭建之SEO搜索优化</h1>
<p><strong>启用sitemap功能</strong></p>
<p>为了让博文被google或百度检索，需要使用hexo的sitemap功能。修改themes/next/_config.yml：</p>
<figure class="highlight dts"><table><tr><td class="code"><pre><span class="line"><span class="symbol">menu:</span></span><br><span class="line"><span class="symbol">  home:</span> / || home</span><br><span class="line">  <span class="meta">#about: /about/ || user</span></span><br><span class="line"><span class="symbol">  tags:</span> <span class="meta-keyword">/tags/</span> || tags</span><br><span class="line"><span class="symbol">  categories:</span> <span class="meta-keyword">/categories/</span> || th</span><br><span class="line"><span class="symbol">  archives:</span> <span class="meta-keyword">/archives/</span> || archive</span><br><span class="line">  <span class="meta">#schedule: /schedule/ || calendar</span></span><br><span class="line"><span class="symbol">  sitemap:</span> /sitemap.xml || sitemap</span><br><span class="line">  <span class="meta">#commonweal: /404/ || heartbeat</span></span><br></pre></td></tr></table></figure>
<p><strong>安装插件</strong></p>
<p>切换到hexo根目录下，安装搜索引擎插件，插件根据自己的需要安装其中一个或者都安装：</p>
<figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">npm <span class="keyword">install </span>hexo-generator-sitemap --save</span><br><span class="line">npm <span class="keyword">install </span>hexo-generator-<span class="keyword">baidu-sitemap </span>--save</span><br></pre></td></tr></table></figure>
<p>对于 next 主题，直接执行如下命令即可访问站点地图：</p>
<figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">hexo g</span></span><br></pre></td></tr></table></figure>
<p>此时，在public的静态文件根目录中会多出一个sitemap.xml文件，表示谷歌检索的sitemap安装成功。</p>
<h2 id="谷歌检索"><strong>谷歌检索</strong></h2>
<p>这块在<a href="http://theme-next.iissnan.com/third-party-services.html#google-webmaster-tools">官方文档</a>里面有提到（官方文档其实很容易上手，跟着官方走还是很容易的，有些地方可能不够详细，但是网上关于 next 的配置博客也不少，如<a href="http://fionat.github.io/blog/2013/10/23/sitemap/">｜Hexo 优化｜如何向 google 提交 sitemap（详细）</a>），这里给出傻瓜式详细步骤：</p>
<ol type="1">
<li>在谷歌搜索栏中输入如下信息进行检索：</li>
</ol>
<figure class="highlight avrasm"><table><tr><td class="code"><pre><span class="line"><span class="symbol">site:</span> xxx.github.io</span><br></pre></td></tr></table></figure>
<p>xxx为你的GitHub账号，如果没有被检索，不会显示hexo中的任何博文，如果有下面的步骤就可以省略了。</p>
<ol start="2" type="1">
<li><strong>验证站点</strong></li>
</ol>
<p>需要谷歌账号，没有的可以申请一个。登录<a href="https://www.google.com/webmasters/tools">GoogleSearchConsole</a>，点击立即使用，点击骚红色的”ADD A PROPERTY”，输入需要验证所有权的网站地址，例如本站地址</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">https:<span class="regexp">//</span>jason-huanghao.github.io</span><br></pre></td></tr></table></figure>
<ol start="3" type="1">
<li>对于hexo博客网站，最好使用<strong>HTML tag</strong>法验证网站所有权，在弹出来的小框中加入你的站点地址 <a href="http://yoursite.com/">http://yoursite.com</a> ，然后点击”Continue”Tab 栏选择”Alternate methods”，选中 HTML tag 可以看见</li>
</ol>
<p><strong>千万不要采用修改head.swig文件的方法</strong>，不然在升级 NexT 版本时会遇到很多不必要的麻烦。修改themes/next/_config.yml文件，找到 google_site_verification 字段（找不到就新建）：</p>
<figure class="highlight dts"><table><tr><td class="code"><pre><span class="line"><span class="meta"># Google Webmaster tools verification.</span></span><br><span class="line"><span class="symbol">google_site_verification:</span> verification=G5BgKB47rsdNz1abyiPJS9_1BIclYVpKGUsKVC7GxJg</span><br><span class="line"></span><br><span class="line"><span class="meta">#Sitemap</span></span><br><span class="line"><span class="symbol">Plugins:</span></span><br><span class="line">- hexo-generator-baidu-sitemap</span><br><span class="line">- hexo-generator-sitemap</span><br><span class="line"></span><br><span class="line"><span class="symbol">sitemap:</span> </span><br><span class="line"><span class="symbol">    path:</span> sitemap.xml</span><br><span class="line"><span class="symbol">baidusitemap:</span></span><br><span class="line"><span class="symbol">    path:</span> baidusitemap.xml</span><br></pre></td></tr></table></figure>
<ol start="4" type="1">
<li>然后生成静态文件并发布：</li>
</ol>
<figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">hexo g</span></span><br><span class="line"><span class="attribute">hexo d</span></span><br></pre></td></tr></table></figure>
<ol start="5" type="1">
<li><p>回到 Google Webmaster Central 页面，点击骚红色的”VERIFY”，done！</p></li>
<li><p><strong>添加 sitemap.xml</strong></p></li>
</ol>
<p>打开谷歌控制台选择上一步添加的网站-&gt;<strong>索引</strong>-&gt;<strong>站点地图</strong>，在添加新的站点地图中填入”sitemap.xml”即可，添加成功会在<strong>已提交的站点地图</strong>中显示，过一段时间在<strong>概述</strong>中会显示被索引的情况。</p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210508221842.png" /></p>
<h2 id="百度检索">百度检索</h2>
<p><strong>添加站点</strong></p>
<p>登录<a href="https://ziyuan.baidu.com/">百度资源管理平台</a>，依次点击<strong>用户中心</strong>-&gt;<strong>站点管理</strong>-&gt;<strong>添加网站</strong>（网站会随时更新，路径可能不同，只要找到添加网站的位置就可以）。</p>
<ol type="1">
<li><p>输入网址</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">https<span class="regexp">//</span>eericzeng.github.io</span><br><span class="line"><span class="regexp">//</span>（注意协议头，gitpage在http基础上要加s）</span><br></pre></td></tr></table></figure></li>
<li><p>站点属性 最多可以选择三项，建议相关的都选上，提高曝光度</p></li>
<li><p>验证网站 NexT主题选择<strong>HTML标签验证即可</strong>，复制标签中的content值，修改next配置文件_config.yml：</p>
<figure class="highlight ldif"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Baidu Webmaster tools verification.</span></span><br><span class="line"><span class="comment"># See: https://ziyuan.baidu.com/site</span></span><br><span class="line"><span class="attribute">baidu_site_verification</span>: code-SnIEO2eNeq</span><br><span class="line"><span class="comment"># &lt;meta name=&quot;baidu-site-verification&quot; content=&quot;code-SnIEO2eNeq&quot; /&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Enable baidu push so that the blog will push the url to baidu automatically which is very helpful for SEO.</span></span><br><span class="line"><span class="attribute">baidu_push</span>: ture</span><br></pre></td></tr></table></figure>
<p><strong>baidu 验证只能修改head.swig文件</strong></p>
<p>将 上面设置为 baidu_site_verification: true</p></li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210508221852.png" /></p>
<p>百度资源页面先不要关闭，执行下面的步骤之后再点击<strong>完成验证</strong>。</p>
<p><strong>发布+验证</strong></p>
<p>hexo根目录下执行如下命令：</p>
<figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">hexo g</span></span><br><span class="line"><span class="attribute">hexo d</span></span><br></pre></td></tr></table></figure>
<p>回到百度资源网站，点击<strong>完成验证</strong>。</p>
<h1 id="置顶">置顶</h1>
<p><strong>1 卸载原插件和安装置顶插件</strong></p>
<p>执行下面两行命令：</p>
<figure class="highlight fortran"><table><tr><td class="code"><pre><span class="line">npm uninstall hexo-generator-<span class="built_in">index</span> --<span class="keyword">save</span></span><br><span class="line">npm install hexo-generator-<span class="built_in">index</span>-pin-top --<span class="keyword">save</span></span><br><span class="line">复制代码</span><br></pre></td></tr></table></figure>
<p>在新增文章的开头中加入<strong>top: true</strong>，比如：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">title:</span> <span class="string">Hexo</span> <span class="string">Next主题设置文章置顶</span></span><br><span class="line"><span class="attr">id:</span> <span class="string">a1</span></span><br><span class="line"><span class="attr">date:</span> <span class="number">2020-01-03 17:26:01</span></span><br><span class="line"><span class="attr">categories:</span> <span class="string">Hexo</span></span><br><span class="line"><span class="attr">tags:</span> <span class="string">Next主题</span></span><br><span class="line"><span class="attr">top:</span> <span class="literal">true</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="string">复制代码</span></span><br></pre></td></tr></table></figure>
<p><strong>2 设置置顶标志</strong></p>
<p>打开**theme_macro.swig**</p>
找到
<div class="post-meta">
<p>下面插入一下代码：</p>
<figure class="highlight django"><table><tr><td class="code"><pre><span class="line"><span class="template-tag">&#123;% <span class="name"><span class="name">if</span></span> post.top %&#125;</span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">i</span> <span class="attr">class</span>=<span class="string">&quot;fa fa-thumb-tack&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">i</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">font</span> <span class="attr">color</span>=<span class="string">&quot;RED&quot;</span>&gt;</span>置顶<span class="tag">&lt;/<span class="name">font</span>&gt;</span></span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">&quot;post-meta-divider&quot;</span>&gt;</span>|<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span></span><br><span class="line"><span class="template-tag">&#123;% <span class="name"><span class="name">endif</span></span> %&#125;</span></span><br><span class="line"><span class="xml">复制代码</span></span><br></pre></td></tr></table></figure>
<p>至此，功能已完成。</p>
<h1 id="hexo接入google-adsense广告">Hexo接入Google AdSense广告</h1>
<p><strong>注册账号</strong></p>
<p>Google Adsense 注册账号流程，入口在这里：<a href="https://www.google.com/adsense/">Google Adsense</a></p>
<p><strong>添加 Google 广告代码</strong></p>
<ol type="1">
<li>注册账号完成之后，google会生成一段代码。</li>
<li>需要将谷歌提供给你的一份代码添加到你网站的中，因为我目前是next主题，因此放到 <code>\themes\next\layout\partials\head.swig</code> 任意一个位置 (本人放在了最后) 即可。</li>
</ol>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">data-ad-client</span>=<span class="string">&quot;ca-pub-2691877571661707&quot;</span> <span class="attr">async</span> <span class="attr">src</span>=<span class="string">&quot;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ol start="3" type="1">
<li>在你添加完成之后，<code>hexo gen &amp;&amp; hexo deploy</code> 更新你的网站，点击确认，谷歌会到你的网站上进行核查和验收，一般没问题的话几分钟就会出结果，有问题的话要等待一段时间。</li>
</ol>
<p><strong>Google 广告投放</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210509100945.png" /></p>
<ol type="1">
<li><p>自动广告 (by site)，会根据你的内容精准投放，投放概率低，不推荐</p></li>
<li><p>广告单元 (by ad unit)，这种比较灵活，可以充分利用自己的博客广告位，推荐</p>
<ul>
<li>文字广告和展示广告 (即侧边栏，评论区之类的固定广告位)</li>
<li>信息流广告 (插入在信息流内容的广告位置)</li>
<li>文章内嵌广告 (主要是插入在每篇文章内部的开始，中间，结尾部分，展示次数比较多，强烈推荐)</li>
</ul>
<p>使用了第三种。具体的操作流程是:</p>
<ul>
<li><p>在网站上，选择广告单元-&gt;新建广告位-&gt;选择对应的广告类型-&gt;生成对应的广告代码。</p></li>
<li><p>在themes/next/layout/_custom 下新建 google_adsense.swig 文件，将代码复制过去。</p></li>
<li><p>google_adsense.swig 文件引用位置决定广告展示位置，位置自己决定。</p></li>
<li><p>插入评论区：将代码插入<em>_partials.swig</em> 中的末尾即可</p>
<figure class="highlight dust"><table><tr><td class="code"><pre><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">script</span> <span class="attr">async</span> <span class="attr">src</span>=<span class="string">&quot;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">ins</span> <span class="attr">class</span>=<span class="string">&quot;adsbygoogle&quot;</span></span></span></span><br><span class="line"><span class="xml">     style=&quot;display:block; text-align:center;&quot;</span></span><br><span class="line"><span class="xml">     data-ad-layout=&quot;in-article&quot;</span></span><br><span class="line"><span class="xml">     data-ad-format=&quot;fluid&quot;</span></span><br><span class="line"><span class="xml">     data-ad-client=&quot;ca-pub-9110130131408694&quot;</span></span><br><span class="line"><span class="xml">     data-ad-slot=&quot;6644558881&quot;&gt;<span class="tag">&lt;/<span class="name">ins</span>&gt;</span></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">script</span>&gt;</span></span></span><br><span class="line"><span class="xml">     (adsbygoogle = window.adsbygoogle || []).push(</span><span class="template-variable">&#123;&#125;</span><span class="xml">);</span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br></pre></td></tr></table></figure></li>
<li><p>hexo deploy代码到github pages上，可能需要20-30分钟广告才会显示在网页上。我的很快，基本1-2分钟就显示了。</p></li>
</ul></li>
</ol>
<h1 id="音频">音频</h1>
<p>参考 https://leezhiy.github.io</p>
<h2 id="使用-hexo-tag-aplayer-插件">使用 hexo-tag-aplayer 插件</h2>
<p><a href="https://github.com/MoePlayer/hexo-tag-aplayer">hexo-tag-aplayer</a> 就是将 <a href="https://github.com/DIYgod/APlayer">APlayer</a> 内嵌入博客页面的 Hexo 插件。</p>
<p>安装执行：</p>
<figure class="highlight ada"><table><tr><td class="code"><pre><span class="line">$ npm install <span class="comment">--save hexo-tag-aplayer</span></span><br></pre></td></tr></table></figure>
<p>原先 <code>hexo-tag-aplayer</code> 不支持 <code>MetingJS</code>，使得需要图片 url，音乐 url 等等参数，操作起来都很麻烦，需要去音乐网站扒音乐播放链接或者下载下来存储在七牛云或本地，要了解具体参数和使用可以查看其<a href="https://github.com/MoePlayer/hexo-tag-aplayer/blob/master/docs/README-zh_cn.md">中文文档</a>了解。</p>
<h2 id="meingjs-支持-3.0-新功能">MeingJS 支持 (3.0 新功能)</h2>
<p><a href="https://github.com/metowolf/MetingJS">MetingJS</a> 是基于 <a href="https://github.com/metowolf/Meting">Meting API</a> 的 APlayer 衍生播放器，引入 MetingJS 后，播放器将支持对于 QQ 音乐、网易云音乐、虾米、酷狗、百度等平台的音乐播放。</p>
<p>如果想在本插件中使用 MetingJS，请在 Hexo 配置文件 <code>_config.yml</code> 中设置：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">aplayer:</span></span><br><span class="line">  <span class="attr">meting:</span> <span class="literal">true</span>                                  <span class="comment"># Meting support, default: false</span></span><br></pre></td></tr></table></figure>
<p>接着就可以 在<strong>文章</strong>中使用 MetingJS 播放器了，例如打开网易云音乐网站找一个歌单，例如： https://music.163.com/#/playlist?id=3136952023， 这个歌单的 id 就是 3136952023，按下面格式即可使用：</p>
<figure class="highlight clojure"><table><tr><td class="code"><pre><span class="line">&#123;% meting <span class="string">&quot;3136952023&quot;</span> <span class="string">&quot;netease&quot;</span> <span class="string">&quot;playlist&quot;</span> <span class="string">&quot;theme:#FF4081&quot;</span> <span class="string">&quot;mode:circulation&quot;</span> <span class="string">&quot;mutex:true&quot;</span> <span class="string">&quot;listmaxheight:340px&quot;</span> <span class="string">&quot;preload:auto&quot;</span> %&#125;</span><br></pre></td></tr></table></figure>
<h2 id="全局音乐插件">全局音乐插件</h2>
<p>如果想在非 Post 页面使用插件功能，直接使用上面的方法修改 layout 的话会报以下错误</p>
<figure class="highlight subunit"><table><tr><td class="code"><pre><span class="line"><span class="keyword">Error: </span>Unexpected tag &quot;meting&quot;</span><br></pre></td></tr></table></figure>
<p>所以我们只能使用另一种办法，创建 <code>Hexo/source/_data/APlayer.swig</code> 文件，添加以下内容。</p>
<figure class="highlight handlebars"><table><tr><td class="code"><pre><span class="line"><span class="xml">&#123;% if aplayer.enabled %&#125;</span></span><br><span class="line"><span class="xml">  <span class="comment">&lt;!-- require APlayer --&gt;</span></span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span> <span class="attr">href</span>=<span class="string">&quot;</span></span></span><span class="template-variable">&#123;&#123;<span class="name">aplayer.cdn.css</span>&#125;&#125;</span><span class="xml"><span class="tag"><span class="string">&quot;</span>&gt;</span></span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;</span></span></span><span class="template-variable">&#123;&#123;<span class="name">aplayer.cdn.js</span>&#125;&#125;</span><span class="xml"><span class="tag"><span class="string">&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br><span class="line"><span class="xml">  <span class="comment">&lt;!-- require MetingJS --&gt;</span></span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;</span></span></span><span class="template-variable">&#123;&#123;<span class="name">aplayer.cdn.meting</span>&#125;&#125;</span><span class="xml"><span class="tag"><span class="string">&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br><span class="line"><span class="xml">  &lt;meting-js</span></span><br><span class="line"><span class="xml">    server=&quot;</span><span class="template-variable">&#123;&#123;<span class="name">aplayer.server</span>&#125;&#125;</span><span class="xml">&quot;</span></span><br><span class="line"><span class="xml">    type=&quot;</span><span class="template-variable">&#123;&#123;<span class="name">aplayer.type</span>&#125;&#125;</span><span class="xml">&quot;</span></span><br><span class="line"><span class="xml">    fixed=&quot;</span><span class="template-variable">&#123;&#123;<span class="name">aplayer.fixed</span>&#125;&#125;</span><span class="xml">&quot;</span></span><br><span class="line"><span class="xml">    id=&quot;</span><span class="template-variable">&#123;&#123;<span class="name">aplayer.id</span>&#125;&#125;</span><span class="xml">&quot;</span></span><br><span class="line"><span class="xml">    auto=&quot;</span><span class="template-variable">&#123;&#123;<span class="name">aplayer.auto</span>&#125;&#125;</span><span class="xml">&quot;</span></span><br><span class="line"><span class="xml">    mini=&quot;</span><span class="template-variable">&#123;&#123;<span class="name">aplayer.mini</span>&#125;&#125;</span><span class="xml">&quot;</span></span><br><span class="line"><span class="xml">    autoplay=&quot;</span><span class="template-variable">&#123;&#123;<span class="name">aplayer.autoplay</span>&#125;&#125;</span><span class="xml">&quot;</span></span><br><span class="line"><span class="xml">    theme=&quot;</span><span class="template-variable">&#123;&#123;<span class="name">aplayer.theme</span>&#125;&#125;</span><span class="xml">&quot;</span></span><br><span class="line"><span class="xml">    loop=&quot;</span><span class="template-variable">&#123;&#123;<span class="name">aplayer.loop</span>&#125;&#125;</span><span class="xml">&quot;</span></span><br><span class="line"><span class="xml">    order=&quot;</span><span class="template-variable">&#123;&#123;<span class="name">aplayer.order</span>&#125;&#125;</span><span class="xml">&quot;</span></span><br><span class="line"><span class="xml">    preload=&quot;</span><span class="template-variable">&#123;&#123;<span class="name">aplayer.preload</span>&#125;&#125;</span><span class="xml">&quot;</span></span><br><span class="line"><span class="xml">    volume=&quot;</span><span class="template-variable">&#123;&#123;<span class="name">aplayer.volume</span>&#125;&#125;</span><span class="xml">&quot;</span></span><br><span class="line"><span class="xml">    mutex=&quot;</span><span class="template-variable">&#123;&#123;<span class="name">aplayer.mutex</span>&#125;&#125;</span><span class="xml">&quot;</span></span><br><span class="line"><span class="xml">    list-folded=&quot;</span><span class="template-variable">&#123;&#123;<span class="name">aplayer.listfolded</span>&#125;&#125;</span><span class="xml">&quot;</span></span><br><span class="line"><span class="xml">    list-max-height=&quot;</span><span class="template-variable">&#123;&#123;<span class="name">aplayer.listmaxheight</span>&#125;&#125;</span><span class="xml">&quot;</span></span><br><span class="line"><span class="xml">    storage-name=&quot;</span><span class="template-variable">&#123;&#123;<span class="name">aplayer.storagename</span>&#125;&#125;</span><span class="xml">&quot; &gt;</span></span><br><span class="line"><span class="xml">  <span class="tag">&lt;/<span class="name">meting-js</span>&gt;</span></span></span><br><span class="line"><span class="xml">&#123;% endif %&#125;</span></span><br></pre></td></tr></table></figure>
<p>接着打开 hexo/themes/next/_config.yml主题配置文件 ，在最底部添加</p>
<figure class="highlight vala"><table><tr><td class="code"><pre><span class="line"><span class="meta"># --------------------------------------------------------------</span></span><br><span class="line"><span class="meta"># APlayer settings</span></span><br><span class="line"><span class="meta"># --------------------------------------------------------------</span></span><br><span class="line"><span class="meta"># enabled:  true/false   开启/关闭</span></span><br><span class="line"><span class="meta"># id: song id / playlist id / album id / search keyword   歌曲ID、歌单ID、关键字</span></span><br><span class="line"><span class="meta"># server: netease, tencent, kugou, xiami, baidu     音乐平台</span></span><br><span class="line"><span class="meta"># type: song, playlist, album, search, artist  类型</span></span><br><span class="line"><span class="meta"># auto: music link, support: netease, tencent, xiami</span></span><br><span class="line"><span class="meta"># fixed: true/false   吸底模式</span></span><br><span class="line"><span class="meta"># mini: true/false   迷你模式</span></span><br><span class="line"><span class="meta"># autoplay: true/false   自动播放</span></span><br><span class="line"><span class="meta"># theme: #eeeeee 主题颜色</span></span><br><span class="line"><span class="meta"># loop: values: &#x27;all&#x27;, &#x27;one&#x27;, &#x27;none&#x27; 循环播放</span></span><br><span class="line"><span class="meta"># order: values: &#x27;list&#x27;, &#x27;random&#x27; 是否随机播放</span></span><br><span class="line"><span class="meta"># preload: values: &#x27;none&#x27;, &#x27;metadata&#x27;, &#x27;auto&#x27; 预载入</span></span><br><span class="line"><span class="meta"># volume:	0.7	默认音量，请注意播放器会记忆用户设置，用户手动设置音量后默认音量即失效</span></span><br><span class="line"><span class="meta"># mutex: true/false	互斥，阻止多个播放器同时播放，当前播放器播放时暂停其他播放器</span></span><br><span class="line"><span class="meta"># list-folded:	true/false	列表默认折叠</span></span><br><span class="line"><span class="meta"># list-max-height:	340px	列表最大高度</span></span><br><span class="line"><span class="meta"># storage-name:	metingjs	存储播放器设置的 localStorage key</span></span><br><span class="line">aplayer:</span><br><span class="line">  enabled: <span class="literal">true</span></span><br><span class="line">  id: <span class="number">3099335800</span></span><br><span class="line">  server: netease</span><br><span class="line">  type: playlist</span><br><span class="line">  auto:</span><br><span class="line">  fixed: <span class="literal">true</span></span><br><span class="line">  mini: <span class="literal">true</span></span><br><span class="line">  autoplay: <span class="literal">true</span></span><br><span class="line">  theme: #<span class="number">607</span>d8b</span><br><span class="line">  loop: <span class="string">&#x27;all&#x27;</span></span><br><span class="line">  order: <span class="string">&#x27;random&#x27;</span></span><br><span class="line">  preload: <span class="string">&#x27;auto&#x27;</span></span><br><span class="line">  volume: <span class="number">0.7</span></span><br><span class="line">  mutex: <span class="literal">true</span></span><br><span class="line">  listfolded: <span class="literal">true</span></span><br><span class="line">  listmaxheight: <span class="number">340</span>px</span><br><span class="line">  storagename: metingjs</span><br><span class="line">  cdn:</span><br><span class="line">    css: https:<span class="comment">//cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css</span></span><br><span class="line">    js: https:<span class="comment">//cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js</span></span><br><span class="line">    meting: https:<span class="comment">//cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js</span></span><br></pre></td></tr></table></figure>
<p>打开 <code>hexo/scripts/plugins.js</code>, 在 head 注入点<a href="https://theme-next.org/docs/advanced-settings">注入</a> APlayer</p>
<figure class="highlight actionscript"><table><tr><td class="code"><pre><span class="line">hexo.extend.filter.register(<span class="string">&#x27;theme_inject&#x27;</span>, <span class="function"><span class="keyword">function</span> <span class="params">(injects)</span> </span>&#123;</span><br><span class="line">  .</span><br><span class="line">  .</span><br><span class="line">  .</span><br><span class="line">  <span class="comment">// 引入 APlayer</span></span><br><span class="line">  injects.head.file(<span class="string">&#x27;aplayer&#x27;</span>, <span class="string">&#x27;source/_data/APlayer.swig&#x27;</span>, &#123;aplayer: hexo.theme.config.aplayer&#125;);</span><br><span class="line">  .</span><br><span class="line">  .</span><br><span class="line">  .</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>最后是 MetingJs 的参数详情：</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">参数名</th>
<th style="text-align: left;">默认</th>
<th style="text-align: left;">description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">id</td>
<td style="text-align: left;">require</td>
<td style="text-align: left;">歌曲 ID / 播放列表 ID / 专辑 ID / 搜索关键字</td>
</tr>
<tr class="even">
<td style="text-align: left;">server</td>
<td style="text-align: left;">require</td>
<td style="text-align: left;">音乐平台，可选值： ‘netease’，’tencent’，’kugou’，’xiami’，’baidu’</td>
</tr>
<tr class="odd">
<td style="text-align: left;">type</td>
<td style="text-align: left;">require</td>
<td style="text-align: left;">类型，可选值：’song’, ‘playlist’, ‘album’, ‘search’, ‘artist’</td>
</tr>
<tr class="even">
<td style="text-align: left;">auto</td>
<td style="text-align: left;">options</td>
<td style="text-align: left;">音乐链接，支持： ‘netease’, ‘tencent’, ‘xiami’</td>
</tr>
<tr class="odd">
<td style="text-align: left;">fixed</td>
<td style="text-align: left;">false</td>
<td style="text-align: left;">开启吸底模式，<a href="https://aplayer.js.org/#/home?id=fixed-mode">详情</a></td>
</tr>
<tr class="even">
<td style="text-align: left;">mini</td>
<td style="text-align: left;">false</td>
<td style="text-align: left;">开启迷你模式，<a href="https://aplayer.js.org/#/home?id=mini-mode">详情</a></td>
</tr>
<tr class="odd">
<td style="text-align: left;">autoplay</td>
<td style="text-align: left;">false</td>
<td style="text-align: left;">音频自动播放</td>
</tr>
<tr class="even">
<td style="text-align: left;">theme</td>
<td style="text-align: left;">#2980b9</td>
<td style="text-align: left;">主题色</td>
</tr>
<tr class="odd">
<td style="text-align: left;">loop</td>
<td style="text-align: left;">all</td>
<td style="text-align: left;">音频循环播放，可选值: ‘all’, ‘one’, ‘none’</td>
</tr>
<tr class="even">
<td style="text-align: left;">order</td>
<td style="text-align: left;">list</td>
<td style="text-align: left;">音频循环顺序，可选值: ‘list’, ‘random’</td>
</tr>
<tr class="odd">
<td style="text-align: left;">preload</td>
<td style="text-align: left;">auto</td>
<td style="text-align: left;">预加载，可选值: ‘none’, ‘metadata’, ‘auto’</td>
</tr>
<tr class="even">
<td style="text-align: left;">volume</td>
<td style="text-align: left;">0.7</td>
<td style="text-align: left;">默认音量，请注意播放器会记忆用户设置，用户手动设置音量后默认音量即失效</td>
</tr>
<tr class="odd">
<td style="text-align: left;">mutex</td>
<td style="text-align: left;">true</td>
<td style="text-align: left;">互斥，阻止多个播放器同时播放，当前播放器播放时暂停其他播放器</td>
</tr>
<tr class="even">
<td style="text-align: left;">lrc-type</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;"><a href="https://aplayer.js.org/#/home?id=lrc">详情</a></td>
</tr>
<tr class="odd">
<td style="text-align: left;">list-folded</td>
<td style="text-align: left;">false</td>
<td style="text-align: left;">列表默认折叠</td>
</tr>
<tr class="even">
<td style="text-align: left;">list-max-height</td>
<td style="text-align: left;">340px</td>
<td style="text-align: left;">列表最大高度</td>
</tr>
<tr class="odd">
<td style="text-align: left;">storage-name</td>
<td style="text-align: left;">metingjs</td>
<td style="text-align: left;">存储播放器设置的 localStorage key</td>
</tr>
</tbody>
</table>
<h1 id="图片">图片</h1>
<h1 id="视频">视频</h1>
<h1 id="打赏功能">打赏功能</h1>
<h1 id="rss-订阅设置">RSS 订阅设置</h1>
<h1 id="参考-references">参考 (References)</h1>
]]></content>
      <categories>
        <category>Blog Building</category>
      </categories>
  </entry>
  <entry>
    <title>next博客入门设置</title>
    <url>/2021/05/09/Blog%20Building/next%E5%8D%9A%E5%AE%A2%E5%85%A5%E9%97%A8%E8%AE%BE%E7%BD%AE/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="install-hexo">Install hexo</h1>
<p>安装完成后，需要安装hexo：</p>
<figure class="highlight stata"><table><tr><td class="code"><pre><span class="line">sudo <span class="keyword">su</span></span><br><span class="line"># <span class="keyword">input</span> password</span><br><span class="line">npm install -<span class="keyword">g</span> hexo-<span class="keyword">cli</span></span><br></pre></td></tr></table></figure>
<span id="more"></span>
<figure class="highlight ada"><table><tr><td class="code"><pre><span class="line">npm install hexo <span class="comment">--save</span></span><br><span class="line">npm install hexo-deployer-git <span class="comment">--save</span></span><br><span class="line">npm install hexo-renderer-marked <span class="comment">--save</span></span><br><span class="line">npm install hexo-renderer-pandoc <span class="comment">--save</span></span><br><span class="line"></span><br><span class="line">如果出问题的话，可以尝试更换渲染工具为 hexo-renderer-pandoc：</span><br><span class="line">npm uninstall hexo-renderer-marked <span class="comment">--save</span></span><br><span class="line">npm install hexo-renderer-pandoc <span class="comment">--save</span></span><br></pre></td></tr></table></figure>
<p>建站</p>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line">hexo <span class="keyword">init</span></span><br></pre></td></tr></table></figure>
<p>安装依赖包：</p>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">npm <span class="keyword">install</span></span><br></pre></td></tr></table></figure>
<p>安装一下hexo-deployer-git</p>
<figure class="highlight ada"><table><tr><td class="code"><pre><span class="line">npm install hexo-deployer-git <span class="comment">--save</span></span><br><span class="line">git init</span><br></pre></td></tr></table></figure>
<h1 id="hexo-使用自定义模板">Hexo 使用自定义模板</h1>
<ol type="1">
<li>新建命令行</li>
</ol>
<figure class="highlight gauss"><table><tr><td class="code"><pre><span class="line">hexo <span class="keyword">new</span> [layout] &lt;<span class="built_in">title</span>&gt;</span><br></pre></td></tr></table></figure>
<ol type="1">
<li><p>Layout 介绍</p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210508221258.png" /></p>
<ul>
<li>post: saved in source/_posts (public)</li>
<li>page: saved in source</li>
<li>draft: saved in source/_drafts (private)</li>
<li>self-defined layout: saved in source/_posts (public)</li>
</ul></li>
<li><p>自定义模板</p>
<ul>
<li><p>用户自定义模板在 scaffolds 文件夹中，比如 “self-module.md”</p></li>
<li><p>命令行如下 <figure class="highlight monkey"><table><tr><td class="code"><pre><span class="line">hexo <span class="keyword">new</span> <span class="built_in">self</span>-<span class="keyword">module</span> 【<span class="keyword">module</span> name】</span><br></pre></td></tr></table></figure></p></li>
<li><p>模板内容，以后可以通过 <code>next new self-module [blog name]</code> 就可以以这个模板初始你的博文内容如下 <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210509111020.png" /></p></li>
</ul></li>
</ol>
<h1 id="hexo-免密部署-hexo-deploy">Hexo 免密部署 (hexo deploy)</h1>
<p><strong>生成 SSH 秘钥</strong></p>
<figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line">$ cd ~/.ssh</span><br><span class="line"></span><br><span class="line">ssh-keygen -t rsa -C <span class="string">&quot;[your_email@example.com]&quot;</span></span><br><span class="line"># Creates a <span class="keyword">new</span> ssh key using the provided email</span><br><span class="line">Generating <span class="keyword">public</span>/<span class="keyword">private</span> rsa key pair.</span><br><span class="line">Enter <span class="keyword">file</span> in which to save the key (<span class="regexp">/home/y</span>ou<span class="regexp">/.ssh/i</span>d_rsa):</span><br></pre></td></tr></table></figure>
<p>将整个 [your_email@example.com] 替换成你们的 github 账户注册邮箱</p>
<p><strong>提示输入密码</strong></p>
<p>直接 enter 键，也可以设置 ssh 的密码，以后 deploy 的时候每次也需要使用这个密码，建议直接 enter (用enter 替代 [Type a passphrase])</p>
<figure class="highlight ada"><table><tr><td class="code"><pre><span class="line">Enter passphrase (empty <span class="keyword">for</span> no passphrase): [<span class="keyword">Type</span> <span class="type">a </span>passphrase]Enter same passphrase again: [<span class="keyword">Type</span> <span class="type">passphrase </span>again]</span><br></pre></td></tr></table></figure>
<p><strong>秘钥生成成功</strong></p>
<figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line">Your identification has been saved in <span class="regexp">/home/y</span>ou<span class="regexp">/.ssh/i</span>d_rsa.Your <span class="keyword">public</span> key has been saved in <span class="regexp">/home/y</span>ou<span class="regexp">/.ssh/i</span>d_rsa.pub.The key fingerprint is:…………………此处是密钥内容…………………… your_email@example.com</span><br></pre></td></tr></table></figure>
<p><strong>复制秘钥至你的 GitHub 账户</strong></p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">vim <span class="selector-tag">i</span></span><br></pre></td></tr></table></figure>
<p>将文件 “id_rsa.pub” 所有的内容复制出来粘贴到</p>
<p>在 <code>jason-huanghao.github.io</code> 的首页菜单栏中点击 Settings --&gt; Deploy keys --&gt; Add deploy key，然后将生成的 <code>id_rsa.pub</code> 中的内容全选复制到 key 输入框中，然后点击 Add key 完成添加公钥</p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210508221421.png" /></p>
<p><strong>测试是否成功</strong></p>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line">ssh -T <span class="symbol">git@</span>github.com</span><br></pre></td></tr></table></figure>
<p>收到下面提示，则配置成功</p>
<figure class="highlight ada"><table><tr><td class="code"><pre><span class="line">Hi username! You<span class="symbol">&#x27;ve</span> successfully authenticated, but GitHub does <span class="keyword">not</span> provide shell <span class="keyword">access</span>.</span><br></pre></td></tr></table></figure>
<p>**配置hexo/_config.yml**</p>
<p>打开 <code>Hexo</code> 的配置文件 <code>_config.yml</code> ，把 <code>deploy</code> 下的 <code>repo</code> 改为</p>
<figure class="highlight vim"><table><tr><td class="code"><pre><span class="line"># Deployment## Doc<span class="variable">s:</span> http<span class="variable">s:</span>//hexo.io/docs/one-<span class="keyword">command</span>-deploymentdeploy:  <span class="built_in">type</span>: git  repo: git@github.<span class="keyword">com</span>:jason-huanghao/jason-huanghao.github.io.git  branch: master</span><br></pre></td></tr></table></figure>
<h1 id="hexo-命令详解">Hexo 命令详解</h1>
<ol type="1">
<li><p>hexo init [folder] 这个命令是 Hexo 初始化命令。[folder] 表示你要初始化的文件夹。如果你要初始化本地，直接 hexo init . 。</p></li>
<li><p>hexo new [layout] 这个命令是新建文章或页面用的命令。其中 [layout] 表示他的模板（即页面或者文章），表示标题。</p>
<p>用法：</p>
<p>hexo new post 001 ，表示新建了一个标题为 001 的文章。 hexo new page 001 ，表示新建了一个标题为 001 的页面。 如果你不想在终端中新建文章或页面，可以直接在 博客根目录/source/_post/ 目录下创建 Markdown 文件写文章。或者在 博客根目录/source/ 目录下创建一个文件夹，然后在新文件夹里创建 index.md 写页面即可。</p>
<p>:::tip 提醒</p>
<p>当你新建页面后，页面的链接就是你页面所在的文件夹的名字。</p>
<p>例如：我在 博客根目录/source/ 下新建了一个名为 test 的文件夹，然后在 test 文件夹下写 Markdown 文件，那么这个页面的链接就是 网址/test。</p></li>
<li><p>hexo server 当你要在本地查看网站的时候，就可以用这个命令。</p>
<p>默认在 http://localhost:8080/ 这里，可能会不同，注意提示信息即可。</p>
<p>:::tip 提醒</p>
<p>如果你想要换端口号（上面的 8080 就是端口号），可以在终端里输入 hexo s -p 端口号。</p>
<p>如果遇到端口占用，在hexo/_config.yml 中添加下面语句修改 hexo 启动端口号</p>
<figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">server</span>:  port: <span class="number">4001</span>  compress: <span class="keyword">true</span>  <span class="keyword">header</span>: <span class="keyword">true</span></span><br></pre></td></tr></table></figure></li>
<li><p>hexo generate 这个命令是生成网站静态文件的时候用的，生成后网页将会放在根目录下面的 public 文件夹里。</p></li>
<li><p>hexo deploy 这个命令用来部署网站，使用此命令将会把生成好的页面（即 public 文件夹里的内容）部署到指定的地方上。</p></li>
<li><p>hexo clean 这个命令用来清空 public 文件夹。</p></li>
<li><p>hexo version 这个命令用来输出你所使用的 Hexo 目前的版本号。</p></li>
<li><p>部署本地文件到GitHub上</p>
<figure class="highlight 1c"><table><tr><td class="code"><pre><span class="line">$ hexo clean <span class="meta">&amp;&amp; hexo d -g</span></span><br></pre></td></tr></table></figure></li>
<li><p>Hexo -v 查看 hexo 版本</p></li>
</ol>
<h1 id="next-主题使用">Next 主题使用</h1>
<p><strong>下载 Next 主题</strong></p>
<p>cd themes 文件夹</p>
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">git clone https:<span class="regexp">//gi</span>thub.com<span class="regexp">/iissnan/</span>hexo-theme-<span class="keyword">next</span></span><br></pre></td></tr></table></figure>
<p><strong>修改 theme</strong></p>
<p>编辑 hexo/_config.yml，找到 theme 那一行配置，修改为 next</p>
<p><strong>添加“分类”，“关于”和“标签”菜单</strong></p>
<p><strong>打开 tags，about，categories</strong></p>
<p>在主题配置文件 next/_config.yml 在 menu 下去掉 tags，about，categories 注释。 注意这里“主题配置文件”指的是 themes/next 目录的下的 _config.yml。</p>
<p><strong>创建 tags，about，categories</strong></p>
<p>在 hexo 文件夹</p>
<figure class="highlight haxe"><table><tr><td class="code"><pre><span class="line">hexo <span class="keyword">new</span> <span class="type">page</span> tags</span><br></pre></td></tr></table></figure>
<p>会在 source 文件夹生成 tags 文件夹，编辑里面的 index.md ，添加</p>
<figure class="highlight ada"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span>: <span class="string">&quot;tags&quot;</span>comments: <span class="literal">false</span></span><br></pre></td></tr></table></figure>
<p>同样的方法添加 categories； 添加 about 不需要修改 md 文件的 type，因为 tags，categories 是特殊目录类型，about 只是简单的一个 md。</p>
<h1 id="参考-references">参考 (References)</h1>
<ol type="1">
<li>https://www.youtube.com/watch?v=erKYtw4Rfhk</li>
</ol>
]]></content>
      <categories>
        <category>Blog Building</category>
      </categories>
      <tags>
        <tag>博客</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>博客域名绑定</title>
    <url>/2021/05/16/Blog%20Building/%E5%8D%9A%E5%AE%A2%E5%9F%9F%E5%90%8D%E7%BB%91%E5%AE%9A/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="namesilo-域名注册平台介绍">Namesilo 域名注册平台介绍</h1>
<p>去<a href="https://www.namesilo.com">namesilo</a>官网查找到自己满意的域名，价格都有标注。一些冷门域名后缀第一年比较便宜，续费可能会比较贵(注意关注Renewal后面的价格，这是续费的价格)，比如我搜索 "hao1234" 这个域名，“hao1234.buzz”虽然便宜，但是续费需要27.99刀每年 (简直贵出天际) 。一般的.com顶级域名价格是$8.99，且目前续费不涨价，挺划算的。相比其他平台价格很美丽，访问速度也还行，老牌的域名销售平台了。 <span id="more"></span> 在首页根据关键词搜素你感兴趣的域名，点击 “Add” 添加你心仪的域名。 <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210516152110.png" /></p>
<h1 id="namesilo-域名购买">Namesilo 域名购买</h1>
<ol type="1">
<li>注册账号 <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210516152456.png" /></li>
<li>完善个人信息，必须项，等你购买域名时也会要求填信息，其中蓝色标 * 项为必填项 <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210516152624.png" /></li>
<li>选择好了之后购买域名，注意可以选择是否自动续费，把隐私保护项选起来(有些平台隐私保护还要单独收费，Namesilo可谓良心了) <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210516152747.png" /></li>
<li>支付支持非常多，可以支付宝，微信，我选择微信支付。 <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210516152956.png" /></li>
</ol>
<h1 id="域名配置">域名配置</h1>
<ol type="1">
<li><p>点击个人账户右上角的 “Manage My Domains”，自己购买的域名的蓝色按钮来配置自己的域名 <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210516153512.png" /></p></li>
<li><p>添加 A 记录，IP地址通过 <code>ping yourusername.github.io</code> 得到，这就是你的github部署的博客的IP地址，改 TTL 为3600 <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210516153632.png" /></p></li>
<li><p>添加 CNAME 记录，添加一条 CNAME，实现绑定你的域名和你的github博客 <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210516153850.png" /></p></li>
<li><p>到你的本地博客目录添加一个不带后缀的文件 <code>hexo/source/CNAME</code>，在其中输入你后买的域名，比如我购买的是 “jason-hao.cyou”，那么就把它输入这个文件中，最后重新生成部署下 hexo <code>hexo gen &amp;&amp; hexo d</code>.</p></li>
<li><p>令你的域名网站支持 <code>https</code> 进入你的github博客仓库（不是bolg网址）, 然后 <code>Settings-&gt;Pages-&gt;Enforce HTTPS</code> <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210516154750.png" /></p></li>
<li><p>最后一步，添加你的新域名到 Goolge 检索 进入 <a href="https://search.google.com/search-console">Google Search Console</a>，左上角 <code>Add property</code> 添加你注册的新域名比如 <code>hao1234.buzz</code>， <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210516155153.png" /></p></li>
</ol>
<p>复制 Google 给的验证字段 <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210516155232.png" /></p>
<p>粘贴到你的 Namessilo 注册的域名下，进入域名配置页面，按如下操作。TEXT 就是上一步复制的 Google 验证字段 <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210516155649.png" /></p>
<p>回到 <a href="https://search.google.com/search-console">Google Search Console</a>，继续验证 <code>VERIFY</code>，这一步可能失败，一般域名解析需要时间，大概等个半天一天就可以了 <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210516155935.png" /></p>
<h1 id="参考-references">参考 (References)</h1>
<ol type="1">
<li>https://ftzzloo.com/github-pages-and-domain-name-setting/</li>
<li>https://juejin.cn/post/6844903477051654152</li>
</ol>
]]></content>
      <categories>
        <category>Blog Building</category>
      </categories>
      <tags>
        <tag>博客</tag>
        <tag>域名</tag>
      </tags>
  </entry>
  <entry>
    <title>Back Propagation</title>
    <url>/2021/07/13/Deep%20Learning/Back-Propagation/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><span id="more"></span>
<h1 id="references">References</h1>
<ol type="1">
<li>http://galaxy.agh.edu.pl/~vlsi/AI/backp_t_en/backprop.html</li>
</ol>
]]></content>
      <tags>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>GNN Note</title>
    <url>/2021/06/20/Deep%20Learning/GNN-Note/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="why-need-gnn">Why need GNN</h1>
<ol type="1">
<li>utilize the structure and relationship of data (CNN cannot deal with non-Euclidean space)</li>
<li>semi-supervised learning (partial labels)</li>
</ol>
<span id="more"></span>
<h1 id="how-to-embed-node-into-a-feature-space-using-convolution">How to Embed node into a feature space using convolution?</h1>
<p>Suppose a graph <span class="math inline">\(G=\{V, E\}\)</span>, <span class="math inline">\(V\)</span> is a set of <span class="math inline">\(N=|V|\)</span> nodes, <span class="math inline">\(E\subseteq V\times V\)</span> is a set of edges between nodes. There are two different groups of GNN:</p>
<ol type="1">
<li>Generalize convolution into Graph: Spatial-based Convolution</li>
<li>Back into signal processing: Spectral-based Convolution</li>
</ol>
<h1 id="spatial-based-convolution">1. Spatial-based Convolution</h1>
<p>Two important problem to be solved:</p>
<ol type="1">
<li>Aggreation: how to update the next hidden sate by using neighbor's information</li>
<li>Readout: how to represent graph using features from all nodes</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210621200951.png" /></p>
<h2 id="nn4g">NN4G</h2>
<p><a href="https://ieeexplore.ieee.org/document/4773279">reference paper</a></p>
<p><strong>Aggregate</strong> by sum</p>
<ol type="1">
<li><p>from input layer to <span class="math inline">\(0_{th}\)</span> hidden layer</p>
<p><span class="math inline">\(h_{n}^0=x_n \cdot w_n, n \in [1,2...,N]\)</span></p></li>
<li><p>from hidden layer <span class="math inline">\(k\)</span> to hidden layer <span class="math inline">\(k+1\)</span></p>
<p><span class="math inline">\(h_n^{k+1}=w_n^{k,k+1}\cdot \sum_{v\in \mathcal{N}(h_n^k)}h_v^k\)</span></p>
<p>where <span class="math inline">\(\mathcal{N}(x)\)</span> is all neighbors of <span class="math inline">\(x\)</span></p></li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210621203710.png" /></p>
<p><strong>Readout</strong></p>
<p><span class="math inline">\(y=\sum_{k=0}^K{w_k}^T(mean(h^k)), h^k=[h_0^k,...,h_N^k]\)</span> <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210621203834.png" /></p>
<h2 id="dcnn">DCNN</h2>
<p><a href="https://arxiv.org/abs/1511.02136">reference paper</a></p>
<p><strong>Aggregate</strong> by mean</p>
<ol type="1">
<li><p>from input layer to <span class="math inline">\(0_{th}\)</span> hidden layer (the same as NN4G)</p>
<p><span class="math inline">\(h_{n}^0=x_n \cdot w_n, n \in [1,2...,N]\)</span></p></li>
<li><p>from hidden layer <span class="math inline">\(k\)</span> to hidden layer <span class="math inline">\(k+1\)</span></p>
<p><span class="math inline">\(h_n^{k+1}=w_n^{k,k+1} Mean(h_{d(n,.)=k+1}^k)\)</span>, <span class="math inline">\(d(n,.)=k+1\)</span> is these nodes that has a distance of <span class="math inline">\(k+1\)</span> to node <span class="math inline">\(n\)</span></p></li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210621203428.png" /></p>
<p><strong>Readout</strong></p>
<p><span class="math inline">\(y_n=[h_n^0,h_n^1,...,h_n^K]^T W\)</span></p>
<p>the feature of a node <span class="math inline">\(v_1\)</span> is <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210621204309.png" /></p>
<h2 id="dgc">DGC</h2>
<p><a href="https://arxiv.org/pdf/1707.01926.pdf">reference paper ICLR 2018</a></p>
<p><strong>Aggregate</strong> by mean</p>
<p>similar to DCNN</p>
<p><strong>Readout</strong></p>
<p>the feature of each node is directly sum over multiple hideen sates <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210621204924.png" /></p>
<h2 id="monet">MoNET</h2>
<p><a href="https://arxiv.org/pdf/1611.08402.pdf">reference paper</a></p>
<p><strong>Aggregate</strong> by weighted sum</p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210622105032.png" /> <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210621210209.png" /></p>
<p><span class="math inline">\(D_j(x)f=\sum_{y\in\mathcal{N}(x)}w_j(u(x,y))f(y),j=1,...,J\)</span></p>
<p><span class="math inline">\((f*g)(x)-\sum_{j=1}^Jg_j D_j(x)f\)</span></p>
<p>where <span class="math inline">\(u(x,y)\)</span> is used for measuring distance between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, but it is a <span class="math inline">\(d\)</span>-dementional vector. Then using a list of weight functions (kernels) <span class="math inline">\(w_{\Theta}(u)=(w_1(u),...,w_J(u))\)</span> to extract features and aggregate feature for hidden state of next layer</p>
<p>Different Spatial based GNN differ in choosing on the pseudo-coordinates <span class="math inline">\(u\)</span> and the weight functions <span class="math inline">\(w(u)\)</span></p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210622110851.png" /></p>
<h2 id="graphsage">GraphSAGE</h2>
<p><a href="https://arxiv.org/pdf/1706.02216.pdf">GraphSAGE</a> is Sample and Aggregate, learning how to embed node features from neighors</p>
<p><strong>Aggregate</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210621210811.png" /></p>
<ol type="1">
<li><p>Aggregate by Mean</p>
<p>replace line 4 and line 5 with <span class="math inline">\(h_v^k\leftarrow \sigma(W\cdot Mean(\{h_v^{k-1}\}\cup \{h_u^{k-1}\}),u\in \mathcal{N}(v)\)</span></p></li>
<li><p>Aggregate by LSTM</p>
<p>applying LSTM to a random permutation of the node's neighbors</p></li>
<li><p>Aggregate by Pooling</p>
<p><span class="math inline">\(AGGREGATE_k^{pool}=max(\{\sigma(W_{pool}h_{u}^k)+b\}), u\in\mathcal{N}(v)\)</span></p></li>
</ol>
<p>Loss Function:</p>
<p><span class="math inline">\(J_{\mathcal{G}}(z_u)=-log(\sigma(z_u^Tz_v))-Q\cdot \mathbb{E}_{v_n\sim P_n(v)}log(\sigma(-z_u^Tz_{v_n}))\)</span></p>
<p>where <span class="math inline">\(Q\)</span> is the number of samples by negative sampling process. In supervised method, <span class="math inline">\(v\)</span> is postive samples, <span class="math inline">\(v_n\)</span> is negative samples; In unsupervised method, <span class="math inline">\(v\)</span> is neighboring nodes, <span class="math inline">\(v_n\)</span> is nodes that far away from <span class="math inline">\(u\)</span>.</p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210621212722.png" /></p>
<h2 id="gat">GAT</h2>
<p><a href="https://arxiv.org/pdf/1710.10903.pdf">reference paper ICLR 2018</a></p>
<p>In MoNet, the distance measurement <span class="math inline">\(u(i,j)\)</span> and kernel <span class="math inline">\(w_j(u)\)</span> is manually defined. GAT, however learn these measurements and weight functions as engergy <span class="math inline">\(e_{i,j}\)</span>.</p>
<p><strong>Aggregate</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210621212959.png" /></p>
<p>Node feature <span class="math inline">\(h=\{\vec h_1, \vec h_2,...,\vec h_N\},\vec h_i\in \mathbb{R}^F\)</span></p>
<p>Energy Calculation: <span class="math inline">\(e_{i,j}=a(W\vec h_i, W\vec h_j)\)</span></p>
<p>Attention Score over neighbors: <span class="math inline">\(a_{i,j}=\frac{exp(LeakyReLU(\vec \alpha^T [W\vec h_i || W\vec h_j]))}{\sum_{k\in\mathcal{N}(i)} exp(LeakyReLU(\vec \alpha^T [W\vec h_i || W\vec h_k]))}\)</span></p>
<p>where <span class="math inline">\(j\)</span> is one neighbor of <span class="math inline">\(i\)</span>, <span class="math inline">\(||\)</span> means concatenation, <span class="math inline">\(\vec \alpha \in \mathbb{R}^{2F&#39;}\)</span> is the parameter of the feedforward neural network</p>
<p>Node <span class="math inline">\(i\)</span> is updated by <span class="math inline">\(\vec h_i&#39; = \sigma(\sum_{j\in \mathcal{N}(i)}\alpha_{i,j}W\vec h_j)\)</span>, which is a 1-head attention. One can even use a Multi-head attention like</p>
<p><span class="math inline">\(\vec h_i&#39; = {||}_{k=1}^K \sigma(\sum_{j\in \mathcal{N}(i)}\alpha_{i,j}W^k \vec h_j)\)</span> or <span class="math inline">\(\vec h_i&#39; = \sigma(\frac{1}{K}\sum_{k=1}^K \sum_{j\in \mathcal{N}(i)}\alpha_{i,j}W^k \vec h_j)\)</span></p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210621214351.png" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210621214821.png" /></p>
<p>Transductive task: the feature of testing data can be used in training stage, but the label can not be observed.</p>
<p>Inductive task: the testing data can not be used in training stage.</p>
<h2 id="gin">GIN</h2>
<p><a href="https://openreview.net/forum?id=ryGs6iA5Km">reference paper ICLR 2019</a></p>
<p>A GNN can be at most as powerful as WL isomorphic test</p>
<p>Theoretical proofs were provided</p>
<p><strong>Aggregate</strong></p>
<p><span class="math inline">\(h_v^k = MLP^{k}((1+\epsilon^k)\cdot h_v^{k-1} +\sum_{u\in \mathcal{N}(n)}h_u^{k-1})\)</span></p>
<ol type="1">
<li>suggest using Sum instead of mean or max</li>
<li>suggest using MLP instead of 1-layer</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210621215353.png" /></p>
<h1 id="spectral-based-convolution">2. Spectral-based Convolution</h1>
<p>Main idea of spectral-based convolution:</p>
<ol type="1">
<li><p>transform signal from time domain into frequency domain;</p></li>
<li><p>using filter to process signal;</p></li>
<li><p>transform signal back into time domain</p></li>
</ol>
<p><strong>Different spectral-based models differ in the way of learning filter <span class="math inline">\(g_{\theta}(L)\)</span></strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210621215520.png" /></p>
<h2 id="fourier-transformation">Fourier Transformation</h2>
<p>In order to understand better what's the transformation between Time Domain and Frequency Domain, thinking about the Fourier Transformation.</p>
<h3 id="time-domain">Time Domain</h3>
<p><span class="math inline">\(\vec A=\sum_i a_i \vec v_i\)</span></p>
<p><span class="math inline">\(x(t)=\int_{-\infty}^{\infty}x(\tau)\delta(t-\tau)d\tau\)</span></p>
<h3 id="frequency-domain">Frequency Domain</h3>
<p><span class="math inline">\(\vec A=\sum_k b_k \vec u_k\)</span></p>
<p><span class="math inline">\(x(t)=\frac{1}{2\pi}\int_{-\infty}^{\infty}X(j\omega)e^{j\omega t}d\omega\)</span></p>
<p>A signal can be represented by the weighted combination of infinite basis. The basis is <span class="math inline">\(e^{-j\omega t}\)</span>, whose weight is <span class="math inline">\(X(j\omega)\)</span>. For spectral-based Convolution GNNs, the idea is behind the designing of a list of basis and weights.</p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210622101443.png" /></p>
<h2 id="spectral-graph-theory">Spectral Graph Theory</h2>
<p>the spectral graph theory will provide a way to obtaining a group of basis and their weights.</p>
<p><strong>Notations</strong></p>
<p>For a undirected graph <span class="math inline">\(G=(V,E),N=|V|\)</span>.</p>
<p>The adjacency matrix of <span class="math inline">\(G\)</span> is <span class="math inline">\(A\in \mathbb{R}^{N\times N}\)</span>, where <span class="math inline">\(A_{i,j}=0\ if\ e_{i,j}\notin E, else\ A_{i,j}=w(i,j)\)</span>.</p>
<p>The degree matrix of <span class="math inline">\(G\)</span> is <span class="math inline">\(D\in \mathbb{R}^{N\times N}\)</span>, where <span class="math inline">\(D_{i,j}=d(i)\ if\ i=j, else\ D_{i,j}=0, d(i)=\sum_j A_{i,j}\)</span>.</p>
<p>The signal on <span class="math inline">\(G\)</span>(vertices) is <span class="math inline">\(f:V\rightarrow \mathbb{R}^{N}\)</span>, where <span class="math inline">\(f(i)\)</span> denotes the signal of vertex <span class="math inline">\(i\)</span>.</p>
<p><strong>Spectral Decomposition</strong></p>
<p>The Laplacian Matrix of <span class="math inline">\(G\)</span> is <span class="math inline">\(L=D-A\)</span> (one type of Laplacian Matrix, it is positive semidefinite). Do decomposition on <span class="math inline">\(L=U\Lambda U^T\)</span>, where <span class="math inline">\(\Lambda=diag(\lambda_0,...,\lambda_{N-1})\in \mathbb{R}^{N\times N}\)</span>, <span class="math inline">\(U=[u_0,...,u_{N-1}]\in \mathbb{R}^{N\times N}\)</span> (they are orthonormal with each other). Therefore, we found the basis <span class="math inline">\(u_n\)</span> and its corresponding weight <span class="math inline">\(\lambda_n,n=0,...,N-1\)</span>.</p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210622190152.png" /></p>
<p><strong>Example</strong> <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210622190608.png" /></p>
<p><strong>The meaning of <span class="math inline">\(Lf\)</span></strong> is actually represent the sum of signal (state) difference between node <span class="math inline">\(i\)</span> and its neighbors <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210622191918.png" /> <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210622192254.png" /></p>
<p><strong>Graph Fourier Transform of signal</strong> <span class="math inline">\(\hat x=U^T x\)</span> <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210622193501.png" /></p>
<p><strong>Filtering</strong></p>
<p>Convolution in time domain is multiplication in frequency domain <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210622194440.png" /></p>
<p><strong>Inverse Graph Fourier Transform of signal</strong> <span class="math inline">\(x=U\hat x\)</span> <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210622193523.png" /></p>
<h2 id="what-are-spectral-based-gnn-need-to-learnt">What are spectral-based GNN need to learnt?</h2>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210622194715.png" /> The GNN basically learnt the filter <span class="math inline">\(g_{\theta}(L)\)</span>, and this function can be any function.</p>
<p>For example <span class="math inline">\(g_{\theta}(L)=log(I+L)=L-\frac{L^2}{2}+\frac{L^3}{3}..., L=D-A\)</span>.</p>
<p><strong>Two problem will happen</strong> if we use this function <span class="math inline">\(log(I+L)\)</span></p>
<ol type="1">
<li>The size of parameters is growing up with <span class="math inline">\(O(N)\)</span>, <span class="math inline">\(N=|V|\)</span> is dimention of <span class="math inline">\(\theta\)</span>. Because the decomposition of <span class="math inline">\(L\)</span> must produce <span class="math inline">\(N\)</span> eigenvectors (bases)</li>
<li>The signal <span class="math inline">\(y\)</span> is not localized (over smoothing). Because when <span class="math inline">\(k\)</span> (of <span class="math inline">\(L^{k}\)</span>) becomes bigger, signal of all other nodes will be aggregated in current node. finally, the output of different nodes will be the same. (<span class="math inline">\(K\)</span> should be resonably small)</li>
<li>The decomposition of <span class="math inline">\(L\)</span> is time-costing <span class="math inline">\(O(N^2)\)</span></li>
</ol>
<p>When <span class="math inline">\(g_{\theta}(L)=L\)</span>, each node will just consider aggregate the information from their neighbors. When <span class="math inline">\(g_{\theta}(L)=L^2\)</span>, each node will consider all nodes that has a distance (within 2) from this node. <span class="math inline">\(x=[f(0),f(1),f(2),f(3)]\)</span> <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210623090134.png" /></p>
<p>Therefore all those spectral-based GNN use different strategy to overcome the difficulty of learning <span class="math inline">\(g_{\theta}(L)\)</span></p>
<h2 id="chebnet">ChebNet</h2>
<p><a href="https://arxiv.org/pdf/1606.09375.pdf">reference paper</a></p>
<p>ChebNet use polynomial to parametrize <span class="math inline">\(g_{\theta}(L)\)</span> and prevent the decomposition of <span class="math inline">\(L\)</span> (explicitly calculate eigenvectors). The localization is managed by <span class="math inline">\(K\)</span> (K-hop neighbors).</p>
<p><span class="math inline">\(g_{\theta}(L)=\sum_{k=1}^K \theta_k L^k\)</span></p>
<p><span class="math inline">\(g_{\theta}(\Lambda)=\sum_{k=1}^K \theta_k \Lambda^k\)</span></p>
<p><span class="math inline">\(y=Ug_{\theta}(\Lambda)U^Tx=\sum_{k=1}^K \theta_k L^kx=U(\sum_{k=1}^K \theta_k \Lambda^k)U^Tx\)</span></p>
<p>Therefore, the size of parameter is <span class="math inline">\(K\)</span>, and the localization is fixed by <span class="math inline">\(K\)</span>. But the calculate <span class="math inline">\(L^k\)</span> and obtaining eigenvectors <span class="math inline">\(U\)</span> need time complexity of <span class="math inline">\(O(N^2)\)</span></p>
<p>Therefore Chebyshev poluyomial is used to calculate <span class="math inline">\(\Lambda^k\)</span> in a recursive way and also prohibit the calculation of eigenvectors <span class="math inline">\(U\)</span>.</p>
<p><span class="math inline">\(T_0(\tilde \Lambda)=I, T_1(\tilde \Lambda)=\tilde{\Lambda}, T_l(\tilde \Lambda)=2\tilde \Lambda\ T_{k-1}(\tilde \Lambda)-T_{k-2}(\tilde \Lambda)\)</span>, where <span class="math inline">\(\tilde \Lambda=\frac{2\Lambda}{\lambda_{max}}-I, \tilde \lambda\in[-1,1]\)</span></p>
<p><span class="math inline">\(g_{\theta}(\Lambda)=\sum_{k=1}^K \theta_k \Lambda^k\rightarrow g_{\theta&#39;}(\Lambda)=\sum_{k=1}^K \theta_k&#39; T_k(\tilde{\Lambda})\)</span></p>
<p>Therefore the final signal <span class="math inline">\(y\)</span> can be efficiently computed, <span class="math inline">\(y=g_{\theta&#39;}(\tilde{L})x=\sum_{k=1}^K \theta_k&#39; T_k(\tilde{L})x\)</span> <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210622210221.png" /> <strong>ChebNet</strong> <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210622210316.png" /></p>
<h2 id="gcn">GCN</h2>
<p><a href="https://openreview.net/pdf?id=SJU4ayYgl">reference paper</a></p>
<p>The designing of <span class="math inline">\(g_{\theta}(L)\)</span></p>
<p><span class="math inline">\(y=g_{\theta&#39;}(L)x\approx \sum_{k=0}^K\theta_k&#39; T_k(\tilde{L})x, K=1\)</span></p>
<p><span class="math inline">\(y=g_{\theta&#39;}(L)x\approx\theta_0&#39;x+\theta_1&#39;\tilde{L}x,\ \ \ \ \tilde{L}=\frac{2L}{\lambda_{max}}-I\)</span></p>
<p><span class="math inline">\(=\theta_0&#39;x+\theta_1&#39;(\frac{2L}{\lambda_{max}}-I)x,\ \ \ \ \lambda_{max}\approx 2\)</span></p>
<p><span class="math inline">\(=\theta_0&#39;x+\theta_1&#39;(L-I)x,\ \ \ \ L=I-D^{-\frac{1}{2}}AD^{-\frac{1}{2}}\)</span></p>
<p><span class="math inline">\(=\theta_0&#39;x-\theta_1&#39;(D^{-\frac{1}{2}}AD^{-\frac{1}{2}})x,\ \ \ \ \theta=\theta_0&#39;=-\theta_1&#39;\)</span></p>
<p><span class="math inline">\(=\theta(I+D^{-\frac{1}{2}}AD^{-\frac{1}{2}})x\)</span></p>
<p>Use the renomalization trick: <span class="math inline">\(I+D^{-\frac{1}{2}}AD^{-\frac{1}{2}}\rightarrow \tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}\)</span>, where <span class="math inline">\(\tilde{A}=A+I\)</span>, and <span class="math inline">\(\tilde{D}_{ii}=\sum_j \tilde{A}_{i,j}\)</span></p>
<p>Therefore, the classic GCN use <span class="math inline">\(y\approx \theta(\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}})x\)</span>, why GCN use <span class="math inline">\(\tilde{D}^{-\frac1{2}}\)</span>, because it can reduce the information from neighbors according to the degree of node. Node with a few neighbors will get more information from its neighbors, while node with many neighbors should get less information from its neighbors.</p>
<p>The updating function of layer <span class="math inline">\(l+1\)</span> is <span class="math inline">\(H^{(l+1)}=\sigma(\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}H^{(l)}W^{(l)})\)</span></p>
<p>An example of 2 layer GCN is</p>
<p><span class="math inline">\(Z=f(X,\tilde{A})=softmax(\tilde{A}\ ReLU(\tilde{A}X\ W^{(0)})\ W^{(1)}), \tilde{A}=\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}\)</span></p>
<h2 id="hypergcn">HyperGCN</h2>
<p><a href="https://arxiv.org/pdf/1809.02589.pdf">reference paper 2019 NeurIPS</a> deals with the network of co-author, co-citation. The main idea is simplifying the hypergraph into a simple graph that can be processed by GNN.</p>
<p>Hypergraph <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210623111406.png" /></p>
<p>Graph Convolution on a hypernode <span class="math inline">\(v\)</span> using HyperGCN, where</p>
<p><span class="math inline">\(\tau\)</span> is the number of epoch</p>
<p><span class="math inline">\(h_v^{\tau+1}\)</span> is the hidden state in epoch <span class="math inline">\(\tau+1\)</span></p>
<p><span class="math inline">\(\mathcal{N}(v)\)</span> is neighbors of node <span class="math inline">\(v\)</span></p>
<p><span class="math inline">\([\bar A_s^{(\tau)}]_{u,v}\)</span> is the normalized weight between node <span class="math inline">\(v\)</span> and <span class="math inline">\(u\)</span></p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210623111955.png" /></p>
<h1 id="differences-between-spatial-based-gnn-and-spectral-based-gnn">Differences between Spatial-based GNN and Spectral-based GNN</h1>
<ol type="1">
<li>Spectral-based GNN can not assign different weights for neighbors in different hop, GAT (spatial-based GNN) solved this problem. For example, <span class="math inline">\(w_{0,2},w_{1,2},w_{2,2}\)</span> are hop-1 neighbors of <span class="math inline">\(v_2\)</span>, while <span class="math inline">\(w_{3,2}\)</span> is is hop-2 neighbor of <span class="math inline">\(v_2\)</span>. In spectral-based GNN, <span class="math inline">\(w_{0,2}=w_{1,2}=w_{2,2}\neq w_{3,2}\)</span>; in GAT, <span class="math inline">\(w_{0,2}\neq w_{1,2}\neq w_{2,2}\neq w_{3,2}\)</span></li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210623105003.png" /></p>
<h1 id="python-implementation-of-gnn">Python implementation of GNN</h1>
<ol type="1">
<li><a href="https://github.com/rusty1s/pytorch_geometric">Pytorch Geometric</a></li>
<li><a href="https://www.dgl.ai">Deep Graph Library</a></li>
<li><a href="https://github.com/graph4ai/graph4nlp">Graph4NLP</a></li>
</ol>
<h1 id="dataset">Dataset</h1>
<ol type="1">
<li>CORA: citation network. 2.7k nodes and 5.4k links</li>
<li>TU-MUTAG: 188 molecules with 18 nodes on average</li>
</ol>
<h1 id="summarization">Summarization</h1>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210623114430.png" /></p>
<h1 id="参考-references">参考 (References)</h1>
<ol type="1">
<li><a href="https://blog.csdn.net/weixin_37589575/article/details/106540831">Graph Neural Networks (GNN)（一）：Spatial-GNN</a></li>
<li><a href="https://blog.csdn.net/weixin_37589575/article/details/107013739">Graph Neural Networks (GNN)（三）：Spectral-GNN</a></li>
<li><a href="https://www.youtube.com/watch?v=eybCCtNKwzA">姜成翰 GNN 李宏毅</a></li>
<li><a href="http://speech.ee.ntu.edu.tw/~tlkagk/courses/ML2020/GNN.pdf">姜成翰 GNN 李宏毅 PPT</a></li>
</ol>
]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>GNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Gated Recurrent Unit (GRU)</title>
    <url>/2021/07/13/Deep%20Learning/Gated-Recurrent-Unit-GRU/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><span id="more"></span>
<h1 id="references">References</h1>
]]></content>
  </entry>
  <entry>
    <title>LSTM详解</title>
    <url>/2021/06/06/Deep%20Learning/LSTM%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="简单介绍">简单介绍</h1>
<p>LSTM 是一类循环神经网络，它的提出是为了化解传统循环神经网络（RNN）在 back propagation 中梯度弥散问题，这导致了 RNN 的短期记忆问题，使得 RNN 不能学习长距离的依赖关系。LSTM 通过引入 <span class="math inline">\(sigmoid\)</span> 控制门来控制信息的保留和丢弃，使得它能够记住重要的信息，遗忘不重要的信息</p>
<span id="more"></span>
<h1 id="lstm-几个重要的门介绍">LSTM 几个重要的门介绍</h1>
<p>从 <a href="https://blog.mlreview.com/understanding-lstm-and-its-diagrams-37e2f46f1714">Understanding LSTM and its diagrams</a> 这个博客中，我找到了一个最佳的描述 LSTM 细节的图。这是 LSTM 的一个胞元结构，它有两条主要的水平方向的数据流，上面的是胞元状态（<span class="math inline">\(C_{t-1}\)</span> 包含了 <span class="math inline">\(t-1\)</span> 时刻及以前序列的信息），下面的是输出或者隐状态（<span class="math inline">\(h_t\)</span> 包含了当前输入 <span class="math inline">\(x_t\)</span> 的重要信息）。下面我们介绍下 LSTM 的三个控制门 <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210606173408.png" /></p>
<h2 id="遗忘门">遗忘门</h2>
<p>遗忘门根据隐状态 <span class="math inline">\(h_t\)</span> 和当前输入 <span class="math inline">\(x_t\)</span> 来决定遗忘 <span class="math inline">\(C_{t-1}\)</span> 中的哪些信息，其中 <span class="math inline">\(\sigma(x)=\frac{1}{1+e^{-x}}\)</span> 是一个将输入向量的每一位映射到 <span class="math inline">\((0,1)\)</span> 的函数，映射后的值越大，<span class="math inline">\(C_{t-1}\)</span> 的信息保留越多，反之则遗忘越多</p>
<p><span class="math inline">\(f_t=\sigma(W_f \cdot [h_{t-1}, x_t] + b_f)\)</span> <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210606174445.png" /></p>
<h2 id="输入门">输入门</h2>
<p>输入门根据输入 <span class="math inline">\(x_t\)</span>，前一时刻输出 <span class="math inline">\(h_{t-1}\)</span> 和前一时刻胞元状态 <span class="math inline">\(C_{t-1}\)</span> 来计算 <span class="math inline">\(t\)</span> 时刻下的胞元状态 <span class="math inline">\(C_t\)</span>，其中 <span class="math inline">\(f_t\otimes C_{t-1}\)</span> 是 <span class="math inline">\(t-1\)</span> 时刻遗忘过后剩余的胞元信息，<span class="math inline">\(i_t \otimes \tilde{C_{t}}\)</span> 是 <span class="math inline">\(t\)</span> 时刻新增的胞元状态信息</p>
<p><span class="math inline">\(i_t=\sigma(W_i\cdot [h_{t-1}, x_t] + b_i)\)</span></p>
<p><span class="math inline">\(\tilde{C_t}=tanh(W_c\cdot [h_{t-1}, x_t] + b_C)\)</span></p>
<p><span class="math inline">\(C_t=f_t\otimes C_{t-1}+i_t \otimes \tilde{C_t}\)</span></p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210606174539.png" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210606174746.png" /></p>
<h2 id="输出门">输出门</h2>
<p>输出门根据 <span class="math inline">\(t-1\)</span> 时刻的输出，<span class="math inline">\(t\)</span> 时刻的输入 <span class="math inline">\(x_t\)</span> 和 <span class="math inline">\(t\)</span> 时刻的胞元信息来计算 <span class="math inline">\(t\)</span> 时刻的输出信息</p>
<p><span class="math inline">\(o_t=\sigma(W_o\cdot [h_{t-1}, x_t] + b_o)\)</span></p>
<p><span class="math inline">\(h_t=o_t\otimes tanh(C_t)\)</span></p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210606174906.png" /></p>
<h1 id="参考-references">参考 (References)</h1>
<ol type="1">
<li><a href="https://blog.mlreview.com/understanding-lstm-and-its-diagrams-37e2f46f1714">Understanding LSTM and its diagrams</a></li>
<li><a href="https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21">Illustrated Guide to LSTM’s and GRU’s: A step by step explanation</a></li>
<li><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a></li>
<li><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">The Unreasonable Effectiveness of Recurrent Neural Networks</a></li>
</ol>
]]></content>
      <categories>
        <category>Deep Learning</category>
      </categories>
      <tags>
        <tag>LSTM</tag>
      </tags>
  </entry>
  <entry>
    <title>养生</title>
    <url>/2021/06/01/Life/%E5%85%BB%E7%94%9F/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><span id="more"></span>
<p>养生两个目标</p>
<ol type="1">
<li>养气血</li>
<li>排垃圾</li>
</ol>
<p>按摩</p>
<ol type="1">
<li>头部</li>
</ol>
<p>梳头，从前额往后梳（100次） 头侧边的胆经，从前往后，往下梳（100次）</p>
<ol type="1">
<li><p>背部</p></li>
<li><p>手部</p></li>
</ol>
<h1 id="参考-references">参考 (References)</h1>
]]></content>
      <categories>
        <category>Life</category>
      </categories>
  </entry>
  <entry>
    <title>学校申请</title>
    <url>/2021/06/02/Life/%E5%AD%A6%E6%A0%A1%E7%94%B3%E8%AF%B7/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="大区职位申请链接">大区职位申请链接</h1>
<ol type="1">
<li>https://euraxess.ec.europa.eu</li>
<li>https://scholarshipdb.net/</li>
</ol>
<h1 id="potential-position">Potential Position</h1>
<h2 id="gnn">GNN</h2>
<ol type="1">
<li><a href="https://www.kth.se/profile/mvaz">Michail Vazirgiannis</a>, <a href="https://www.kth.se/profile/annaoj">Anna Olanås Jansson</a> from KTH,</li>
</ol>
<h2 id="knowledge-graph">Knowledge Graph</h2>
<h1 id="欧盟erasmus与eit奖学金项目">欧盟Erasmus+与EIT奖学金项目</h1>
<p>欧盟Erasmus+奖学金： 大部分在12月份-1月份之间，也有个别早一点在11月份就截止申请，或晚一点在3月份截止申请</p>
<p>EIT奖学金： 截止日期是1月中旬到3月初之间 <span id="more"></span></p>
<h1 id="瑞士留学">瑞士留学</h1>
<p>苏黎世联邦理工学院（申请截止日期12月15日）、洛桑联邦理工学院（申请截止日期12月15日）、巴塞尔大学（申请截止日期4月30日）、伯尔尼大学（申请截止日期4月30日）、日内瓦大学（申请截止日期2月28日）、苏黎世大学（申请截止日期2月28日）、洛桑大学（申请截止日期2月28日）等</p>
<h1 id="荷兰留学">荷兰留学</h1>
<p>荷兰大学的奖学金，截止日期大多在12月份到2月份之间，比如代尔夫特理工大学的奖学金一般是12月1日截止申请，乌特勒支大学的奖学金也是12月1日截止申请，阿姆斯特丹大学的奖学金是2月1日截止申请</p>
<p>阿姆斯特丹大学（申请截止日期3月1日或4月1日，根据学校不同而不同）、代尔夫特理工大学（4月1日）、瓦格宁根大学（申请截止日期5月1日）、莱顿大学（申请截止日期4月1日）、乌特勒支大学（申请截止日期4月1日）、鹿特丹Erasmus大学（申请截止日期4月15日至6月1日，根据学院不同而不同）、格罗宁根大学（申请截止日期5月1日）、马斯特里赫特大学（申请截止日期5月1日）、内梅亨大学（申请截止日期4月1日）、埃因霍温科技大学（申请截止日期5月1日）、阿姆斯特丹自由大学（申请截止日期4月1日）、屯特大学（申请截止日期5月1日）、蒂尔堡大学（申请截止日期4月1日）等</p>
<h1 id="德国留学">德国留学</h1>
<p>慕尼黑工业大学（申请截止日期大部分项目5月31日截止，个别项目3月截止）、亚琛工业大学（申请截止日期3月1日）、德累斯顿工业大学（申请截止日期5月31日）、柏林工业大学（申请截止日期3月至5月，根据项目不同而不同）、达姆斯塔特工业大学（申请截止日期7月15日）、卡尔斯鲁厄理工学院（申请截止日期4月至6月，根据项目不同而不同）、斯图加特大学（申请截止日期2月15日）、汉诺威大学（申请截止日期5月31日）、布伦瑞克工业大学（申请截止日期3月15日）；其他知名大学：慕尼黑大学（申请截止日期7月15日）、海德堡大学（申请截止日期3月至7月，根据项目不同而不同）、柏林洪堡大学（申请截止日期3月至7月，根据项目不同而不同）、弗赖堡大学（申请截止日期5月至7月，根据项目不同而不同）、柏林自由大学（申请截止日期5月31日）、图宾根大学（申请截止日期5月15日7月15日，根据项目不同而不同）、波恩大学（申请截止日期3月至7月，根据项目不同而不同）、曼海姆大学（申请截止日期4月30日或5月31日，根据项目不同而不同）、哥廷根大学（申请截止日期1月至7月，根据项目不同而不同）、乌尔姆大学（申请截止日期3月至5月，根据项目不同而不同）、埃尔朗根纽伦堡大学（申请截止日期3月至7月，根据项目不同而不同）、明斯特大学（申请截止日期5月31日）、科隆大学（申请截止日期6月至7月，根据项目不同而不同，国际管理学硕士3月31日截止）、汉堡大学（申请截止日期3月至7月，根据项目不同而不同）、维尔茨堡大学（申请截止日期7月15日，个别项目3月截止）、康斯坦茨大学（申请截止日期3月至7月，根据项目不同而不同）、杜伊斯堡-埃森大学（申请截止日期6月15日或7月15日，根据项目不同而不同）、法兰克福大学（申请截止日期6月至8月，根据项目不同而不同）、魏玛包豪斯大学（申请截止日期5月至7月，根据项目不同而不同）、霍恩海姆大学（申请截止日期3月15日）等</p>
<p>德国留学需要做APS审核，该审核周期需要3-6个月，所以申请德国大学，需要提前3-6个月时间用来做APS审核</p>
<h1 id="法国留学">法国留学</h1>
<p>申请截止日期都比较晚，一般在每年3月份之后。法国知名高等商学院的申请一般都分为4轮，从9月份开通申请，一直到延续到4月份。但申请埃菲尔奖学金的学生，必须赶在第一轮截止前提交申请。</p>
<p>巴黎六大、巴黎十一大、巴黎一大、巴黎七大、马赛大学、巴黎高等师范学院、巴黎政治学院、里昂高等师范学院、巴黎高科工程师集团Paris Tech、N+i工程师联盟、巴黎综合理工学院、巴黎中央理工学院、巴黎HEC商学院、ESSEC商学院、EDHEC商学院、EM里昂商学院、ESCP商学院</p>
<h1 id="比利时留学">比利时留学</h1>
<p>荷兰语区大学申请截止日期大部分为3月1日，法语区大学申请截止日期基本上都是4月30日</p>
<p>荷兰语鲁汶大学（申请截止日期3月1日）、法语鲁汶大学（申请截止日期4月30日）、根特大学（申请截止日期3月1日）、法语布鲁塞尔自由大学（申请截止日期4月30日）、荷兰语布鲁塞尔自由大学（申请截止日期4月1日）、安特卫普大学（申请截止日期3月1日，个别项目例外）、VLERICK鲁汶根特管理学院（申请截止日期4月30日）等</p>
<h1 id="北欧五国丹麦瑞典芬兰挪威冰岛">北欧五国（丹麦、瑞典、芬兰、挪威、冰岛）</h1>
<p>瑞典卡罗林斯卡学院、芬兰赫尔辛基大学、瑞典乌普萨拉大学、丹麦哥本哈根大学、瑞典隆德大学、挪威奥斯陆大学、瑞典斯德哥尔摩大学、丹麦奥胡斯大学、瑞典哥德堡大学、挪威卑尔根大学、冰岛大学、瑞典KTH皇家理工大学、丹麦技术大学排名、瑞典查尔姆斯理工大学、挪威科技大学、芬兰阿尔托大学、斯德哥尔摩经济学院、哥本哈根商学院、挪威BI管理学院、挪威经经济管理学院、芬兰阿尔托大学等</p>
<h1 id="英国留学与爱尔兰">英国留学与爱尔兰</h1>
<h1 id="意大利留学">意大利留学</h1>
<p>截止申请最早的是米兰理工大学，第一轮申请在11月截止，其余大学的申请截止日期都比较晚，在3月至6月之间</p>
<p>博洛尼亚大学、罗马大学、博科尼商业大学、米兰理工大学、米兰大学、都灵大学、都灵理工大学、帕多瓦大学、比萨大学等</p>
<h1 id="西班牙留学">西班牙留学</h1>
<p>申请截止日期普遍较晚，大部分在3月以后，有的大学甚至在7、8月份还可以申请当年秋季入学项目</p>
<p>巴塞罗那大学、庞培法布拉大学、巴塞罗那自治大学、马德里大学、马德里自治大学、加泰罗尼亚理工大学、马德里理工大学等</p>
<h1 id="奥地利留学">奥地利留学</h1>
<p>当年秋季入学项目的申请截止日期都在4月30日及以后，主要是因为奥地利大学开学时间比较晚，在10月份才开学</p>
<p>维也纳大学、因斯布鲁克大学、维也纳经济大学、维也纳医科大学、萨尔茨堡大学</p>
<h1 id="卢森堡留学">卢森堡留学</h1>
<h1 id="波兰-捷克与匈牙利">波兰 捷克与匈牙利</h1>
<p>中欧的捷克、波兰和匈牙利，都是欧盟申根国家。这三个国家都有众多历史悠久而知名的大学，包括捷克的布拉格查理大学、布拉格经济大学等，波兰的华沙大学、雅盖隆大学、华沙工业大学、华沙经济学院等，匈牙利的罗兰大学</p>
<h1 id="参考-references">参考 (References)</h1>
]]></content>
      <categories>
        <category>Life</category>
      </categories>
      <tags>
        <tag>院校申请</tag>
      </tags>
  </entry>
  <entry>
    <title>王阳明心学</title>
    <url>/2021/06/19/Life/%E7%8E%8B%E9%98%B3%E6%98%8E%E5%BF%83%E5%AD%A6/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="梁启超语录">梁启超语录</h1>
<ol type="1">
<li><p>大师通常能把自己的阅历甘苦用于指示我们，我们跟着他的路走，自然能事半功倍</p></li>
<li><p>口号的几个要素：（1）语句简单；（2）意义明确；（3）内容丰富；（4）刺激性强；（5）法门可实行，不管聪明才智多少，都能有个下手处</p></li>
<li><p>口号两个小计要素：（1）不要带宗教迷信；（2）不要带玄学性 <span id="more"></span></p></li>
<li><p>格物--致知--诚意--正心--修身--齐家--治国--平天下</p></li>
<li><p>知行合一：（1）未有知者而不行者，知而不行只是未知；（2）知是行的主意，行是知的功夫。知识行之始，行是知之成；（3）知行原是两个字说一个功夫，知之真切笃行处便是行，行之明觉精察处便是知</p></li>
<li><p>“知识行之始”：只要决心实行，则知识虽缺少些也不足为病，因为实行起来，便逼着你不能不设法求知识，知识便跟着来了；“行是知之成”：除了实行外，再没有第二条路得到知识。只有实地经验，行一步，得一点，再行一步，再得一点</p></li>
<li><p>只有打定主意诚诚恳恳去做这件事，自然着手之前逼着做预备知识功夫。这首之后，一步一步地磨练出知识来。并不需要把万事万物格个遍再去实行</p></li>
<li><p>“心外无物”：凡不在我们意识范围内的物（王阳明所谓意念不涉着者），最多只能承认他是物理学、数学或者几何学上的存在，而不能承认它有伦理学或认识论上的存在。再进一步看，物理学、数学、几何学的本身，也不能离开人类的意识而单独存在</p></li>
<li><p>王阳明认为，人类一切罪恶，皆由“间形骸分尔我”的私见衍生出来的，而这种私见，实非我们心体所本有</p></li>
<li><p>致良知功夫，最要紧的是把这些私欲化除净尽</p></li>
<li><p>良知唯一的仇敌是功利主义，不把这个病根拔了，一切学问无从做起</p></li>
<li><p>善恶唯一标准：凡做一事，发一念，其动机是否出自自私自利（然这一点除了自己的良知之外，没有别人或者别的方法能知得真切确实的）</p></li>
<li><p>欲廓清自私自利念头，除却良知没有第二法门</p></li>
<li><p>王阳明固为确信心外无物物外无心，灼然见得我身外人们及天地万物们都是“真我”或者“大我”的构成要素，因此得着“物我同体”的结论</p></li>
<li><p>一切行为，都是目的，不是手段</p></li>
<li><p>圣人是以质计，不以量计，固而人人可为圣贤</p></li>
</ol>
<h1 id="参考-references">参考 (References)</h1>
]]></content>
      <categories>
        <category>Life</category>
      </categories>
      <tags>
        <tag>哲学</tag>
      </tags>
  </entry>
  <entry>
    <title>EM算法</title>
    <url>/2021/06/12/Machine%20Learning/EM%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="em-基本思想">EM 基本思想</h1>
<p>已知观察数据，未知隐含数据和模型参数。在E步，我们所做的事情是固定模型参数的值，优化隐含数据的分布（猜想隐变量的数据），而在M步，我们所做的事情是固定隐含数据分布，优化模型参数的值（基于观测数据和猜测的隐变量数据最大化对数似然函数） <span id="more"></span></p>
<p>这个算法与 MLE（maximum likelihood estimation）的差别是：MLE 针对无隐变量的模型，先收集所有变量的观测数据，然后根据完整的观测数据去估计参数；EM 针对含隐变量的模型，先根据可观测变量的数据猜测隐变量的数据，然后根据隐变量数据和观测数据来估计参数 <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210612104008.png" /></p>
<h1 id="em-推导">EM 推导</h1>
<h2 id="jensens-inequality">Jensen’s inequality</h2>
<p>如果函数 <span class="math inline">\(g(x)\)</span> 是凸函数，那么有 <span class="math inline">\(g(E(x))\geq E(g(x))\)</span></p>
<p>证明如下，过点 <span class="math inline">\((x, g(E(x)))\)</span> 所一条切线，假设切线公式为 <span class="math inline">\(L(x)=a+bx\)</span> <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210612110505.png" /></p>
<h2 id="em-算法">EM 算法</h2>
<p><strong>整体思想</strong></p>
<p>假设有 <span class="math inline">\(n\)</span> 个独立同分布的数据 <span class="math inline">\({x^{1}, x^{(2)},...,x^{(n)}}\)</span>，我们要估计一个包含隐变量 <span class="math inline">\(z\)</span> 和变量 <span class="math inline">\(x\)</span> 的模型的参数，改模型表示为 <span class="math inline">\(p(x,z;\theta)\)</span>,</p>
<p>那么，关于变量 <span class="math inline">\(x\)</span> 的概率密度为 <span class="math inline">\(p(x;\theta)=\sum_{z} p(x,z;\theta)\)</span></p>
<p>模型的训练目标为极大对数似然函数 <span class="math inline">\(l(\theta)=log(\sum_{i=1}^{n}p(x^{(i)};\theta))=\sum_{i=1}^{n}\sum_{z^{(i)}}p(x^{(i)}, z^{(i)};\theta)\)</span>。由于 <span class="math inline">\(z\)</span> 是隐变量，数据无法观测，优化这个目标是困难的</p>
<p>EM 算法，通过构造 <span class="math inline">\(l(\theta)\)</span> 的下界函数，通过在 E 步根据参数和部分观测数据计算下界函数，在 M 步最大化下界函数来实现对参数 <span class="math inline">\(\theta\)</span> 的逐步优化</p>
<p><strong>下界函数 ELBO 推导</strong></p>
<p>先考虑对一个数据样例 <span class="math inline">\(x\)</span> 的优化过程，即针对目标 <span class="math inline">\(log(p(x;\theta))=log(\sum_{z} p(x,z;\theta))\)</span>，令分布 <span class="math inline">\(Q(z)\)</span> 为隐变量 <span class="math inline">\(z\)</span> 的一个分布，<span class="math inline">\(\sum_{z}Q(z)=1, Q(z)\geq 0\)</span>，此时重写目标</p>
<p><span class="math inline">\(log(p(x;\theta))=log(\sum_{z} p(x,z;\theta))=log\sum_{z}Q(z)\frac{p(x,z;\theta)}{Q(z)} \geq \sum_{z}Q(z)log\frac{p(x,z;\theta)}{Q(z)}\)</span></p>
<p>上面不等式根据 Jensen 不等式可推导，因为 <span class="math inline">\(log(\frac{p(x,z;\theta)}{Q(z)})\)</span> 是一个关于 <span class="math inline">\(z\)</span> 的凸函数</p>
<p><strong>Q 函数的确定</strong></p>
<p>对于任意一个 <span class="math inline">\(Q(z)\)</span> 上面的不等式都成立，但是我们希望找到的下界函数跟目标函数足够接近（也就是令不等式的等式成立），此时必须满足条件 <span class="math inline">\(\frac{p(x,z;\theta)}{Q(z)}=c\)</span>，这意味着 <span class="math inline">\(Q(z)\sim p(x,z;\theta)\)</span>，而 <span class="math inline">\(\sum_z Q(z)=1\)</span>（归一化概率分布），因此我们可以计算出 <span class="math inline">\(Q(z)\)</span> 为</p>
<p><span class="math inline">\(Q(z)=\frac{p(x,z;\theta)}{\sum_{z} p(x,z;\theta)}=\frac{p(x,z;\theta)}{p(x;\theta)}=p(z|x;\theta)\)</span></p>
<p>这样我们就唯一确定了 <span class="math inline">\(Q(z)\)</span> 函数为 <span class="math inline">\(z\)</span> 的给定观测数据 <span class="math inline">\(x\)</span> 和参数 <span class="math inline">\(\theta\)</span> 的后验概率，即给定了观测数据和参数，就可以猜测出 <span class="math inline">\(z\)</span> 的概率分布（隐数据），基于此就计算出了一个新的 ELBO</p>
<p><strong>EM 算法</strong></p>
<p>在此重写我们的目标函数和下界函数的关系</p>
<p><span class="math inline">\(l(\theta)=\sum_{i}log(p(x_i;\theta))\geq \sum_{i}ELBO(x^{(i)};Q_i(z^{(i)}),\theta)=\sum_{i}\sum_{z^{(i)}} Q_i(z^{(i)})log\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}\)</span>，对于任意 <span class="math inline">\(Q_i,i=1,2,...,n\)</span> 必须满足 <span class="math inline">\(Q_i(z^{(i)})=p(z^{(i)}|x^{(i)};\theta)\)</span></p>
<p><strong>Initialization</strong></p>
<p>随机初始化 <span class="math inline">\(\theta\)</span></p>
<p><strong>E-step</strong></p>
<p>对于每一个 <span class="math inline">\(i\)</span>，令</p>
<p><span class="math inline">\(Q_i(z^{(i)}):=p(z^{(i)}|x^{(i)};\theta)\)</span></p>
<p><strong>M-step</strong></p>
<p><span class="math inline">\(\theta:=\underset{\theta}{argmax}\sum_{i}^{n} ELBO(x^{(i)};Q_i,\theta) =\underset{\theta}{argmax}\sum_{i}^{n}\sum_{z^{(i)}}Q_i(z^{(i)})log\frac{p(x^{(i)},z^{(i)};\theta)}{Q_i(z^{(i)})}\)</span></p>
<h1 id="收敛性证明">收敛性证明</h1>
<p><span class="math inline">\(l(\theta^{(t+1)})\geq \sum_{i=1}^{n} ELBO(x^{(i)},Q_i^{(t)},\theta^{(t+1)}) \geq \sum_{i=1}^{n} ELBO(x^{(i)},Q_i^{(t)},\theta^{(t)}) =l(\theta^{(t)})\)</span></p>
<p>其中 <span class="math inline">\(\theta^{(t+1)}\)</span> 是通过 <span class="math inline">\(\underset{\theta}{argmax} \sum_{i=1}^n ELBO(x^{(i)};Q_i^{(t)},\theta)\)</span> 求出来的最优参数</p>
<h1 id="应用">应用</h1>
<h2 id="k-means-算法">K-means 算法</h2>
<p>K-means 算法开始给定随机的聚类簇的中心（簇的中心就是隐变量），根据聚类簇的中心划分数据。在 E 步中估计 K 个簇的中心位置。然后计算得到每个样本最近的质心，并把样本聚类到最近的这个质心，这个就是 M 步</p>
<h2 id="gmm-混合高斯模型">GMM 混合高斯模型</h2>
<h2 id="lda-主题模型">LDA 主题模型</h2>
<h1 id="参考-references">参考 (References)</h1>
<ol type="1">
<li><a href="https://www.cnblogs.com/pinard/p/6912636.html">刘建平老师 Pinard EM 算法原理总结</a></li>
<li><a href="http://cs229.stanford.edu/notes2020spring/cs229-notes8.pdf">Tengyu Ma and Andrew Ng CS229 Lecture notes</a></li>
<li><a href="https://link.zhihu.com/?target=http%3A//ai.stanford.edu/~chuongdo/papers/em_tutorial.pdf">What is the expectation maximization algorithm?</a></li>
</ol>
]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>EM</tag>
      </tags>
  </entry>
  <entry>
    <title>GMM模型</title>
    <url>/2021/06/12/Machine%20Learning/GMM%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="单个高维高斯分布">单个高维高斯分布</h1>
<p><span class="math inline">\(d\)</span> 维的高斯分布的密度函数为</p>
<p><span class="math inline">\(N(x;\mu,\Sigma)=\frac{1}{\sqrt{(2\pi)^{d}det(\Sigma)}}exp\left[-\frac{1}{2}(x-\mu)^T \Sigma^{-1}(x-\mu) \right]]\)</span></p>
<p>其中 <span class="math inline">\(x\)</span> 是一个 <span class="math inline">\(d\)</span> 维的数据，<span class="math inline">\(\mu\)</span> 是一个 <span class="math inline">\(d\)</span> 维的向量，<span class="math inline">\(\Sigma\)</span> 是一个 <span class="math inline">\(d\times d\)</span> 的协方差矩阵</p>
<span id="more"></span>
<h1 id="混合高斯推导">混合高斯推导</h1>
<p><strong>混合高斯模型的概率密度函数</strong></p>
<p><span class="math inline">\(p(x|\Theta)=\sum_k \alpha_k N(x;\mu_k,\Sigma_k)=\sum_k \alpha_k\frac{1}{\sqrt{(2\pi)^d det(\Sigma_k)}}exp\left[-\frac{1}{2}(x-\mu_k)^T \Sigma_k^{-1}(x-\mu_k)\right]\)</span></p>
<p>其中 <span class="math inline">\(\Theta\)</span> 包含 <span class="math inline">\(\{\alpha_k,\mu_k,\Sigma_k\},k=1,2,...,K\)</span></p>
<p><strong>ELBO 下限函数的推导</strong></p>
<p><span class="math inline">\(l(\Theta)=\sum_i log(p(x_i|\Theta))\)</span></p>
<p><span class="math inline">\(=\sum_i log(\sum_{k}p(x_i,z_k|\Theta))\)</span></p>
<p><span class="math inline">\(=\sum_i log(\sum_{k}p(x_i|z_k,\Theta)p(z_k=k))\)</span></p>
<p><span class="math inline">\(= \sum_i log(\sum_{k}Q_k(z_k|x_i,\mu_k,\Sigma_k)\frac{p(x_i|z_k=k,\mu_k,\Sigma_k)p(z_k=k)}{Q_k(z_k|x_i,\mu_k,\Sigma_k)})\)</span></p>
<p><span class="math inline">\(\geq ELBO(\Theta) = \sum_i \sum_k Q_k(z_k|x_i,\mu_k,\Sigma_k) log\frac{p(x_i|z_k=k,\mu_k,\Sigma_k)p(z_k=k)}{Q_k(z_k|x_i,\mu_k,\Sigma_k)}\)</span></p>
<p><strong>Q 函数的推导</strong></p>
<p>为了使得获得一个最好的 <span class="math inline">\((\Theta)\)</span> 的 ELBO 下限函数，要求 <span class="math inline">\(\frac{p(x_i|z_k=k,\mu_k,\Sigma_k)p(z_k=k)}{Q_k(z_k|x_i,\mu_k,\Sigma_k)}=c\)</span>，而 <span class="math inline">\(\sum_k Q_k(z_k|x_i,\mu_k,\Sigma_k)=1\)</span>（分母归一化），因此</p>
<p><span class="math inline">\(Q_k(z_k|x_i,\mu_k,\Sigma_k)=\frac{p(x_i|z_k=k,\mu_k,\Sigma_k)p(z_k=k) }{\sum_k p(x_i|z_k=k,\mu_k,\Sigma_k)p(z_k=k)}=\frac{N(x_i|\mu_k,\Sigma_k)\alpha_k}{\sum_k N(x_i|\mu_k,\Sigma_k)\alpha_k}=p(z_k=k|x_i,\mu_k,\Sigma_k)\)</span></p>
<p>其中 <span class="math inline">\(p(z_k=k)=\alpha_k\)</span> 为先验概率；GMM 选用的隐变量是 <span class="math inline">\(z=[z_1,...,z_K]\)</span>, 代表数据 <span class="math inline">\(x_i\)</span> 来自第 <span class="math inline">\(k\)</span> 个高斯分布的概率。关于隐变量 <span class="math inline">\(z_k\)</span> 的 Q 函数为 <span class="math inline">\(Q_k(z_k)=p(z_k=k|x_i,\mu_k, \Sigma_k)\)</span>（给定部分观测数据 <span class="math inline">\(x_i\)</span> 和参数，<span class="math inline">\(z_k\)</span> 的后验概率）。不等式由 Jensen 不等式推导得到（<span class="math inline">\(E(f(x))\geq f(E(x))\)</span> 如果 <span class="math inline">\(f(x)\)</span> 是一个凸函数）</p>
<p>那么 EM 在 E 步时计算 Q 函数，在 M 步最大化 <span class="math inline">\(\Theta=\{\alpha_k, \mu_k, \Sigma_k\},k=1,2,...,K\)</span></p>
<h1 id="gmm-的em-算法">GMM 的EM 算法</h1>
<p><strong>Initialization</strong></p>
<p>初始化参数 <span class="math inline">\(\{\alpha_k,\mu_k,\Sigma_k\},k=1,2,...,K\)</span></p>
<p><strong>E-step</strong></p>
<p>计算 Q 函数 <span class="math inline">\(Q_k(z_k|x_i,\mu_k,\Sigma_k)=\frac{N(x_i|\mu_k,\Sigma_k)\alpha_k}{\sum_k N(x_i|\mu_k,\Sigma_k)\alpha_k}\)</span></p>
<p>计算新的 ELBO 函数</p>
<p><span class="math inline">\(ELBO(\Theta)=\sum_i\sum_k Q_k(z_k|x_i,\mu_k,\Sigma_k) log\frac{p(x_i|z_k=k,\mu_k,\Sigma_k)p(z_k=k)}{Q_k(z_k|x_i,\mu_k,\Sigma_k)}\)</span></p>
<p><span class="math inline">\(=\sum_i\sum_k Q_k(z_k|x_i,\mu_k,\Sigma_k)log\left(\frac{\alpha_k}{Q_k(z_k|x_i,\mu_k,\Sigma_k)}\frac{1}{\sqrt{(2\pi)^d det(\Sigma_k)}}exp[-\frac{1}{2}(x_i-\mu_k)^T\Sigma_k^T(x_i-\mu_k)]\right)\)</span></p>
<p><strong>M-step</strong> 用更新过后的 <span class="math inline">\(ELBO(\Theta)\)</span> 对参数 <span class="math inline">\(\alpha_k,\mu_k,\Sigma_k,k=1,2,...,K\)</span> 分别求导，令导数等于 0，令 <span class="math inline">\(Q_k(i)=Q_k(z_k|x_i,\mu_k,\Sigma_k)\)</span> 最后得到参数更新公式</p>
<p>更新参数 <span class="math inline">\(\alpha_k, k=1,2,...,K\)</span>， <span class="math inline">\(\alpha_k=\frac{\sum_i Q_k(i)}{N}\)</span></p>
<p>更新参数 <span class="math inline">\(\alpha_k, k=1,2,...,K\)</span>， <span class="math inline">\(\mu_k==\frac{\sum_i Q_k(i)x_i}{\sum_i Q_k(i)}\)</span></p>
<p>更新参数 <span class="math inline">\(\alpha_k, k=1,2,...,K\)</span>， <span class="math inline">\(\Sigma_k=\frac{\sum_i Q_k(i)(x_i-\mu_k)(x_i-\mu_k)^T}{\sum_i Q_k(i)}\)</span></p>
<p>其中 <span class="math inline">\(N\)</span> 是数据点的数量（假设每个数据点都是独立同分布产生的），<span class="math inline">\(K\)</span> 是 GMM 中高斯分布的个数</p>
<h1 id="参考-references">参考 (References)</h1>
<ol type="1">
<li>https://wjchen.net/post/cn/gmm-em-cn.html</li>
</ol>
]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>GMM</tag>
      </tags>
  </entry>
  <entry>
    <title>SVM模型</title>
    <url>/2021/06/16/Machine%20Learning/SVM%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="空间几何基础">空间几何基础</h1>
<h2 id="点到平面距离公式">点到平面距离公式</h2>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210616164127.png" /></p>
<p>如图，有一个平面 $: <span class="math inline">\(ax+by+cz+d=0\)</span>，它的法向量 <span class="math inline">\(\vec n=(a,b,c)\)</span>（平面内任意一个向量与 <span class="math inline">\(\vec n\)</span> 的点积为 0），求平面外一点 <span class="math inline">\(B=(x_1,y_1,z_1)\)</span> 到平面 <span class="math inline">\(\alpha\)</span> 的距离 <span id="more"></span> 取平面内任意一点 <span class="math inline">\(A=(x_0,y_0,z_0)\)</span>，则向量 <span class="math inline">\(\overrightarrow{AB}=(x_1-x_0,y_1-y_0,z_1-z_0)\)</span> ，点 <span class="math inline">\(B\)</span> 到平面 <span class="math inline">\(\alpha\)</span> 的距离等于 <span class="math inline">\(|\overrightarrow{AB}|cos\theta\)</span>，而 <span class="math inline">\(cos\theta=\frac{\vec n \cdot \overrightarrow{AB}}{|\vec n|| \overrightarrow{AB}|}\)</span>，</p>
<p>因此点 <span class="math inline">\(B\)</span> 到平面的距离 <span class="math inline">\(h=\overrightarrow{AB}\cdot \frac{\vec n}{|\vec n|}=\left|(x_1-x_0,y_1-y_0,z_1-z_0)\cdot \frac{(a,b,c)}{\sqrt{a^2+b^2+c^2}} \right|=\frac{|a(x_1-x_0)+b(y_1-y_0)+c(z_1-z_0))|}{\sqrt{a^2+b^2+c^2}}\)</span>，</p>
<p>又 <span class="math inline">\(ax_0+by_0+cz_0+d=0\)</span>，所以最终点 <span class="math inline">\(B\)</span> 到平面的距离为 <span class="math inline">\(h=\frac{|ax_1+by_1+cz_1+d|}{\sqrt{a^2+b^2+c^2}}\)</span>,</p>
<p>推广到 n 维空间中点 <span class="math inline">\(A=(x_1,x_2,...,x_n)\)</span>，超平面 <span class="math inline">\(\pi\)</span>: <span class="math inline">\(a_1y_1+a_2y_2+...+a_ny_n+d=0\)</span>，则点 <span class="math inline">\(A\)</span> 到平面 <span class="math inline">\(\pi\)</span> 的距离为 <span class="math inline">\(\frac{|a_1x_1+a_2x_2+...+a_nx_n+d|}{\sqrt{ {a_1}^2+{a_2}^{2}+...+{a_n}^2}}\)</span></p>
<h2 id="两个平面之间的距离">两个平面之间的距离</h2>
<p>已知两个超平面 <span class="math inline">\({\pi}_1\)</span>: <span class="math inline">\(a_1x_1+a_2x_2+...+a_nx_n+d_1=0\)</span> 和超平面 ${}_2: <span class="math inline">\(a_1y_1+a_2y_2+...+a_ny_n+d_2=0\)</span>。 取 <span class="math inline">\({\pi}_1\)</span> 中任意一点 <span class="math inline">\(P(x_1,x_2,...,x_n)\)</span>，则 <span class="math inline">\(P\)</span> 到 <span class="math inline">\(\pi_2\)</span> 的距离为 <span class="math inline">\(h=\frac{|a_1x_1+a_2x_2+...+a_nx_n+d_2|}{\sqrt{ {a_1}^2+{a_2}^2+...+{a_n}^2 }}\)</span>。由于 <span class="math inline">\(P\)</span> 在平面 <span class="math inline">\(\pi_1\)</span> 上，所以有 <span class="math inline">\(a_1x_1+a_2x_2+...+a_nx_n+d_1=0\)</span>，最后 <span class="math inline">\(h=\frac{|d_2-d_1|}{\sqrt{ {a_1}^2+{a_2}^2+...+{a_n}^2}}\)</span></p>
<h1 id="svm-间隔">SVM 间隔</h1>
<h2 id="函数间隔">函数间隔</h2>
<p>令 <span class="math inline">\(w^Tx+b=0\)</span> 为我们的划分超平面，对于任何一个数据点 <span class="math inline">\(x\)</span>，它的标签为 <span class="math inline">\(y\in [-1,1]\)</span>，我们规定，当 <span class="math inline">\(w^Tx+b&gt;0\)</span>，<span class="math inline">\(x\)</span> 被划分为正例，当 <span class="math inline">\(w^Tx+b&lt;0\)</span>，<span class="math inline">\(x\)</span> 被划分为反例。定义函数间隔为</p>
<p><span class="math inline">\(\gamma(x) = y(w^Tx+b)=yf(x)\)</span></p>
<p>当 <span class="math inline">\(\gamma &gt; 0\)</span>，那么说明数据点 <span class="math inline">\(x\)</span> 被正确分类</p>
<p>那么 SVM 训练的目标为 <span class="math inline">\(\hat \gamma = min\ \gamma(x_i), i = 1,2,...,n\)</span></p>
<h2 id="几何间隔">几何间隔</h2>
<p>由于函数间隔 <span class="math inline">\(\hat\gamma\)</span> 的值会随着参数 <span class="math inline">\(w\)</span> 和 <span class="math inline">\(b\)</span> 的缩放（超平面不变）而变化，比如 <span class="math inline">\(w\)</span> 和 <span class="math inline">\(b\)</span> 变成 <span class="math inline">\(2w\)</span> 和 <span class="math inline">\(2b\)</span>，<span class="math inline">\(f(x)\)</span> 会变成 <span class="math inline">\(2f(x)\)</span>，如果按照最小化函数间隔，永远求不出个最优的参数 <span class="math inline">\(w\)</span> 和 <span class="math inline">\(b\)</span>。为此将目标给为最小化几何间隔</p>
<p><span class="math inline">\(\tilde \gamma=\frac{y(w^Tx+b)}{||w||}=\frac{yf(x)}{||w||}=\frac{\gamma(x)}{||w||}\)</span></p>
<p>其中 <span class="math inline">\(\frac{f(x)}{||w||}\)</span> 其实就是点 <span class="math inline">\(x\)</span> 到超平面 <span class="math inline">\(w^Tx+b=0\)</span> 的几何距离</p>
<h2 id="最大间隔分类器">最大间隔分类器</h2>
<p>对于我们的分类器，希望最大化 <span class="math inline">\(max\ \tilde{\gamma}\)</span>，并且对所有的数据点要满足 <span class="math inline">\(y_i(w^Tx_i)+b=\gamma(x_i)\geq \hat \gamma, i=1,2,...,n\)</span>。</p>
<p>这里我们可以取 <span class="math inline">\(\hat \gamma=1\)</span>（这个值可以随意取一个大于 0 的数，参数 <span class="math inline">\(b\)</span> 可以在训练过程中调整），如此 SVM 的优化目标为</p>
<p><span class="math inline">\(max\frac{1}{||w||},\ s.t.,\ y_i(w^Tx_i+b)\geq 1,i=1,2,...,n\)</span></p>
<p>这个问题的优化目标就如下图所示</p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210616205916.png" /></p>
<h1 id="深入推导">深入推导</h1>
<h2 id="线性可分问题">线性可分问题</h2>
<p><strong>Max 问题变为 Min 问题</strong></p>
<p><span class="math inline">\(min\frac{1}{2}||w||^2,\ s.t.,\ y_i(w^Tx_i+b)\geq 1,i=1,2,...,n\)</span></p>
<p><strong>对偶问题转化</strong></p>
<p>上面的问题是一个凸二次规划问题，可以直接用现成优化方法。还可以用朗格朗日对偶性，将原问题变化成它的对偶问题来求解。这样做的好处：（1）对偶问题更容易求解；（2）方便引入核函数</p>
<p>定义拉格朗日函数</p>
<p><span class="math inline">\(L(w,b,\alpha)=\frac{1}{2}||w||^2-\sum_{i=1}^n \alpha_i(y_i(w^Tx_i+b)-1)\)</span></p>
<p>现在来看，我们的目标为 <span class="math inline">\(\underset{w,b}{min}\ \underset{\alpha_i\geq 0}{max}\ L(w,b,\alpha)=p^*\)</span></p>
<p>其中 <span class="math inline">\(p^*\)</span> 为问题的最优值。容易验证，如果有那个条件 <span class="math inline">\(y_i(w^Tx_i+b)&lt;1\)</span> 不满足，那么里面的 <span class="math inline">\(max\)</span> 问题就会趋向 <span class="math inline">\(\infty\)</span>，只有当所有的条件都满足时，才能求出外面的 <span class="math inline">\(min\)</span> 问题，最小值为 <span class="math inline">\(\frac{1}{2}||w||^2\)</span></p>
<p>此时对换 <span class="math inline">\(min\)</span> 和 <span class="math inline">\(max\)</span> 就得到了原问题的对偶问题</p>
<p><span class="math inline">\(\underset{\alpha_i\geq 0}{max}\ \underset{w,b}{min}\ L(w,b,\alpha)=d^*\)</span></p>
<p>其中 <span class="math inline">\(d^*\)</span> 为问题的最优值，并且满足 <span class="math inline">\(d^*\leq p^*\)</span>。由这个对偶问题，从而实现先对 <span class="math inline">\(w\)</span> 和 <span class="math inline">\(b\)</span> 极小化，然后对 <span class="math inline">\(\alpha_i\)</span> 极大化</p>
<p><strong>注：</strong> 只有原问题能满足 KTT 条件才能转化为它的对偶问题来求解。 KTT 条件定义如下：</p>
<p>对于一个凸函数 <span class="math inline">\(f(x)\)</span>，求解 <span class="math inline">\(min\ f(x)\)</span></p>
<p><span class="math inline">\(s.t. h_j(x)=0,j=1,...,p;\ g_k(x)\leq 0,k=1,...,q\)</span></p>
<p>KTT 条件如下： 1. <span class="math inline">\(h_j(x)=0,j=1,...,p;\ g_k(x)\leq 0,k=1,...,q\)</span> 2. <span class="math inline">\(\bigtriangledown f(x)+\sum_{j=1}^p \lambda_j\bigtriangledown h_j(x) + \sum_{k=1}^q \mu_k\bigtriangledown g_k(x) = 0, \lambda_j\neq 0,\mu_k\geq 0, \mu_kg_k(x)=0\)</span></p>
<p><strong>问题求解</strong> 1. 固定 <span class="math inline">\(\alpha_i\)</span>，最小化 <span class="math inline">\(w\)</span> 和 <span class="math inline">\(b\)</span></p>
<pre><code>$\frac&#123;\partial L&#125;&#123;\partial w&#125;=0 \Rightarrow w=\sum_&#123;i=1&#125;^n \alpha_i y_i x_i$ 

$\frac&#123;\partial L&#125;&#123;\partial b&#125;=0 \Rightarrow b=\sum_&#123;i=1&#125;^n \alpha_i y_i=0$

代入 $L(w,b,\alpha)=\frac&#123;1&#125;&#123;2&#125;||w||^2-\sum_&#123;i=1&#125;^n \alpha_i(y_i(w^Tx_i+b)-1)$ 得到

$L(w,b,\alpha)$

$=\frac&#123;1&#125;&#123;2&#125;\sum_&#123;i,j=1&#125;^n \alpha_i\alpha_jy_iy_jx_i^Tx_j-\sum_&#123;i,j=1&#125;^n\alpha_i\alpha_jy_iy_jx_i^Tx_j-b\sum_&#123;i=1&#125;^n \alpha_i y_i+\sum_&#123;i=1&#125;^n \alpha_i$ 

$=\sum_&#123;i=1&#125;^n \alpha_i-\frac&#123;1&#125;&#123;2&#125;\sum_&#123;i,j=1&#125;^n\alpha_i\alpha_jy_iy_jx_i^Tx_j$</code></pre>
<ol start="2" type="1">
<li><p>代入上一步求解的最优 <span class="math inline">\(w^*\)</span> 和 <span class="math inline">\(b^*\)</span>，然后对 <span class="math inline">\(\alpha\)</span> 最大化</p>
<p>由上一步求出了新的朗格朗日函数不包含 <span class="math inline">\(w\)</span> 和 <span class="math inline">\(b\)</span>，得到：</p>
<p><span class="math inline">\(\underset{\alpha}{max}\sum_{i=1}^n \alpha_i-\frac{1}{2}\sum_{i,j=1}^n\alpha_i\alpha_jy_iy_jx_i^Tx_j\)</span></p>
<p><span class="math inline">\(s.t.,\ \alpha_i\geq 0,i=1,...,n\)</span></p>
<p><span class="math inline">\(\sum_{i=1}^n \alpha_i y_i=0\)</span></p>
<p>求得 <span class="math inline">\(L(w,b,\alpha)\)</span> 关于 <span class="math inline">\(w\)</span> 和 <span class="math inline">\(b\)</span> 最小化，以及对 <span class="math inline">\(\alpha\)</span> 的极大化之后，最后使用 SMO 算法求解对偶问题中的拉格朗日乘子 <span class="math inline">\(\alpha\)</span>，由此可以求出 <span class="math inline">\(\alpha_i\)</span></p>
<p>根据 <span class="math inline">\(w=\sum_{i=1}^n \alpha_i y_i x_i\)</span> 可求出 <span class="math inline">\(w\)</span>, 然后通过 <span class="math inline">\(b^*=y_j-\sum_{i=1}^n\alpha_i y_i(x_i^Tx_j),\alpha_j&gt;0\)</span> 求出 <span class="math inline">\(b\)</span>。而分类函数 <span class="math inline">\(f(x)=w^Tx+b\)</span>，其中 <span class="math inline">\(w=\sum_{i=1}^n \alpha_iy_ix_i\)</span>，代入得到分类函数 <span class="math inline">\(f(x)=\sum_{i=1}^n \alpha_iy_i\langle x_i,x\rangle+b\)</span></p></li>
</ol>
<h2 id="线性不可分问题">线性不可分问题</h2>
<p>由上面的分类函数可以看出，新的数据点 <span class="math inline">\(x^*\)</span> 的分类，只需要计算它与训练数据点的内积即可（可用于推广 Kernel）。而 SVM 中的支持向量（supporting vectors）是对应 <span class="math inline">\(\alpha_i\neq 0\)</span> 的训练数据点。</p>
<p>感性理解就是，<span class="math inline">\(x^*\)</span> 分类其实只与分类超平面有关，而这个超平面只受支持向量的影响，所以其他的训练数据点不需要参与决策</p>
<p>理性理解，回到我们的拉格朗日乘式子，<span class="math inline">\(\underset{\alpha_i\geq 0}{max}\ \frac{1}{2}||w||^2-\sum_{i=1}^n \alpha_i(y_i(w^Tx_i+b)-1)\)</span></p>
<p>对于一个支持向量来说，<span class="math inline">\(y_i(w^Tx_i+b)-1=0\)</span>，<span class="math inline">\(\alpha_i\)</span> 可以不为 0；对于非支持向量的数据点来说<span class="math inline">\(y_i(w^Tx_i+b)-1&gt;0\)</span>， 为了求极大，必须满足 <span class="math inline">\(\alpha_i=0\)</span>（<span class="math inline">\(\alpha_i\geq 0\)</span>）</p>
<h2 id="松弛变量使用">松弛变量使用</h2>
<p>加入松弛变量是为了解决离群点的问题，因为当训练数据中存在函数间隔大于 1 时，采用一个松弛变量来实现对一些数据点的软间隔</p>
<p>由此，原目标函数：</p>
<p><span class="math inline">\(max\ \frac{1}{2}||w||^2;\ y_i(w^Tx_i+b)\geq 1,i=1,...,n\)</span></p>
<p>就变成了新的目标函数：</p>
<p><span class="math inline">\(max\ \frac{1}{2}||w||^2+C\sum_{i=1}^n \xi_i;\ y_i(w^Tx_i)-b\geq 1- \xi_i, \xi_i\geq 0,i=1,...,n\)</span></p>
<p>其中 <span class="math inline">\(C&gt;0\)</span> 用于平衡对两个目标：（1）最大化几何间隔；（2）使误分点尽量少。当 <span class="math inline">\(C\)</span> 很大时，对误分类的惩罚大（着重考虑减少误分点）；相反，就更重视最大化几何间隔</p>
<p>用拉格朗日乘数法对上面的新目标求对偶问题得</p>
<ol type="1">
<li>拉格朗日函数</li>
</ol>
<p><span class="math inline">\(L(w,b,\alpha,\xi,\mu)=\frac{1}{2}||w||^2+C\sum_{i=1}^n \xi_i\)</span></p>
<p><span class="math inline">\(-\sum_{i=1}^n\alpha_i(y_i(w^Tx_i+b)-1+\xi_i)-\sum_{i=1}^n\mu_i\xi_i\)</span></p>
<ol start="2" type="1">
<li>对偶问题</li>
</ol>
<p><span class="math inline">\(\underset{\alpha}{min}\frac{1}{2}\sum_{i,j=1}^n \alpha_i\alpha_jy_iy_j(x_i^Tx_j)-\sum_{i=1}^n\alpha_i\)</span></p>
<p><span class="math inline">\(s.t.\ \sum_{i=1}^n \alpha_i y_i=0,0 \leq \alpha_i\leq C,i=1,...,n\)</span></p>
<ol start="3" type="1">
<li>求解 （1）求解得到最优 <span class="math inline">\(\alpha^*=(\alpha_1^*,\alpha_2^*,...,\alpha_n^*)^T\)</span></li>
</ol>
<p>（2）计算 <span class="math inline">\(w^*=\sum_{i=1}^n\alpha_i^* y_ix_i\)</span></p>
<p>（3）选择一个数据 <span class="math inline">\(j,0&lt;\alpha_j^*&lt;C\)</span>，计算 <span class="math inline">\(b^*=y_j-\sum_{i=1}^n y_i\alpha_i^*(x_i^Tx_j)\)</span></p>
<p>（4）得到决策函数 <span class="math inline">\(f(x)=sign({w^*}^Tx+b)\)</span></p>
<p>软间隔支持向量 <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210617113314.png" /> 软间隔支持向量可以在三个位置（1）间隔边界上；（2）间隔边界与分离超平面之间；（3）分离超平面误分的那一侧。 若 <span class="math inline">\(a_i^*&lt;C\)</span>，则 <span class="math inline">\(\xi_i=0\)</span>，支持向量 <span class="math inline">\(x_i\)</span> 恰好落在间隔边界上；若 <span class="math inline">\(a_i^*=C, 0&lt;\xi_i&lt;1\)</span>，则分类正确，<span class="math inline">\(x_i\)</span> 在间隔边界与分离超平面之间；若 <span class="math inline">\(a_i^*=C,\xi_i=1\)</span>，则 <span class="math inline">\(x_i\)</span> 在分离超平面上；若 <span class="math inline">\(a_i^*=C,\xi_i &gt; 1\)</span>，则 <span class="math inline">\(x_i\)</span> 位于分离超平面误分一侧</p>
<h2 id="核函数">核函数</h2>
<p>之前讲到对原问题求偶问题，第二优点就是方便引入核函数。核函数的作用主要是为了解决线性不可分的数据。它的思想是通过<strong>隐式</strong>地将低维空间的数据隐式到高维空间，然后对数据进行线性分割，但是只需要通过低维非线性计算既可以实现。</p>
<p>引入核函数后的目标函数</p>
<p><span class="math inline">\(\underset{\alpha}{min}\frac{1}{2}\sum_{i,j=1}^n \alpha_i\alpha_jy_iy_j\kappa(x_i^,x_j)-\sum_{i=1}^n\alpha_i\)</span> <span class="math inline">\(s.t.\ \sum_{i=1}^n \alpha_i y_i=0,0 \leq \alpha_i\leq C,i=1,...,n\)</span></p>
<h2 id="smo-sequential-minimal-optimization-算法">SMO (Sequential Minimal Optimization) 算法</h2>
<p>SVM 推导过程：分类函数，最大化分类间隔，max1/||w||，min1/2||w||^2，凸二次规划，拉格朗日函数，转化为对偶问题，SMO算法，都为寻找一个最优解，一个最优分类平面</p>
<h1 id="参考-references">参考 (References)</h1>
<ol type="1">
<li><a href="https://blog.csdn.net/v_JULY_v/article/details/7624837">支持向量机通俗导论</a></li>
<li>李航老师统计机器学习第2版</li>
</ol>
]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title>“聚类指标”</title>
    <url>/2021/06/06/Machine%20Learning/%E2%80%9C%E8%81%9A%E7%B1%BB%E6%8C%87%E6%A0%87%E2%80%9D/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>compactness：同一个簇内对象间的距离</p>
<p>separation：度量一个簇和其他簇的分离程度</p>
<p>connectivity：空间距离相近的对象放在同一聚类的程度 <span id="more"></span> # Silhouette Coefficient 衡量一个对象与同簇的对象的相似性对比它与其他簇的对象的相似性的程度</p>
<p>假设 <span class="math inline">\(C_i\)</span> 是一个包含了数据 <span class="math inline">\(i\)</span> 的簇，对于数据点 <span class="math inline">\(i, i\in C_i\)</span> 而言，有</p>
<p><span class="math inline">\(a(i)=\frac{1}{C_i|-1}\sum_{j\in C_i, i\neq j}d(i,j)\)</span></p>
<p><span class="math inline">\(b(i)=\underset{k\neq i}{min}\frac{1}{C_k|}\sum_{j\in C_k}d(i,j)\)</span></p>
<p>数据 <span class="math inline">\(i\)</span> 的 Silhouette 值定义为 <span class="math inline">\(s(i)\frac{b(i)-a(i)}{max\{a(i), b(i)\}},\ if\ |C_i|&gt;1\)</span>; <span class="math inline">\(s(i)=0,\ if \ |C_i|=1\)</span>，而 <span class="math inline">\(-1\leq s(i)\leq 1\)</span>。当 <span class="math inline">\(s(i)\)</span> 越靠近 1，说明数据 <span class="math inline">\(i\)</span> 被聚类在越适合的簇中，若 <span class="math inline">\(s(i)=0\)</span>，说明数据 <span class="math inline">\(i\)</span> 处在两个簇中间，若 <span class="math inline">\(s(i)\)</span> 越靠近 -1，说明数据 <span class="math inline">\(i\)</span> 很可能被错分了</p>
<p>对一个 <span class="math inline">\(K\)</span> 个簇的集合，整体的 Silhouette Coefficient 定义为</p>
<p><span class="math inline">\(SC=\underset{k}{max} \frac{1}{|C_k|}\sum_{i\in C_k} s(i)\)</span></p>
<h1 id="dunn-index">Dunn Index</h1>
<p>对于一个具有 <span class="math inline">\(K\)</span> 个簇的集合，它的 Dunn Index 定义如下：</p>
<p><span class="math inline">\(DI=\frac{\underset{1\leq i&lt;j \leq K}{min}\delta(C_i, C_j)}{\underset{1\leq k \leq K}{max} \Delta_k}\)</span></p>
<p>其中 <span class="math inline">\(\delta(C_i, C_j)\)</span> 指代簇间距离，<span class="math inline">\(\Delta_k\)</span> 指代簇内聚类（直径），这个值越小越好</p>
<h2 id="簇间距离的各种定义">簇间距离的各种定义</h2>
<ol type="1">
<li>两个簇之间最近的两个数据点之间的距离 <span class="math inline">\(\delta(C_i, C_j)=\underset{x\in C_i, y\in C_j}{min}d(x,y)\)</span></li>
<li>两个簇之间最远的两个数据点之间的距离 <span class="math inline">\(\delta(C_i, C_j)=\underset{x\in C_i, y\in C_j}{max}d(x,y)\)</span></li>
<li>两个簇中心的距离 <span class="math inline">\(\delta(C_i, C_j)=d(\mu_i, \mu_j), \mu_k=\frac{\sum_{x\in C_k} x}{|C_k|}\)</span></li>
</ol>
<h2 id="簇内聚类直径的各种定义">簇内聚类（直径）的各种定义</h2>
<ol type="1">
<li>簇内距离最大的数据对的聚类 <span class="math inline">\(\Delta_k = \underset{x,y\in C_k}{max} d(x,y)\)</span></li>
<li>簇内所有词对的平均距离 <span class="math inline">\(\Delta_k = \frac{2}{|C_k|(|C_k|-1)}\sum_{x,y\in C_k,x\neq y}d(x,y)\)</span></li>
<li>簇内所有点到簇中心的聚类 <span class="math inline">\(\Delta_k = \frac{\sum_{x\in C_k} d(x,\mu_k)}{|C_k|}\)</span></li>
</ol>
<h1 id="rand-index-需要-gold-standard一个人工分好的簇集合">Rand Index (需要 Gold Standard：一个人工分好的簇集合)</h1>
<p>假设一个集合 <span class="math inline">\(S=\{o_1, o_2,...,o_n\}\)</span> 包含 <span class="math inline">\(n\)</span> 个元素。对它有一个划分 <span class="math inline">\(X=\{X_1,X_2,...,X_r\}\)</span>，包含了 <span class="math inline">\(r\)</span> 个子集；一个划分 <span class="math inline">\(Y={Y_1,Y_2,...,Y_s}\)</span>，包含了 <span class="math inline">\(s\)</span> 个子集，定义如下几个符号：</p>
<h2 id="rand-index">Rand Index</h2>
<p><span class="math inline">\(a\)</span>: 出现在 <span class="math inline">\(X\)</span> 中相同子集，并且出现在 <span class="math inline">\(Y\)</span> 中相同子集的元素对的个数 <span class="math inline">\((x,y), x\in X_i, y\in X_i, x\in Y_j, y\in Y_j\)</span></p>
<p><span class="math inline">\(b\)</span>: 出现在 <span class="math inline">\(X\)</span> 中不同子集，并且出现在 <span class="math inline">\(Y\)</span> 中不同子集的元素对的个数 <span class="math inline">\((x,y), x\in X_i, y\notin X_i, x\notin Y_j, y\in Y_j\)</span></p>
<p><span class="math inline">\(c\)</span>: 出现在 <span class="math inline">\(X\)</span> 中相同子集，并且出现在 <span class="math inline">\(Y\)</span> 中不同子集的元素对的个数 <span class="math inline">\((x,y), x\in X_i, y\in X_i, x\notin Y_j, y\in Y_j\)</span></p>
<p><span class="math inline">\(d\)</span>: 出现在 <span class="math inline">\(X\)</span> 中不同子集，并且出现在 <span class="math inline">\(Y\)</span> 中相同子集的元素对的个数 <span class="math inline">\((x,y), x\notin X_i, y\in X_i, x\in Y_j, y\in Y_j\)</span></p>
<p>Rand Index 的定义为 <span class="math inline">\(RI=\frac{a+b}{a+b+c+d}=\frac{a+b}{\tbinom{n}{2}}=\frac{TP+TN}{TP+TN+FP+FN}\)</span>，它衡量了两个划分的相似程度</p>
<h2 id="adjusted-rand-index">Adjusted Rand Index</h2>
<table>
<thead>
<tr class="header">
<th></th>
<th><span class="math inline">\(Y_1\)</span></th>
<th><span class="math inline">\(Y_2\)</span></th>
<th>...</th>
<th><span class="math inline">\(Y_s\)</span></th>
<th>sum</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong><span class="math inline">\(X_1\)</span></strong></td>
<td><span class="math inline">\(n_{11}\)</span></td>
<td><span class="math inline">\(n_{2}\)</span></td>
<td>...</td>
<td><span class="math inline">\(n_{1s}\)</span></td>
<td><span class="math inline">\(a_{1}\)</span></td>
</tr>
<tr class="even">
<td><strong><span class="math inline">\(X_2\)</span></strong></td>
<td><span class="math inline">\(n_{21}\)</span></td>
<td><span class="math inline">\(n_{22}\)</span></td>
<td>...</td>
<td><span class="math inline">\(n_{2s}\)</span></td>
<td><span class="math inline">\(a_{2}\)</span></td>
</tr>
<tr class="odd">
<td><strong>...</strong></td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="even">
<td><strong><span class="math inline">\(X_r\)</span></strong></td>
<td><span class="math inline">\(n_{r1}\)</span></td>
<td><span class="math inline">\(n_{r2}\)</span></td>
<td>...</td>
<td><span class="math inline">\(n_{rs}\)</span></td>
<td><span class="math inline">\(a_{r}\)</span></td>
</tr>
<tr class="odd">
<td><strong>sum</strong></td>
<td><span class="math inline">\(b_{1}\)</span></td>
<td><span class="math inline">\(b_{2}\)</span></td>
<td>...</td>
<td><span class="math inline">\(b_{s}\)</span></td>
<td></td>
</tr>
</tbody>
</table>
<p>Adjusted Rand Index 的定义为 <span class="math inline">\(ARI=\frac{\sum_{ij}\tbinom{n_{ij}}{2}-\left[\sum_i \tbinom{a_i}{2} \sum_j \tbinom{b_j}{2}\right]/\tbinom{n}{2}}{\frac{1}{2}\left[\sum_i \tbinom{a_i}{2} \sum_j \tbinom{b_j}{2}\right]-\left[\sum_i \tbinom{a_i}{2} \sum_j \tbinom{b_j}{2}\right]/\tbinom{n}{2}}\)</span>，它是基于 Rand Index 的改进，用于应对当 <span class="math inline">\(r\neq s\)</span> 的情况</p>
<h1 id="micro-precision-recall-f1-需要-gold-standard一个人工分好的簇集合">Micro Precision, Recall, F1 (需要 Gold Standard：一个人工分好的簇集合)</h1>
<p>这个评判指标完全和分类中的一样，<a href="https://jason-hao.cyou/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%88%86%E7%B1%BB%E6%8C%87%E6%A0%87.html">链接在这里</a> 唯一不同的是如何决定 cluster 跟 Gold Standard 中的哪个 class 去计算指标，相对于先要给出 cluster 的class 标签。大致有两种方式：（1）由人工决定，这在一些词聚类上可以使用；（2）用 majority voting <span class="math inline">\(\underset{1\leq k\leq K}{argmax}|Cluster_i \cap Class_k|\)</span> 来决定 cluster <span class="math inline">\(i\)</span> 的 class 标签</p>
<h1 id="topic-coherence">Topic Coherence</h1>
<p><a href="https://jason-hao.cyou/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%B8%BB%E9%A2%98%E6%8C%87%E6%A0%87.html">Reference Page</a></p>
<h1 id="参考-references">参考 (References)</h1>
<ol type="1">
<li>https://en.wikipedia.org/wiki/Silhouette_(clustering)</li>
<li>https://en.wikipedia.org/wiki/Dunn_index</li>
<li>https://en.wikipedia.org/wiki/Rand_index</li>
<li>http://qpleple.com/topic-coherence-to-evaluate-topic-models/</li>
</ol>
]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>聚类</tag>
        <tag>clustering</tag>
      </tags>
  </entry>
  <entry>
    <title>主题指标</title>
    <url>/2021/06/07/Machine%20Learning/%E4%B8%BB%E9%A2%98%E6%8C%87%E6%A0%87/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>通常 Topic Model 对文本数据集建模，模型对训练数据集拟合的程度自然而然的使用来作为衡量模型好坏的指标，但是这样学出来的主题通常与人对主题的理解有较大差异。由此提出了一些用于衡量 Topic 质量的指标，主要分为两种（1）intrinsic measures；（2）extrinsic measures</p>
<span id="more"></span>
<p>在这篇最新的 <a href="https://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf">paper</a> 中，主题质量的衡量分为四个步骤：</p>
<ol type="1">
<li>Segmentation of Word Subsets 某个主题内词子集的划分</li>
<li>Probability Estimation 基本的概率值的计算</li>
<li>Confirmation Measure 支持度计算</li>
<li>Aggregation 整合所有主题上的主题指标</li>
</ol>
<h1 id="segmentation-of-word-subsets">1 Segmentation of Word Subsets</h1>
<p>一个词集合 <span class="math inline">\(W\)</span> 的一致性（Coherence）是用于描述主题内一个词子集被其他词子集支持的程度。本步骤主要的任务是构造一个词子集对集合 <span class="math inline">\(S\)</span>，数学表示为 <span class="math inline">\(S=\{(W&#39;, W^*)\}, W&#39;\cap W^* = \emptyset，W&#39;\subseteq W, W^* \subseteq W\)</span></p>
<h1 id="probability-estimation">2 Probability Estimation</h1>
<p>考虑数据单元的粒度大小，对于词有四个不同的概率计算方法</p>
<p><span class="math inline">\(P_{bd}\)</span>: Boolean Document Estimation. 在文档级别上对出现的词只计数一次</p>
<p><span class="math inline">\(P_{bp}\)</span>: Boolean Paragraph Estimation. 在段落级别上对出现的词只计数一次</p>
<p><span class="math inline">\(P_{bs}\)</span>: Boolean Sentence Estimation. 在句子级别上对出现的词只计数一次</p>
<p><span class="math inline">\(P_{sw}\)</span>: Boolean Sliding Window Estimation. 在窗口（窗口大小可自定义）级别上对出现的词只计数一次</p>
<p>概率 <span class="math inline">\(P(w_i, w_j)=\frac{Count(w_i,w_j)}{|D|}\)</span></p>
<p>概率 <span class="math inline">\(P(w_i)=\frac{Count(w_i)}{|D|}\)</span></p>
<p>其中 <span class="math inline">\(Count(w_i,w_j)\)</span> 是同时出现 <span class="math inline">\(w_i\)</span> 和 <span class="math inline">\(w_j\)</span> 的数据单元个数，<span class="math inline">\(Count(w_i)\)</span> 是包含 <span class="math inline">\(w_i\)</span> 的数据单元的数量，<span class="math inline">\(|D|\)</span> 是数据集中数据单元的数量。当数据单元的粒度为文档的时候，<span class="math inline">\(|D|\)</span> 就是总的文档的数量；当粒度为 Window 的时候，<span class="math inline">\(|D|\)</span> 就是总的窗口的数量</p>
<h1 id="confirmation-measure">3 Confirmation Measure</h1>
<p>这个步骤就是真正定义 topic score 衡量主题质量的方法了，各种 Topic Coherence 计算方法在这个步骤上不同，基于上一步中的概率公式来计算</p>
<h2 id="umass-mimno11a">UMass <a href="">Mimno11a</a></h2>
<p><span class="math inline">\(score(w_i,w_j)=log\frac{P_{bd}(w_i,w_j)+\epsilon}{P_{bd}(w_j)}, j&lt;i\)</span></p>
<h2 id="uci-newman10a">UCI <a href="">Newman10a</a></h2>
<p><span class="math inline">\(score(w_i,w_j)=log\frac{P_{sw}(w_i,w_j)+\epsilon}{P_{sw}(w_i)P_{sw}(w_j)}, j&lt;i\)</span></p>
<h2 id="npmi">NPMI</h2>
<p><span class="math inline">\(score(w_i,w_j)=\frac{log\frac{P_{sw}(w_i,w_j)+\epsilon}{P_{sw}(w_i)P_{sw}(w_j)}}{-log(P_{sw}(w_i,w_j))+\epsilon}, j&lt;i\)</span></p>
<h2 id="word2vec-based-similarity-score">Word2vec based Similarity Score</h2>
<p><span class="math inline">\(score(w_i,w_j) = cosine(V_{w_i}, V_{w_j}), j&lt;i\)</span></p>
<h2 id="tf-idf-based-improvement-for-umass">TF-IDF based improvement for UMass</h2>
<p><span class="math inline">\(score(w_i,w_j) = log(\frac{\sum_{d=1}^{|D|} \left(tfidf(d,w_i)\times tfidf(d,w_j)+\epsilon\right)}{\sum_{d=1}^{|D|} tfidf(d,w_j)}), j&lt;i\)</span></p>
<h2 id="tbuckets">TBuckets</h2>
<p><a href="https://www.aclweb.org/anthology/E17-2070/">Reference Paper</a></p>
<h1 id="aggregation">4 Aggregation</h1>
<p>上面的三个步骤是针对一个主题的计算方法，第四步是为了整合多个 Topic 上的得分。比如和取多个主题得分的均值，中位数或者几何中心等等</p>
<h1 id="参考-references">参考 (References)</h1>
<ol type="1">
<li><a href="https://www.aclweb.org/anthology/D12-1087.pdf">Exploring Topic Coherence over many models and many topics 2012</a></li>
<li><a href="https://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf">Exploring the Space of Topic Coherence Measures 2015</a></li>
<li><a href="https://radimrehurek.com/gensim/models/coherencemodel.html">Gensim Implements of Topic Coherence Measurements</a></li>
<li>https://labs.imaginea.com/how-to-measure-topic-coherence/</li>
<li>http://qpleple.com/topic-coherence-to-evaluate-topic-models/</li>
<li>http://qpleple.com/bib/#Newman10a</li>
</ol>
]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
  </entry>
  <entry>
    <title>分类指标</title>
    <url>/2021/05/31/Machine%20Learning/%E5%88%86%E7%B1%BB%E6%8C%87%E6%A0%87/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="predifinition">Predifinition</h1>
<p>Suppose that there is a set <span class="math inline">\(s\)</span> to be predicted as class <span class="math inline">\(c\)</span>. A data point in <span class="math inline">\(s\)</span> is can be predicted as positive (P, means belonging to <span class="math inline">\(c\)</span>), or negative (N, means belonging to other classes)</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Predicted P</th>
<th>Predicgted N</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>P</td>
<td>TP</td>
<td>FN</td>
</tr>
<tr class="even">
<td>N</td>
<td>FP</td>
<td>TN</td>
</tr>
</tbody>
</table>
<span id="more"></span>
<p>TP: Actual Positive, Predicted as Positive FN: Actual Positive, Predicted as Negative TN: Actual Negative, Predicted as Negative FP: Actual Negative, Predicted as Positive</p>
<h1 id="standard-criteria">Standard Criteria</h1>
<p>Precision</p>
<p><span class="math inline">\(P(c)=\frac{TP_c}{TP_c + FP_c}\)</span></p>
<p>Recall</p>
<p><span class="math inline">\(R(c)=\frac{TP_c}{TP_c + FN_c}\)</span></p>
<p>F1</p>
<p><span class="math inline">\(F1(c)=2× \frac{P(c)×R(c)}{P(c)+R(c)}\)</span></p>
<h1 id="macro-criteria">Macro Criteria</h1>
<p>Note that the Macro Criteria will highly influenced by the small classes. |C| is the number of classes.</p>
<p>Macro Precision</p>
<p><span class="math inline">\(P_{macro}=\sum_{c}\frac{P(c)}{|C|}\)</span></p>
<p>Macro Recall</p>
<p><span class="math inline">\(R_{macro}=\sum_c\frac{R(c)}{|C|}\)</span></p>
<p>Macro F1</p>
<p><span class="math inline">\(F1_{macro}=\sum_c\frac{F1(c)}{|C|}\)</span></p>
<h1 id="micro-criteria">Micro Criteria</h1>
<p><span class="math inline">\(P_{micro}=R_{micro}=F1_{micro}=\sum_c\frac{TP(c)}{|D|}\)</span> , where |D| is the size of data set.</p>
<h1 id="weighted-criteria">Weighted Criteria</h1>
<p>Weighted Precision</p>
<p><span class="math inline">\(P_{weighted}=\sum_c\frac{|c|}{|D|}P(c)\)</span></p>
<p>Weighted Recall</p>
<p><span class="math inline">\(R_{weighted}=\sum_c\frac{|c|}{|D|}R(c)\)</span></p>
<p>Weighted F1 <span class="math inline">\(F1_{weighted}=\sum_c\frac{|c|}{|D|}F1(c)\)</span></p>
<h1 id="参考-references">参考 (References)</h1>
]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>Machine Learning</tag>
        <tag>分类</tag>
      </tags>
  </entry>
  <entry>
    <title>估计方法</title>
    <url>/2021/06/15/Machine%20Learning/%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210615200450.png" /></p>
<span id="more"></span>
<h1 id="预定义符号">预定义符号</h1>
<p>训练数据：<span class="math inline">\(D=\{(x_1,y_1),(x_2,y_2),...,(x_n, y_n)\}\)</span></p>
<p>模型参数：<span class="math inline">\(\theta\)</span></p>
<p>预测数据：<span class="math inline">\(x^*\)</span></p>
<p>概率函数与似然函数</p>
<p>对于函数 <span class="math inline">\(P(x|\theta)\)</span>，从不同角度分为两种情况：</p>
<ol type="1">
<li>如果 <span class="math inline">\(\theta\)</span> 已知，<span class="math inline">\(x\)</span> 是变量，则 <span class="math inline">\(P(x|\theta)\)</span> 称为概率函数，表示不同 <span class="math inline">\(x\)</span> 出现的概率</li>
<li>如果 <span class="math inline">\(x\)</span> 已知，<span class="math inline">\(\theta\)</span> 是未知变量，则 <span class="math inline">\(P(x|\theta)\)</span> 称为概率函数，表示不同 <span class="math inline">\(\theta\)</span> 下，<span class="math inline">\(x\)</span> 出现的概率，也记作 <span class="math inline">\(L(\theta|x)\)</span></li>
</ol>
<h1 id="ml最大似然估计频率主义">ML（最大似然估计，频率主义）</h1>
<p>ML 的思想是找出使得观测数据 <span class="math inline">\(D\)</span> 发生概率最大的参数</p>
<p>学习目标</p>
<p><span class="math inline">\(\theta_{ML}=\underset{\theta}{argmax}\ p(D|\theta)\)</span></p>
<p>通常对目标函数对 <span class="math inline">\(\theta\)</span> 求导，令导师等于 0 即可求出最优解</p>
<p><strong>预测</strong></p>
<p><span class="math inline">\(p(\hat y|x^*,\theta_{ML})\)</span></p>
<p><strong>缺点</strong></p>
<ol type="1">
<li>没有考虑后验概率</li>
<li>容易过拟合数据</li>
</ol>
<p>最大似然估计的求解步骤：</p>
<ol type="1">
<li>确定似然函数</li>
<li>将似然函数转换为对数似然函数</li>
<li>求对数似然函数的最大值（求导，解似然方程）</li>
</ol>
<h1 id="map最大后验估计频率主义">MAP（最大后验估计，频率主义）</h1>
<p>ML 把参数 <span class="math inline">\(\theta\)</span> 看做一个固定值，而 MAP 则认为 <span class="math inline">\(\theta\)</span> 是一个随机变量，<span class="math inline">\(\theta\)</span> 要满足某种概率分布，即先验分布，因此求解 <span class="math inline">\(\theta\)</span> 时不仅要考虑似然函数 <span class="math inline">\(p(D|\theta)\)</span> 还要考虑 <span class="math inline">\(\theta\)</span> 的先验分布 <span class="math inline">\(p(\theta)\)</span>。MAP 通常被认为是正则化的 ML</p>
<p><strong>学习目标</strong></p>
<p><span class="math inline">\(\theta_{MAP}=\underset{\theta}{argmax}\ p(D|\theta)p(\theta)\)</span></p>
<p>目标式中可以对两个概率加 <span class="math inline">\(log\)</span> 函数</p>
<p><strong>预测</strong></p>
<p><span class="math inline">\(p(\hat y|x^*,\theta_{MAP})\)</span></p>
<p><strong>优势</strong></p>
<ol type="1">
<li>加入了先验知识</li>
<li><span class="math inline">\(p(\theta)\)</span> 相当于起到了正则化的作用，如果 <span class="math inline">\(p(\theta)\)</span> 服从高斯分布，则相当于加了 L2 norm；如果如果 <span class="math inline">\(p(\theta)\)</span> 服从拉普拉斯分布，相当于加了 L1 norm？</li>
</ol>
<p>最大后验概率估计的求解步骤：</p>
<ol type="1">
<li>确定参数的先验分布以及似然函数</li>
<li>确定参数的后验分布函数</li>
<li>将后验分布函数转换为对数函数</li>
<li>求对数函数的最大值（求导，解方程）</li>
</ol>
<h1 id="beyesian贝叶斯估计贝叶斯主义">Beyesian（贝叶斯估计，贝叶斯主义）</h1>
<p>贝叶斯估计要解决的不是如何估计参数，而是用来估计新测量数据出现的概率。贝叶斯估计同样假定 <span class="math inline">\(\theta\)</span> 是一个随机变量，但贝叶斯估计并不是直接估计出θ的某个特定值，而是估计 <span class="math inline">\(\theta\)</span> 的分布，这是贝叶斯估计与最大后验概率估计不同的地方。在贝叶斯估计中，先验 <span class="math inline">\(p(D)\)</span> 是不能忽视的。在已知 <span class="math inline">\(D\)</span> 的情况下，<span class="math inline">\(\theta\)</span> 的分布描述为后验分布 <span class="math inline">\(p(\theta|D)\)</span>，如果后验分布范围较窄，则估计的准确度相对较高；反之，后验分布范围较广，则估计的准确度较低</p>
<p><strong>学习目标</strong></p>
<p>计算 <span class="math inline">\(p(\theta|D)\)</span></p>
<p><strong>预测</strong></p>
<p><span class="math inline">\(p(x^*|D)=\int_{\theta} p(x^*|\theta)p(\theta|D)\ d\theta=\int_{\theta}p(x^*|\theta)\frac{p(\theta)p(D|\theta)}{p(D)}d\theta\)</span></p>
<p>贝叶斯估计先为所有可能的模型计算一个权重，最终的 predict 结果是根据所有模型按照权重加权投出的结果</p>
<p><strong>难点</strong></p>
<p>贝叶斯估计估计结果可靠，但是为了给每个模型 <span class="math inline">\(\theta\)</span> 计算一个权重，也就是后验概率 <span class="math inline">\(p(\theta|D)\)</span>，为了计算这个后验概率我们需要计算</p>
<p><span class="math inline">\(p(\theta|D)=\frac{p(\theta)p(D|\theta)}{\int_{\theta}p(\theta)p(D|\theta)d\theta}\)</span></p>
<p>但是要分母中的积分计算代价是非常大的，为此整个贝叶斯领域的核心技术在于近似计算 <span class="math inline">\(p(\theta|D)\)</span>，称之为 Beyesian Inference。对于贝叶斯估计，我们希望近似计算分母 <span class="math inline">\(p(D)\)</span>，通过对 <span class="math inline">\(\theta\)</span> 采样实现。 <span class="math inline">\(p(D)=\frac{1}{S}\sum_{s=1}^S p(D|\theta^{(s)})\)</span></p>
<p>此外，还可以通过为后验概率分布选择适合的先验分布，从而实现后验概率分布的直接计算，通常能表示为 「后验 = 先验 + 数据」或者 「<span class="math inline">\(posterior\sim prior \times likelihood\)</span>」。如果没有共轭，在需要计算多批新样本数据下的后验分布时，每次计算都需要整体重新计算</p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210616120647.png" /></p>
<p>如果后验分布与先验分布属于同类（分布形式相同），则先验分布与后验分布被称为共轭分布，而先验分布被称为似然函数的共轭先验</p>
<p>比如抛硬币这个实验，结果（也就是 Likelihood）满足二项分布，而二项分布的参数满足分布 <span class="math inline">\(Beta(\theta|\alpha,\beta)=\frac{1}{B(\alpha,\beta)}x^{\alpha-1}x^{\beta-1}\)</span>（先验分布），如果抛硬币的 10 个结果中产生了 6 个正面（概率为 <span class="math inline">\(\theta\)</span>），4 个反面（概率为 <span class="math inline">\(1-\theta\)</span>）。那么后验概率的计算为</p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210616121309.png" /></p>
<p>贝叶斯估计的求解步骤：</p>
<ol type="1">
<li>确定参数的似然函数</li>
<li>确定参数的先验分布，应是后验分布的共轭先验</li>
<li>确定参数的后验分布函数</li>
<li>根据贝叶斯公式求解参数的后验分布</li>
</ol>
<p><strong>注</strong>：二项分布参数的共轭先验是Beta分布，多项式分布参数的共轭先验是Dirichlet分布，指数分布参数的共轭先验是Gamma分布，⾼斯分布均值的共轭先验是另⼀个⾼斯分布，泊松分布的共轭先验是Gamma分布</p>
<h1 id="这个三个估计方法差别">这个三个估计方法差别</h1>
<p>比如你是班里的班长，你有个问题想知道答案，你可以问所有的班里的学生。 一种方案是，问一个学习最好的同学。 另一种方案是，问所有的同学，然后把答案综合起来，但综合的时候，会按照每个同学的成绩好坏来做个权重。 第一种方案的思想类似于ML,MAP，第二种方案类似于贝叶斯模型。</p>
<h1 id="参考-references">参考 (References)</h1>
<ol type="1">
<li><a href="https://yuanxiaosc.github.io/2018/06/20/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1%E3%80%81%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1%E3%80%81%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E4%BC%B0%E8%AE%A1%E4%B8%89%E8%80%85%E7%9A%84%E5%8C%BA%E5%88%AB/">贝叶斯估计、最大似然估计和最大后验估计 参考1</a></li>
<li><a href="http://noahsnail.com/2018/05/17/2018-05-17-%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1%E3%80%81%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1%E3%80%81%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87%E4%BC%B0%E8%AE%A1/">贝叶斯估计、最大似然估计和最大后验估计 参考2</a></li>
</ol>
]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>参数估计</tag>
      </tags>
  </entry>
  <entry>
    <title>朴素贝叶斯法</title>
    <url>/2021/05/31/Machine%20Learning/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><span id="more"></span>
<h1 id="问题描述">问题描述</h1>
<p>数据集：<span class="math inline">\(D={(x_1, y_1), (x_2, y_2), ..., (x_N, y_N)}\)</span>. 其中 <span class="math inline">\(x\in X, X\subseteq \mathbf{R}^n\)</span>; <span class="math inline">\(y\in Y, Y={c_1, C_2, ..., C_K}\)</span>.</p>
<p>当给定一个新的数据 <span class="math inline">\(x\)</span>，它的分类是什么？ 即求 <span class="math inline">\(P(Y=c_k|X=x)=\frac{P(Y=c_k)P(X=x|Y=c_k)}{P(X=x)}=\frac{P(Y=c_k)P(X=x|Y=c_k)}{\sum_{k&#39;}P(Y=c_{k&#39;})P(X=x|Y=c_{k&#39;})}\)</span></p>
<h1 id="问题建模">问题建模</h1>
<p>为此对于上面的问题，最重要的是对先验概率 <span class="math inline">\(P(Y=c_k), k=1,2,...,K\)</span> 和条件概率 <span class="math inline">\(P(X=x|Y=c_k)=P(X^{(1)}=x^{(1)},...,X^{(n)}=x^{(n)}|Y=c_k), k=1,2,...,K\)</span> 进行建模，或者说对联合概率 <span class="math inline">\(P(X,Y)=P(Y)P(X|Y)\)</span> 进行建模.</p>
<p>最终 <span class="math inline">\(x\)</span> 的分类为 <span class="math inline">\(y=f(x)=\underset{c_k}{argmax}\frac{P(Y=c_k)P(X=x|Y=c_k)}{\sum_{k&#39;}P(Y=c_{k&#39;})P(X=x|Y=c_{k&#39;})}\)</span></p>
<h1 id="条件独立性假设">条件独立性假设</h1>
<p>假设 <span class="math inline">\(x\)</span> 的每一个维度都有 <span class="math inline">\(V\)</span> 个取值，那么所需要的参数个数是 <span class="math inline">\(K\times V^n\)</span>, 为此，朴素贝叶斯对条件概率分布做了条件独立性假设，令 <span class="math inline">\(P(X=x|Y=c_k)=P(X^{(1)}=x^{(1)},...,X^{(n)}=x^{(n)}|Y=c_k)=\prod_{j=1}^n P(X^{(j)}=x^{(j)}|Y=c_k)\)</span>，这样联合概率的参数个数变为了 <span class="math inline">\(K\times n \times V\)</span></p>
<h1 id="参数估计">参数估计</h1>
<h2 id="最大后验概率估计">最大后验概率估计</h2>
<p>对于先验概率 <span class="math inline">\(P(Y=c_k)=\frac{\sum_{i=1}^N I(y_i=c_k)}{N}, k=1,2,...,K\)</span></p>
<p>对于条件概率 <span class="math inline">\(P(X^{(j)}=a_{jv}|Y=c_k)=\frac{\sum_{i=1}^N I(a_{jv}, y_i=c_k)}{\sum_{i=1}^N I(y_i=c_k)}, j=1,2,...,n; v=1,2,...,V; k=1,2,...,K\)</span></p>
<h2 id="贝叶斯估计">贝叶斯估计</h2>
<p>对于先验概率 <span class="math inline">\(P(Y=c_k)=\frac{\sum_{i=1}^N I(y_i=c_k)}{N}, k=1,2,...,K\)</span></p>
<p>对于条件概率 <span class="math inline">\(P(X^{(j)}=a_{jv}|Y=c_k)=\frac{\sum_{i=1}^N I(a_{jv}, y_i=c_k)+\lambda}{\sum_{i=1}^N I(y_i=c_k)+V\lambda}, j=1,2,...,n; v=1,2,...,V; k=1,2,...,K\)</span></p>
<p>为每个特征维度 <span class="math inline">\(x^{(j)}\)</span> 的每种取值，预先存在 <span class="math inline">\(\lambda\)</span> 个样例，这样对那些没有出现过的样例的概率进行平滑，不至于概率为 0，当 <span class="math inline">\(\lambda=1\)</span> 时，称为拉普拉斯平滑</p>
<h1 id="参考-references">参考 (References)</h1>
<ol type="1">
<li>《统计学习方法第2版》</li>
</ol>
]]></content>
      <categories>
        <category>Machine Learning</category>
      </categories>
  </entry>
  <entry>
    <title>Bert笔记</title>
    <url>/2021/06/10/NLP/Bert%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>使用了Mask Language Model(MLM) 和 Next Sentence Prediction(NSP) 的多任务训练目标；</p>
<span id="more"></span>
<h1 id="输入向量">输入向量</h1>
<p>输入为每个 Token 位置上的 Token Embedding，Segment Embedding 和 Position Embedding 的和</p>
<p>Token Embedding: 就是单词的词向量表达（比如 Word2vec）。第一个单词是 <code>CLS</code> 标志，用于做句子分类任务；<code>SEP</code> 标志用于区分两个句子前后顺序（当输入有两个句子时）</p>
<p>Segment Embedding：用于区分两个句子，用于帮助做句子对的任务（如果只有一个句子则只需要 <span class="math inline">\(E_A\)</span>）</p>
<p>Position Embedding：用于编码单词的位置信息，跟 Transformer 一样 <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210610161040.png" /></p>
<h1 id="预训练任务">预训练任务</h1>
<h2 id="预训练-next-sentence-predictionnsp-任务">预训练 Next Sentence Prediction（NSP） 任务</h2>
<p>这是一个二分类任务，用于判断 Sentence B 是不是 Sentence A 的下一句（IsNext 或者 NotNext）</p>
<p>对于语料库中的句子，50% 的句对（Sentence Pair）是前后句关系，50% 的 B 句是随机选择的</p>
<p>A 句加 B 句的总长度不超过 512</p>
<h2 id="mask-语言模型">Mask 语言模型</h2>
<p>根据上面构造的句对数据，再对句对中的 Token Embedding 进行随机掩盖，要求模型去预测被掩盖的单词。作者对数据集中的 15% 进行掩盖操作。于这 15% 的单词，分三个部分用不同方法来 Mask <figure class="highlight xl"><table><tr><td class="code"><pre><span class="line"><span class="number">80</span>%：<span class="function"><span class="title">my</span> dog <span class="keyword">is</span> hairy -&gt;</span> my dog <span class="keyword">is</span> [mask]</span><br><span class="line"><span class="number">10</span>%：<span class="function"><span class="title">my</span> dog <span class="keyword">is</span> hairy -&gt;</span> my dog <span class="keyword">is</span> apple</span><br><span class="line"><span class="number">10</span>%：<span class="function"><span class="title">my</span> dog <span class="keyword">is</span> hairy -&gt;</span> my dog <span class="keyword">is</span> hairy</span><br></pre></td></tr></table></figure></p>
<h1 id="特殊任务fine-tuning">特殊任务（Fine Tuning）</h1>
<p>预训练的 Bert 已经学习到了较通用的知识，但是为了进一步提升在特殊任务上的表现，被训练过的 Bert 需要用特定任务的数据再进行一次训练，这次训练就叫做 FineTuning</p>
<ol type="a">
<li><p>多句子分类：CLS+句子A+SEP+句子B。利用CLS分类</p></li>
<li><p>单句子分类：CLS+句子。利用CLS进行分类</p></li>
<li><p>SQuAD：CLS+问题+SEP+文章。利用所有文章单词的输出做计算答案的 start 和 end 位置，用一个向量 <span class="math inline">\(S\)</span>（设置一个模型内部参数）与句子 B 中每个位置的 Bert 最后一层输出 <span class="math inline">\(T_i\)</span> 做內积，那么位置 <span class="math inline">\(j\)</span> 为答案开始的概率为 <span class="math inline">\(P_{start}(j)=\frac{e^{S\cdot T_j}}{\sum_i S\cdot T_i}\)</span>；对于结束位置也可以设置一个向量 <span class="math inline">\(E\)</span> 来做类似训练</p></li>
<li><p>NER：CLS+句子。利用句子单词做标记，然后用输出的词汇的 Tag 来进行 Fine-Tuning</p></li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210610164248.png" /></p>
<p>两种不同类型的任务所需要的向量，详情见特定任务的BERT</p>
<p>sentence-level：一般只拿CLS位置的向量，过线性层再softmax即可得到分类结果 token-level：SQuAD或NER，取对应位置的向量，过线性层再softmax得到相应的结果</p>
<h1 id="如何构建词向量">如何构建词向量？</h1>
<p>对于一个单词而言，通过整合它在 Bert 不同层输出的向量，一共提供了 6 中构建词向量方法。通过对 NER 任务的实验，发现效果最好的是拼接最后四层的输出向量 <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210610165712.png" /></p>
<h1 id="跟其他模型对比">跟其他模型对比</h1>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210610164248.png" /></p>
<h1 id="参考-references">参考 (References)</h1>
<ol type="1">
<li><a href="https://arxiv.org/pdf/1810.04805.pdf">Bert:: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></li>
<li>https://plmsmile.github.io/2018/12/15/52-bert/</li>
<li>https://wmathor.com/index.php/archives/1456/</li>
<li>https://zhuanlan.zhihu.com/p/48612853</li>
<li>https://zhuanlan.zhihu.com/p/46652512</li>
<li>http://fancyerii.github.io/2019/03/09/bert-theory/</li>
</ol>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>Bert</tag>
      </tags>
  </entry>
  <entry>
    <title>NLP Datasets</title>
    <url>/2021/07/05/NLP/NLP-Datasets/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>No matter which problem you are dealing with, it is always important to find suitable datasets. Here are some accecible public datasets.</p>
<ol type="1">
<li><a href="https://datasetsearch.research.google.com/">Google Datasets</a> contains 2.5 million datasets, which can be searched by keywords. It collects datasets from vast domains.</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210705161329.png" /></p>
<ol start="2" type="1">
<li><a href="https://huggingface.co/datasets">Huggingface Datsets</a> (<a href="https://github.com/huggingface/datasets">spare github link</a>) includes many datasets for NLP tasks. <span id="more"></span></li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210705161503.png" /></p>
<ol start="3" type="1">
<li><a href="https://www.kaggle.com/datasets">Kaggle Datasets</a> is a well-known machine learning dataset collection.</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210705161731.png" /></p>
<ol start="4" type="1">
<li><a href="https://www.paperswithcode.com/datasets">Paper with Code datasets</a> contains 4075 machine learning datasets. It contacts papers with their code and dataset.</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210705161924.png" /></p>
<ol start="5" type="1">
<li><a href="https://www.reddit.com/r/datasets/">Reddit Datasets</a> is also a famous dataset which supports discussion over each dataset.</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210705162956.png" /></p>
<ol start="6" type="1">
<li><a href="https://www.cluebenchmarks.com/dataSet_search.html">CLUE Datasets</a> is a big Chinese NLP dataset.</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210705162920.png" /></p>
<ol start="7" type="1">
<li>Some other datasets:
<ul>
<li>https://www.datasetlist.com/</li>
<li>https://github.com/awesomedata/awesome-public-datasets</li>
<li>https://tinyletter.com/data-is-plural</li>
<li>https://jupyter-tutorial.readthedocs.io/en/latest/data/index.html</li>
<li>https://www.openml.org/search?type=data</li>
<li>https://github.com/InsaneLife/ChineseNLPCorpus</li>
</ul></li>
</ol>
<h1 id="参考-references">参考 (References)</h1>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>[object Object]</title>
    <url>/2021/07/10/NLP/NLP-Tools/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="term-extraction">Term Extraction</h1>
<ol type="1">
<li><a href="https://github.com/slanglab/phrasemachine">Bag of What Simple Noun Phrase Extraction for Text 2016</a>. It is a pattern-based phrase extraction tool, written in Python and R.</li>
</ol>
<ul>
<li><p>Basic usage of phrasemachine <figure class="highlight pgsql"><table><tr><td class="code"><pre><span class="line">pip install phrasemachine</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> phrasemachine</span><br><span class="line"><span class="type">text</span> = &quot;Barack Obama supports expanding social security.&quot;</span><br><span class="line">phrasemachine.get_phrases(<span class="type">text</span>)</span><br><span class="line">&#123;<span class="string">&#x27;num_tokens&#x27;</span>: <span class="number">7</span>, <span class="string">&#x27;counts&#x27;</span>: Counter(&#123;<span class="string">&#x27;barack obama&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;social security&#x27;</span>: <span class="number">1</span>&#125;)&#125;</span><br></pre></td></tr></table></figure></p></li>
<li><p>It can support other higher accuracy spaCy tagger, or with Stanford CoreNLP.</p></li>
<li><p>The position of each token can be obtained.</p></li>
</ul>
<ol start="2" type="1">
<li><a href="https://github.com/shangjingbo1226/AutoPhrase">Automated Phrase Mining from Massive Text Corpora 2017</a>. This tool can be easily run by a <code>.sh</code> file, but needs g++, and Java as back tool.</li>
</ol>
<span id="more"></span>
<h1 id="references">References</h1>
<ol type="1">
<li>Bag of What? Simple Noun Phrase Extraction for Text Analysis</li>
<li>Automated Phrase Mining from Massive Text Corpora</li>
</ol>
]]></content>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>Concept Formation</title>
    <url>/2021/06/18/NLP/Ontology-Learning/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="ontology">Ontology</h1>
<p>Definition of Ontology reference at ` - <a href="https://arxiv.org/pdf/1509.05434.pdf">A Study Investigating Typical Concepts and Guidelines for Ontology Building, 2015</a> - https://www.igi-global.com/dictionary/ontology/21117</p>
<p>The domain knowledge in ontologies can be formalized using 5 components <a href="">A translation approach to portable ontology specification</a></p>
<ul>
<li><p>Classes: Set of classes (or concepts) that belong to the ontology. They may contain individuals (or instances), other classes, or a combination of both with their corresponding attributes.</p></li>
<li><p>Relations: These define interrelations between two or several classes (object properties) or a concept to a data type (data type properties).</p></li>
<li><p>Functions: This is a special case of relations.</p></li>
<li><p>Axioms: These are used to impose constraints on the values of classes or instances. Axioms represent expressions in ontology (logical statement) and are always true when used inside the ontology.</p></li>
<li><p>Instances: These represent the objects, elements or individuals of an ontology.</p></li>
</ul>
<h1 id="concept">Concept</h1>
<p>Based on [1], There is no unified definition of concept. A concept can be recognized as the relevant terms that shared the same meaning. Psychologically, it defnied as an idea shared in common in the minds of people who use these terms. It can also seen as a logical contruct, for example, a synset containing a set of words which can be exchanged for each other. <span id="more"></span></p>
<p>From [2]. A concept should include: (1) an intention of this concept; (2) a set a concept instances (ie. its extension); (3) a set of linguistic realizations (multiligual terms that express this concept). However, most of academic research regard concepts as <strong>clusters of related terms</strong>.</p>
<h1 id="concept-formation">Concept Formation</h1>
<p>Existing Approaches 1. Clustering over word embedding 2. Using Graph-based method and treating this problem as community discovery 3. Using Topic model-based method and viewing this problem as topic mining</p>
<h1 id="taxonomy-extraction">Taxonomy Extraction</h1>
<p>Existing Approaches 1. Hearst Patterns: By using a set of predefined lexico-syntactic patterns. This method can get good precision, but low recall. <figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">Vehicles such as cars, trucks <span class="keyword">and </span><span class="keyword">bikes</span></span><br><span class="line"><span class="keyword">Swimming, </span>running <span class="keyword">or </span>other activities</span><br></pre></td></tr></table></figure> 2. Clustering:</p>
<pre><code>Agglomerative clustering and Divisive clustering:
Terms are represented by a dense vector. Then a clustering algorithm is ran over all term vectors, therefore build up a hierarchy of clusters, where each cluster is regarded as a concept.

Conceptual Clustering: A lattice of terms is built by investigate the overlap of descriptive attributes (a document describe the term) between two represented terms.

Cases of conceptual clustering:
- An application of inductive concept analysis to construction of domain-specific ontologies, 2003
- Learning concept hierarchies from text corpora using formal concept analysis, 2005</code></pre>
<ol start="3" type="1">
<li><p>Document-based subsumption: Term <span class="math inline">\(t_1\)</span> subsumes <span class="math inline">\(t_2\)</span> (ie. the relation of is-a(<span class="math inline">\(t_2\)</span>, <span class="math inline">\(t_1\)</span>)) if <span class="math inline">\(t_1\)</span> appears in all the documents where <span class="math inline">\(t_2\)</span> shows up. <span class="math inline">\(P(x|y)=\frac{freq_d(x,y)}{freq_d(y)}\)</span></p></li>
<li><p>Phrase Analysis: The internal structure of noun phrases can be used to deduce taxonomic relations. For example, additional modifiers added to the front of a noun usually is a subclass of the class denoted by the noun (focal epilepsy is subclass of epilepsy). Or terms occuring to the left of a term are subclasses of this term.</p></li>
</ol>
<p>References are: - A Prot ́eg ́e plug-in for ontology extrac- tion from text based on linguistic analysis, 2004 - Web-scale taxonomy learning., 2005</p>
<h1 id="ontology-learning">Ontology Learning</h1>
<p>Machine Learning Algorithm for Ontology Learning (OL)</p>
<table>
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="header">
<th>Algorithm</th>
<th>Generic Use</th>
<th>Usage in OL</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Association rule discovery</td>
<td>Discover interesting itermsets from transactions</td>
<td>Discover interesting association between terms</td>
</tr>
<tr class="even">
<td>(Hierarchical) Clustering</td>
<td>Discover group in data</td>
<td>Clustering terms</td>
</tr>
<tr class="odd">
<td>SVM, NB, KNN</td>
<td>Prediction</td>
<td>Classification of new concepts into existing hierarchy</td>
</tr>
<tr class="even">
<td>Inductive Logic Programming</td>
<td>Induction of rules from data (supervised)</td>
<td>Discovery of new concepts from extensional data</td>
</tr>
<tr class="odd">
<td>Conceptual Clustering (Formal Concept Analysis)</td>
<td>Concept discovery (extension and intention)</td>
<td>Learning concepts and concept hierarchy</td>
</tr>
</tbody>
</table>
<h1 id="references">References</h1>
<ol type="1">
<li><a href="">Beyond Concepts: Ontology as Reality Representation</a></li>
<li><a href="https://pub.uni-bielefeld.de/download/2497696/2525557/pci_OL-Book-Intro.pdf">Ontology learning from text: An overview</a></li>
<li><a href="http://vikas.sindhwani.org/concept-labeling-ijcai11.pdf">Concept Labeling: Building Text Classifiers with Minimal Supervision</a></li>
<li><a href="https://cw.fel.cvut.cz/old/_media/courses/osw/learning-ontologies-osw.pdf">Ontology Learning</a></li>
<li><a href="">Handbook on ontologies</a></li>
<li><a href="https://academic.oup.com/database/article/doi/10.1093/database/bay101/5116160">A survey of ontology learning techniques and applications, 2018</a></li>
<li><a href="https://link.springer.com/chapter/10.1007/978-3-642-03079-6_2">Concept Formation in Linguistic Ontologies</a></li>
</ol>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>Transformer笔记</title>
    <url>/2021/06/09/NLP/Transformer%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Transformer 主包括两个部分，Encoder 和 Decoder，整体流程如下 <span id="more"></span></p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210609174026.png" /></p>
<h1 id="encoder">Encoder</h1>
<p>Encoder 包含了两个子层，一个 multi-headed attention 子层，一个全连接子层。此外这两个子模块都是用了残差连接，然后从一个归一化层输出</p>
<p><span class="math inline">\(Encoding(x,mask)=FeedForward(MultiHeadAttention(x))\)</span></p>
<h2 id="多头注意力-sublayer">多头注意力 Sublayer</h2>
<p><span class="math inline">\(Z=MultiHead(X)=Concat(head_0,...,head_h)W^O\)</span></p>
<p><span class="math inline">\(head_i=Z_i=Attention(Q,K,V)=softmax(\frac{QK^T}{\sqrt{d_k}})V; Q=XW^Q, K=XW^K, V=XW^V\)</span></p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210609122322.png" /></p>
<h2 id="全连接层-sublayer">全连接层 Sublayer</h2>
<p>从全连接层输出的向量维度跟输入的维度一致， <span class="math inline">\(FFN(x)=max(0, xW_1+b_1)W_2+b_2\)</span></p>
<h2 id="addnorm">Add&amp;Norm</h2>
<p><span class="math inline">\(Z_n=LayerNorm(Z_{n-1}, SubLayer(Z_{n-1}))\)</span></p>
<h1 id="decoder">Decoder</h1>
<p>根据 Transformer 最后一层 Encoder 出来的向量，也就是 <span class="math inline">\(LayerNorm(Z_{n-1}+Z_{n})\)</span>，<span class="math inline">\(n\)</span> 为 Encoder 的数量计算得到的 attention 向量 <span class="math inline">\(K\)</span> 和 <span class="math inline">\(V\)</span>。这两个矩阵将作为 Decoder 的输入来帮助 Decoder 关注输入序列中的重要位置信息</p>
<p><span class="math inline">\(Decoding(x,memory,mask1,mask2)=FeedForward(MultiHeadAttention(MultiHeadAttention(x,mask1),memory,mask2))\)</span></p>
<h2 id="第一个-multi-headed-self-attention-层">第一个 multi-headed self attention 层</h2>
<p>用于训练 Decoder 的输出序列按照时间步来进行，每个时间步输入当前位置的前面所有的序列信息，这可以通过在 self-attnetion 子模块中的 softmax 层前面用 <span class="math inline">\(-inf\)</span> mask 掉当前位置之后的序列信息。这样 self attention 层输出的就是被 mask 后的输出序列的 <span class="math inline">\(Z\)</span> <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210609160537.png" /> 对于机器对话任务而言，Decoder 的工作模式如下图所示</p>
<h2 id="第二个-multi-headed-encoder-decoder-层">第二个 multi-headed encoder-decoder 层</h2>
<p>对于这个 encoder-decoder 子模块而言，它使用了从 Encoder 的输出向量复制两份作为 <span class="math inline">\(Q\)</span> 和 <span class="math inline">\(K\)</span>，使用了 Decoder self-attention 子模块的 <span class="math inline">\(V\)</span> 作为输入，这个子模块为输出序列匹配了输入序列。读者肯定会有疑问，输入序列的长度（也就是 <span class="math inline">\(Q\)</span> 和 <span class="math inline">\(K\)</span> 矩阵的高度）和输出序列的长度（也就是 <span class="math inline">\(V\)</span> 矩阵的高度）不一样，怎么能进行计算呢？答案是 Transformer 给输入和输入序列定长为 512，多余的没有内容的地方用一些空字符替代。</p>
<h2 id="线性分类器和最后一个-softmax">线性分类器和最后一个 softmax</h2>
<p>最后一层分类器根据前面的输出序列信息和输入序列信息来预测对于当前位置的词汇，因此最后 softmax 的输出向量的维度为所有输出序列包含的词汇表的大小 <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210609175256.png" /></p>
<h2 id="loss-function">Loss Function</h2>
<p>对于某个翻译的实例 ("Je suis etudiant, merci" --&gt; "I am a student, thanks")，此时预测的词是 “I”，那么我们需要 softmax 层输出的是 <span class="math inline">\([0,0,1,0,0,0]\)</span>，通过softmax 层的输出向量和这个期望的向量进行交叉熵或者 KL 距离计算，来作为 Loss</p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210609180115.png" /></p>
<h1 id="position-encoding">Position Encoding</h1>
<p>为了向 Transformer 引入词汇的位置信息，通过下面的方法对位置进行编码来实现，最终得到下图的矩阵，形状为 <span class="math inline">\(len_{seq}\times dim_{embed}\)</span></p>
<p>对于句子中第 <span class="math inline">\(pos\)</span> 个词汇的位置向量的偶数位，<span class="math inline">\(PE(pos,2i)=sin(\frac{pos}{10000^{2i/dim_{embed}}})\)</span></p>
<p>对于句子中第 <span class="math inline">\(pos\)</span> 个词汇的位置向量的奇数位，<span class="math inline">\(PE(pos,2i+1)=cos(\frac{pos}{10000^{2i/dim_{embed}}})\)</span></p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210609123150.png" /></p>
<h1 id="参考-references">参考 (References)</h1>
<ol type="1">
<li><a href="https://arxiv.org/abs/1706.03762">Attention is All You Need</a></li>
<li><a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html">Stanford implement of Transformer</a></li>
<li>https://jalammar.github.io/illustrated-transformer/</li>
<li>https://towardsdatascience.com/illustrated-guide-to-transformers-step-by-step-explanation-f74876522bc0</li>
<li>https://wandb.ai/authors/One-Shot-3D-Photography/reports/-Transformer---Vmlldzo0MDIwMjc</li>
</ol>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>Transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>word2vec详解</title>
    <url>/2021/05/21/NLP/word2vec%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="word2vec的训练目标">Word2vec的训练目标</h1>
<p>Word2vec都被认为是用于训练词向量表达的工具。但是词向量其实是一个完成了Word2vec网络模型的一个副产品。它的训练目标是训练一个三层神经网络，使得上下文相似的词汇的相似度变高。达到这个目标后，发现输入层到隐藏层的参数竟然奇迹般的能用于词的向量表示，并且还有些神奇的效果，比如 ”King“-"Men"+"Women"="Queen"、 ”日本“-”东京“+"中国"="北京"；或者 "北京"和"烤鸭"的相似性 &gt; "北京"和"早茶"的相似性。 <span id="more"></span> 假设数据集为 <span class="math inline">\(D\)</span>，数据集中的词汇表为 <span class="math inline">\(C\)</span>。如果当前词为 <span class="math inline">\(w_t\)</span>，上下文窗口大小为 5. 那么这个词的上下文 <span class="math inline">\(Context(w_t)=[w_{t-2},w_{t-1},w_{t+1},w_{t+2}]\)</span>。对于下面的例子的第三个窗口而言，当前输入词为“brown”，它的上下文为 [“the”，“quick”，“fox”，“jumps”]</p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210521220013.png" /></p>
<p><strong>Skip-gram</strong></p>
<p>Skip-gram 通过当前词汇来预测上下文，为此它的最大化目标函数为</p>
<p><span class="math inline">\(L=\sum_{w\in D}logp(w|Context(w))\)</span></p>
<p><strong>CBOW</strong></p>
<p>CBOW 的思想则是通过上下文来预测当前词汇，为此它的最大化目标函数为</p>
<p><span class="math inline">\(L=\sum_{w\in D}logp(Context(w)|w)\)</span></p>
<h1 id="word2vec模型">Word2vec模型</h1>
<p>Word2vedc 模型由输入层，隐藏层和输出层组成，它的模型参数包括了输入层到隐藏层的权重矩阵 <span class="math inline">\(W\)</span>（最终保留的词向量矩阵），以及隐藏层到输出层的权重矩阵 <span class="math inline">\(W&#39;\)</span>，数据集的词汇表中一共包含 <span class="math inline">\(V\)</span> 个唯一的词汇，词向量的维度设置为 <span class="math inline">\(N\)</span>。</p>
<h2 id="cbow-模型">CBOW 模型</h2>
<p>对于当前词汇 <span class="math inline">\(w_t\)</span> 而言，它是词汇表中第 <span class="math inline">\(v\)</span> 个词汇。它的一个训练样本为 <span class="math inline">\((Context(w_t), w_t)\)</span>. 输入层是一个只包含 0 和 1 的向量，1 的位置代表词汇表中该位置的词汇在上下文 <span class="math inline">\(Context(w_t)\)</span> 中. 隐藏层的向量 <span class="math inline">\(h=x^TW=\sum_{w&#39;\in Context(w_t)}W_{w&#39;}\)</span>. 其实隐藏层就是上下文词汇的词向量的和。输出层为向量 <span class="math inline">\(o=hW&#39;=x^TWW&#39;\)</span>。对于向量 <span class="math inline">\(o\)</span> 而言，希望第 <span class="math inline">\(v\)</span> 个位置为 1，其他位置为 0. 对于这一个训练样本而言，我们希望最大化</p>
<p><span class="math inline">\(L=\sum_{w_t\in C}log(\prod_{w\in C}p(w|Context(w_t)))\)</span></p>
<p><span class="math inline">\(g(w_t,w)=p(w|Context(w_t))={[\sigma(hW&#39;_{w})]}^{L^{w_t}(w)}\times {[1-\sigma(hW&#39;_{w})]}^{1-L^{w_t}(w)}\)</span></p>
<p>其中 <span class="math inline">\(\sigma(x)=\frac{1}{1+e^{-x}}\)</span>，<span class="math inline">\(L^{w_t}(w)=1\)</span> if <span class="math inline">\(w_t=w\)</span>，<span class="math inline">\(L^{w_t}(w)=1\)</span> if <span class="math inline">\(w_t\neq w\)</span>.</p>
<p>对 <span class="math inline">\(W&#39;_{w}\)</span> 求导 <span class="math inline">\(\frac{\partial g(w_t,w)}{\partial W&#39;_w}=[L^{w_t}(w)-\sigma(hW&#39;_{w})]h\)</span></p>
<p>对 <span class="math inline">\(h\)</span> 求导 <span class="math inline">\(\frac{\partial g(w_t,w)}{\partial h}=[L^{w_t}(w)-\sigma(hW&#39;_{w})]W&#39;_{w}\)</span></p>
<p>更新 <span class="math inline">\(W&#39;_{w}=W&#39;_{w}+\eta \frac{\partial g(w_t,w)}{\partial W&#39;_w}\)</span></p>
<p>更新 <span class="math inline">\(W_{w&#39;} (w&#39;\in Context(w_t))\)</span>， <span class="math inline">\(W_{w&#39;}=W_{w&#39;} + \eta \sum_{w\in C} \frac{\partial g(w_t,w)}{\partial h}\)</span></p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210531085347.png" /></p>
<h2 id="skip-gram-模型">SKip-gram 模型</h2>
<p>对于当前词汇 <span class="math inline">\(w_t\)</span> 而言，它是词汇表中第 <span class="math inline">\(v\)</span> 个词汇。它的一个训练样本为 <span class="math inline">\((w_t,Context(w_t))\)</span>. 输入层是一个 one-hot 向量，其中第 <span class="math inline">\(v\)</span> 个位置为 1，其他位置为 0. 隐藏层的向量 <span class="math inline">\(h=x^TW=\sum_{w\in Context(w_t)}W_{w}\)</span>. 其实隐藏层就是上下文词汇的词向量的和。输出层为向量 <span class="math inline">\(o=hW&#39;=x^TWW&#39;\)</span>。对于向量 <span class="math inline">\(o\)</span> 而言，希望所有与 <span class="math inline">\(Context(w_t)\)</span> 中词汇对应的位置为 1，其他位置为 0. 对于这一个训练样本而言，我们希望最大化</p>
<p><span class="math inline">\(L=\sum_{w_t\in C}log(\prod_{u\in Context(w_t)}\prod_{w\in C}p(w|w_t,u))\)</span></p>
<p><span class="math inline">\(g(w_t,u,w)=p(w|w_t,u)={[\sigma(W_{u}^T W&#39;_{w})]}^{L^{w_t}(w)}\times{[1-\sigma(W_{u}^T W&#39;_{w})]}^{1-L^{w_t}(w)}\)</span></p>
<p>其中 <span class="math inline">\(\sigma(x)=\frac{1}{1+e^{-x}}\)</span>，<span class="math inline">\(L^{w_t}(w)=1\)</span> if <span class="math inline">\(w_t=w\)</span>，<span class="math inline">\(L^{w_t}(w)=1\)</span> if <span class="math inline">\(w_t\neq w\)</span>.</p>
<p>对 <span class="math inline">\(W&#39;_{w}\)</span> 求导 <span class="math inline">\(\frac{\partial g(w_t,w,u)}{\partial W&#39;_w}=[L^{w_t}(w)-\sigma(W_{u}W&#39;_{w})]W_{u}\)</span></p>
<p>对 <span class="math inline">\(W_u\)</span> 求导 <span class="math inline">\(\frac{\partial g(w_t,w)}{\partial W_{u}}=[L^{w_t}(w)-\sigma(W_{u}W&#39;_{w})]W_{u}\)</span></p>
<p>更新 <span class="math inline">\(W&#39;_{w}=W&#39;_{w}+\eta \frac{\partial g(w_t,w)}{\partial W&#39;_w}\)</span></p>
<p>更新 <span class="math inline">\(W_{u} (u\in Context(w_t))\)</span>， <span class="math inline">\(W_{u}=W_{u} + \eta \sum_{w\in C} \frac{\partial g(w_t,w)}{\partial W_u}\)</span></p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210531085440.png" /></p>
<h1 id="负采样">负采样</h1>
<p>从上面的模型可以看到，每个训练样本经过，都需要更新整个 <span class="math inline">\(W&#39;\)</span>，这样代价太大了，因此，负采样对于上面的 <span class="math inline">\(w\in C\)</span> 更改为 <span class="math inline">\(w\in NEG(w_t)\cup w_t\)</span>. 这样每次只需要更新更少的参数. 对于 <span class="math inline">\(w_t\)</span> 而言，除了自己，其他词汇都是负样本词汇. 但是有那么多个负样本词汇，我们怎么去挑选呢，答案是根据负样本词汇的词频。为此 Word2vec 模型定义了一个概率计算公式用于挑选负样本词汇：<span class="math inline">\(P(w)=\frac{tf(w)^{3/4}}{\sum_{w&#39;}tf(w&#39;)^{3/4}}\)</span>.公式中加了一个 <span class="math inline">\(3/4\)</span> 次方纯粹是一个经验值.</p>
<h1 id="下采样">下采样</h1>
<p>回到一个图中的例子中我们构建的训练样本。里面会存在大量的（"fox", "the"）这样的词对，并且像（"the", XXX）这样词对也会频繁出现在训练样本中。我们知道其实 "the" 并不能为 "fox" 这样的词提供多少语义含义，此外对于（"the", XXX）这样的词对，XXX有很高的重复率。为此，Word2vec使用下采样来对付这样的情况。简单来说对于像 ”fox" 这样有意义的词语，我们去掉它的包含 "the" 的词对；对于 "the" 这样的词汇，我们采用更少的训练样本量。</p>
<p>那么对于一个像 "the" 这样的高频词汇，我们按照怎样的方法来选择性的丢掉它的一些样本呢？Word2vec 采用了一个计算词汇被保留的概率公式 <span class="math inline">\(P(w)=(\sqrt{\frac{z(w)}{0.001}}+1)\frac{0.001}{z(w)}\)</span>，其中 <span class="math inline">\(z(w)=\frac{tf(w)}{corpus\ size}\)</span>。函数<span class="math inline">\(f(x)=(\sqrt{\frac{x}{0.001}}+1)\frac{0.001}{x}\)</span>的图像如下图所示：</p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210522112249.png" /></p>
<p>从图中可以看出，高频词汇被保留的概率较少，低频词汇被保留的概率较高。当 <span class="math inline">\(z(w)\leq 0.0026\)</span> 时，<span class="math inline">\(P(w)=1\)</span>，此时 <span class="math inline">\(w\)</span> 所有的词对样本都被保留；当 <span class="math inline">\(z(w)= 0.00746\)</span> 时，<span class="math inline">\(P(w)=0.5\)</span>，此时 <span class="math inline">\(w\)</span> 的词对样本只保留一半。</p>
<h1 id="参考-references">参考 (References)</h1>
<ol type="1">
<li>http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/</li>
<li>http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/</li>
</ol>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>word2vec</tag>
        <tag>词向量</tag>
      </tags>
  </entry>
  <entry>
    <title>知识图谱构建</title>
    <url>/2021/06/03/NLP/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E6%9E%84%E5%BB%BA/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="知识图谱构建法">知识图谱构建法</h1>
<ol type="1">
<li>自顶向下</li>
</ol>
<p>先定义好本体（Ontology 或称为 Schema），再基于输入数据完成信息抽取到图谱构建的过程，适用于专业知识（领域）方面图谱的构建 <span id="more"></span> 2. 自底向上</p>
<p>从开放的 Open Linked Data 中抽取置信度高的知识，或从非结构化文本中抽取知识，完成知识图谱的构建，适合于常识性的知识，比如人名、机构名等通用知识图谱的构建，因为无法区分与领域无关的信息</p>
<h1 id="自顶向下的知识图谱构建">自顶向下的知识图谱构建</h1>
<p>本体构建 --&gt; 数据源配置 --&gt; 信息抽取 --&gt; 知识融合</p>
<h1 id="本体构建">本体构建</h1>
<p>本体是知识图谱的定义语言，就像是数据库中新建表时用的 schema 一样，定义了数据表的格式。通过梳理领域知识、术语词典、专家的人工经验等作为本体构建的基础，结合知识图谱的应用场景来完善图谱的构建，最终获得实体类别、类别之间的关系、实体包含的属性定义</p>
<h1 id="数据源配置">数据源配置</h1>
<ol type="1">
<li>非电子文档：扫描，OCR识别</li>
<li>电子文档：根据类别整合成统一格式</li>
<li>网络资源：爬虫技术</li>
<li>第三方数据：接口获取</li>
</ol>
<h1 id="信息抽取">信息抽取</h1>
<p>对实体，属性和关系的抽取，用（主语，谓语，宾语）三元组表示。</p>
<h1 id="知识融合">知识融合</h1>
<p>对上一步抽取的三元组进行融合。完成实体对齐和知识融合。实体对齐是一个技术难点，通常由基于实体属性相似度的框架、基于联合表征的深度学习框架着两种方法</p>
<h1 id="参考-references">参考 (References)</h1>
<ol type="1">
<li>https://xie.infoq.cn/article/eb0d3f2a5691bf3aabb73966f</li>
<li></li>
</ol>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>自然语言理解任务</title>
    <url>/2021/06/10/NLP/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E7%90%86%E8%A7%A3%E4%BB%BB%E5%8A%A1/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>9项GLUE任务 General Language Understanding Evaluation 包含了很多自然语言理解的任务。</p>
<span id="more"></span>
<h1 id="mnli">MNLI</h1>
<p>Multi-Genre Natural Language Inference是一个众包大规模的文本蕴含任务。</p>
<p>给2个句子，判断第二个句子与第一个句子之间的关系。蕴含、矛盾、中立的</p>
<h1 id="qqp">QQP</h1>
<p>Quora Question Pairs</p>
<p>给2个问题，判断是否语义相同</p>
<h1 id="qnli">QNLI</h1>
<p>Question Natural Language Inference 是一个二分类任务，由SQuAD数据变成。</p>
<p>给1个(问题，句子)对，判断句子是否包含正确答案</p>
<h1 id="sst-2">SST-2</h1>
<p>Stanford Sentiment Treebank，二分类任务，从电影评论中提取。</p>
<p>给1个评论句子，判断情感</p>
<h1 id="cola">CoLA</h1>
<p>The Corpus of Linguistic Acceptablity，二分类任务，判断一个英语句子是否符合语法的</p>
<p>给1个英语句子，判断是否符合语法</p>
<h1 id="sts-b">STS-B</h1>
<p>The Semantic Textual Similarity Benchmark，多分类任务，判断两个句子的相似性，0-5。由新闻标题和其他组成</p>
<p>给2个句子，看相似性</p>
<h1 id="mrpc">MRPC</h1>
<p>Microsoft Research Paraphrase Corpus，2分类任务，判断两个句子是否语义相等，由网上新闻组成。05年的，3600条训练数据。</p>
<p>给1个句子对，判断2个句子语义是否相同</p>
<h1 id="rte">RTE</h1>
<p>Recognizing Textual Entailment，二分类任务，类似于MNLI，但是只是蕴含或者不蕴含。训练数据更少</p>
<h1 id="wnli">WNLI</h1>
<p>Winograd NLI一个小数据集的NLI。据说官网评测有问题。所以评测后面的评测没有加入这个</p>
<h1 id="参考-references">参考 (References)</h1>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
  </entry>
  <entry>
    <title>Paper Reading List</title>
    <url>/2021/07/10/Paper%20Reading/Paper-Reading-List/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><span id="more"></span>
<h1 id="references">References</h1>
]]></content>
  </entry>
  <entry>
    <title>信息论</title>
    <url>/2021/05/31/Probability/%E4%BF%A1%E6%81%AF%E8%AE%BA/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="自信息">自信息</h1>
<p>量化事件的信息量 <span class="math inline">\(I(X=x)=-log p(X=x)\)</span> <span id="more"></span> # 信息熵 对概率分布不确定性总量的量化（信息量的期望）：</p>
<p><span class="math inline">\(H(X) = E_{X}(I(X))=-\sum_{x\in X}p(X=x)logp(X=x)\)</span></p>
<h1 id="条件熵">条件熵</h1>
<p>表示在已知随机变量 X 的条件下，随机变量 Y 的不确定性（熵）</p>
<p><span class="math inline">\(H(Y|X)=\sum_{x\in X} P(X=x)H(Y|X=x)\)</span></p>
<h1 id="信息增益">信息增益</h1>
<p>某个随机变量的信息熵-该变量的条件熵</p>
<p><span class="math inline">\(IG(Y,X)=H(Y)-H(Y|X)\)</span></p>
<p>该方法的决策树 ID3 所选择的特征会偏好于属性值较多的特征</p>
<h1 id="gini-系数">Gini 系数</h1>
<p>将熵定义中的 <span class="math inline">\(-log(p(x))\)</span> 替换成 <span class="math inline">\(1-p(x)\)</span></p>
<p><span class="math inline">\(Gini(X)= \sum_{x\in X}p(X=x) (1-p(X=x))=1-\sum_{x\in X}p(X=x)\)</span> 基于 Gini 系数的决策树同样具有偏好于属性值较多的特征的问题</p>
<h1 id="信息增益率">信息增益率</h1>
<p><span class="math inline">\(GainRatio(Y,X) = IG(Y,X)/H(X)\)</span></p>
<p>直接采样该方法的决策树又会偏好属性取值较少的特征。因此，决策树 C4.5 先通过一遍筛选，先把信息增益低于平均水平的属性剔除掉，之后从剩下的属性中选择信息增益率最高的.</p>
<h1 id="交叉熵">交叉熵</h1>
<p>P 为某样本真实分布，Q 为该样本的估计分布，如果用估计分布 Q 来表示真实分布 P 的平均编码长度就是交叉熵，当我们对分布估计不准确时，总会引入额外的不必要信息期望（可以理解为引入了额外的偏差）</p>
<p><span class="math inline">\(H(P, Q)=-\sum_{x}P(x)log(Q(x))\)</span></p>
<h1 id="相对熵kl散度">相对熵（KL散度）</h1>
<p>用估计的概率分布来表示真实分布多使用的信息量。估计分布表示真实分布所用的平均编码长度-用真实分布编码的平均长度=相对熵</p>
<p><span class="math inline">\(D(P|Q)=KL(P,Q)=H(P,Q)-H(P)\\=-\sum_{x}P(x)log(Q(x))+sum_{x}P(x)logP(x)\\=\sum_{x}P(x)log\frac{P(x)}{Q(x)}\)</span></p>
<h1 id="互信息">互信息</h1>
<p>两个随机变量的联合分布 (P) 与它们的独立分布的乘积 (Q) 之间的相对熵， 两事件的互信息为各自事件单独发生所代表的信息量之和减去两事件同时发生所代表的信息量之后剩余的信息量，这表明了两事件单独发生给出的信息量之和是有重复的，互信息度量了这种重复的信息量大小</p>
<p><span class="math inline">\(I(X;Y)=\sum_{x\in X}\sum_{y \in Y} p(x,y)\frac{p(x,y)}{p(x)p(y)}\)</span></p>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210604172829.png" /></p>
<h1 id="困惑度">困惑度</h1>
<p>给定语言L的样本 <span class="math inline">\(l_1^n=l_1,l_2,...,l_n\)</span>，模型对数据的困惑度为</p>
<p><span class="math inline">\(2^{H(L,q)}\approx 2^{-\frac{1}{n}log q(l_1^n)}={[q(l_1^n)]}^{-\frac{1}{n}}\)</span></p>
<h1 id="参考-references">参考 (References)</h1>
<ol type="1">
<li>https://baike.baidu.com/item/%E7%9B%B8%E5%AF%B9%E7%86%B5/4233536?fr=aladdin</li>
<li>https://baike.baidu.com/item/%E4%BA%92%E4%BF%A1%E6%81%AF/7423853?fr=aladdin</li>
<li>https://www.zhihu.com/question/41252833</li>
<li>https://zhuanlan.zhihu.com/p/136100996</li>
</ol>
]]></content>
      <categories>
        <category>Probability</category>
      </categories>
      <tags>
        <tag>信息论</tag>
        <tag>熵</tag>
      </tags>
  </entry>
  <entry>
    <title>Academic Information Sources</title>
    <url>/2021/07/13/Research%20Method/Academic-Information-Sources/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><span id="more"></span>
<h1 id="references">References</h1>
]]></content>
      <tags>
        <tag>Research</tag>
      </tags>
  </entry>
  <entry>
    <title>How to write a quilified academic paper?</title>
    <url>/2021/07/05/Research%20Method/How-to-write-a-quilified-academic-paper/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>This blog is a water-tight version of Zhiyuanliu's tutorial on how to write a qualified NLP paper.</p>
<h1 id="process-of-paper-publication">Process of Paper Publication</h1>
<p>Usually, a classic process of paper publication is :</p>
<p>Proposal <span class="math inline">\(\longrightarrow\)</span> Model Design <span class="math inline">\(\longrightarrow\)</span> Coding <span class="math inline">\(\longleftrightarrow\)</span> Parameter Tuning <span class="math inline">\(\longrightarrow\)</span> Paper Writing <span class="math inline">\(\longleftrightarrow\)</span> Paper Reediting <span class="math inline">\(\longrightarrow\)</span> Paper Sumbmitting <span class="math inline">\(\longrightarrow\)</span> Presentation</p>
<p>An excellet paper = An excellent work (step 1) + An excellent Writting (step 2)</p>
<span id="more"></span>
<h1 id="classic-framwork-of-a-nlp-paper">Classic Framwork of a NLP paper</h1>
<p>Most of the conference papers (8-10 pages) should include 6 components: Abstract, Introduction, Related Work, Method, Experiment, and Conclusion.</p>
<ul>
<li>Abstract: Using 100-200 words to describe clearly the task, existing challenges, your methodology, your experiment results, and finally, your conclusion.</li>
<li>Introduction: Leaving 1 page to detail the research problem, existing state-of-the-arts, main challenges, typology of methods, specific methods in each branch, and overall performance of each method.</li>
<li>Related Work: Using 0.5-1 page for related works, distinguish the differences between your work and others.</li>
<li>Method: Using 2-3 pages to introduce all details of your proposal.</li>
<li>Experiment: Using 2-3 pages to recommend the datasets, experimental criteria, parameter setting, experimental results, and analysis of these results.</li>
<li>Conclusion: Summing up the main work and contributions, and proposing some possible directions for the future.</li>
</ul>
<p>tips:</p>
<ol type="1">
<li>Writing in the interest of readers. Remember to describe all new concepts in your paper, and detail the work to the extend that can your reader easily to grap your idea.</li>
<li>Writing with rigorous logic. Guarantee the consistency and coherence of your chapeters, paragraphs, and sentences.</li>
</ol>
<p>For example. (1) If you mentioned 3 challenges in your introduction, then, make sure you have 3 components in your proposal to deal with all challenges, 3 algorithms in your method part, and 3 types of experiments to verifying each of your algorithms; (2) You should clear the strctures of your paragraphs, whehter they are organized parallelly, or incrementally. Make sure there is a sentence or adverb to connect paragraphs or sentences.</p>
<h1 id="how-to-write-abstract-and-introduction-part">How to write Abstract and Introduction part</h1>
<h2 id="introduction">Introduction</h2>
<ol type="1">
<li>Problem description and the importance of solving it. For a well-known problem, you don't need to emphasis much. However, for a new research problem, you should write more words to highlight the importance of this problem.</li>
<li>Existing Works. Standing upon the gaint's shoulder, introduce the representative of all methods. You are going to improve the representative.</li>
<li>Presenting challenges and shortcomings of the representative. Make objective criticism on those works.</li>
<li>How can your method solve those challenges you mentioned before?</li>
<li>Proofing that your method can work better considering those challenges.</li>
<li>Summing up the main contributions or your work with precise and concise sentences.</li>
</ol>
<h2 id="abstract">Abstract</h2>
<p>Abstract can be view as a brief of your introduction. But you should paraphrase the content in introduction part. You can see clearly the conrespondence between abstract and introduction.</p>
<h1 id="how-to-write-method-part">How to write Method part</h1>
<ol type="1">
<li>You should introduce the total framework of your method, which offers an overview of your work. Then, give a mathematical formula to describe your prolbem if possible. All notations you going to use should be listed. Finally, introduce all components of your method.</li>
<li>You detail every component from the whole to the part, and bold the title of each part. This will navigate the reader to look through your content with a clear clue.</li>
</ol>
<p>Make the description of framework different from what has been mentioned in introduction part. The description here should be correlated with that in introduction part, but offers more details. Another thing is that you should explain every new notation explicitly.</p>
<h1 id="how-to-write-experiment-part">How to write Experiment part</h1>
<p>Before posting the experimental results, you should mention the datasets you used, those criteria you chosen, and all baselines you compared in your expriments.</p>
<p>For presenting your experiments. You should mainly focus on valid the effectiveness of your method on the challenges you dealing with. That's means your method should be proofed to improve the performance after using it. However, Comparison with the most recent state-of-the-art is not required.</p>
<p>In order to present the advantage and characteristic of your method. You can do some experiment to test the <strong>hyperparameter effects</strong>, <strong>Ablation Test</strong> (how much contribution each component made), <strong>Impact of Datsets</strong> (few-shot, class-imbalanced), <strong>Error Analysis</strong> (limitation of your method, where your method fails), <strong>Case study</strong> (strength of your method, where your method works best) and so on.</p>
<h1 id="how-to-write-related-work-part">How to write Related Work part</h1>
<p>The function of this part is to conclude, classify, and analyse the existing works. The content can be organized chronically or taxonomically. The content should emphasis the challenges they tackled, and the problems they didn't fix. Finally, you should highlight the differences of your method compared with others.</p>
<h1 id="how-to-write-conclusion">How to write Conclusion</h1>
<p>Conclusion is used to summarize contributions and the results to support those contributions. Additionally, one may further possible research topics for future.</p>
<h1 id="参考-references">参考 (References)</h1>
<ol type="1">
<li>https://mp.weixin.qq.com/s/X48Cm58eub_sULlLRk-VIA</li>
</ol>
]]></content>
      <categories>
        <category>Research Method</category>
      </categories>
      <tags>
        <tag>Writing</tag>
      </tags>
  </entry>
  <entry>
    <title>Research Pipeline</title>
    <url>/2021/07/13/Research%20Method/Research-Pipeline/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>Things become easy if you arrange it into industrial production procedure. Publishing a paper can also be treated like a pipeline work procedure.</p>
<span id="more"></span>
<h1 id="paper-searching">Paper Searching</h1>
<ol type="1">
<li><a href="https://www.connectedpapers.com">Connected Papers</a> to find papers that connect with the query paper. The results will be shown in a graph, awesomoe!</li>
<li><a href="https://www.semanticscholar.org">Semantic Scholar</a> search paper by different filters (fileds of study, date, has pdf, publication type, famous authors, journal &amp; conference), could be a super search tool</li>
<li><a href="">CiteSpace</a>, <a href="">HistCite Pro</a> (both are software) are used for analyze the citation network</li>
<li><a href="https://paperswithcode.com">Paper with Code</a> is a community where every work will be attached by their code link</li>
<li><a href="https://libgen.is">Library Genesis</a> facilitate you to download every pdf book</li>
<li><a href="http://www.4243.net">大木虫学术导航</a> is a comprehensive nevigation for scholars, 有空多逛逛</li>
<li><a href="https://www.chongbuluo.com/">虫部落</a> very good collection of search tools and methods</li>
</ol>
<h1 id="code-search">Code Search</h1>
<ol type="1">
<li><a href="https://about.sourcegraph.com">Source Graph</a></li>
</ol>
<h1 id="paper-writing">Paper Writing</h1>
<ol type="1">
<li>Environment:
<ul>
<li><a href="https://www.youtube.com/watch?v=5qap5aO4i9A">Focus Music</a></li>
<li>Quite Place</li>
</ul></li>
<li>Writing Tool
<ul>
<li><a href="https://www.overleaf.com/">Overleaf with latex</a></li>
</ul></li>
<li>English Writing
<ul>
<li><a href="https://www.thesaurus.com">Thesaurus.com</a> enrich your lexical resource</li>
<li><a href="http://www.uefap.com/vocab/select/awl.htm">Academic Word List</a> most frequent words used in academic paper</li>
<li><a href="http://www.phrasebank.manchester.ac.uk">Academic Phrasebank</a> help you to polish your sentences so that equip your paper with coherence and logic.</li>
<li><a href="https://linggle.com">Linggle.com</a> help you to chose right words for your expression.</li>
<li><a href="https://www.grammarly.com">Grammarly</a> check your spell errors and grammar errors.</li>
<li><a href="https://www.deepl.com/translator">DeepL</a> for translation</li>
</ul></li>
<li>Formating
<ul>
<li><a href="https://coolors.co/">Colors.co</a> for color choosing</li>
<li><a href="">Snip</a> for hand writing formula and table recognization. I would highly recommand for generating the latex code of complex table, which is quite convinient.</li>
</ul></li>
</ol>
<h1 id="journal-or-conference">Journal or Conference</h1>
<h2 id="choosing">Choosing</h2>
<ul>
<li>[SJR]（https://www.scimagojr.com/）help you to choose a suitable Journal in your area</li>
<li><a href="https://www.letpub.com/index.php">LetPub</a> is also a good platform ranking Journal</li>
<li><a href="http://cic.tju.edu.cn/faculty/zhileiliu/doc/COREComputerScienceConferenceRankings.html">CORE Computer Science Conference Rankings</a> help you to estimate the rank of conferences</li>
<li><a href="http://www.conferenceranks.com">Conference Ranks</a> for conferences ## Deadlines</li>
<li><a href="https://aideadlin.es/?sub=ML,NLP">AI Conference Deadlines</a> informs and track the deadlines of all AI conferences</li>
<li></li>
</ul>
<h1 id="free-book-download">Free book download</h1>
<ol type="1">
<li>http://www.getfreeebooks.com/category/all/</li>
<li>http://manybooks.net/statistics_weekly.php</li>
<li>https://devfreebooks.github.io/</li>
<li>http://www.digitalbook.io/search.html#!//metro</li>
<li>http://www.bartleby.com/</li>
<li>http://freecomputerbooks.com/index.html</li>
<li>http://www.freetechbooks.com/topics</li>
<li>http://onlinebooks.library.upenn.edu/new.html</li>
<li>http://www.freebookspot.es/</li>
<li>http://www.freebookcentre.net/</li>
<li>http://cnx.org/</li>
</ol>
<h1 id="references">References</h1>
]]></content>
      <tags>
        <tag>Research</tag>
      </tags>
  </entry>
  <entry>
    <title>Tips for first year PhD</title>
    <url>/2021/07/12/Research%20Method/Tips-for-first-year-PhD/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>科研本是一件你喜欢的事，如果搞得自己郁闷就没必要了，就是干他娘的，能解决就解决，不能就躺会儿再解决。别搞得什么努力科研，拼命科研，那都是老板骗你努力工作的幌子，我们就是要开心的科研，万不得已也允许自己开心的划水，这样搞科研他不香吗，皮皮虾？</p>
<span id="more"></span>
<h1 id="关于看论文">关于看论文</h1>
<ol type="1">
<li><p>多读论文，一定要读顶会期刊，以后是要发顶级文章的人，自然要用顶级文章作为标杆，不要浪费生命在不好的文章上面。</p></li>
<li><p>怎么读？</p>
<ul>
<li>看别人在干啥：了解下国内外各个方向的牛人；找顶流文章看，否则做了两三年自己还是在二三流的水平。</li>
<li>看别人怎么做的：要了解作者怎么做的，还要理解，对于感兴趣的文章要尽量去推下公式、跑实验，达到彻底理解（知行合一）。</li>
<li>看别人为什么这么做：<strong>Motivation</strong>，了解别人做这篇文章的初衷是什么，他发现了什么新问题是其他人没有解决的。<strong>怎么做是术，为什么这么做才是道</strong>。在这个阶段能达到不管别人写的多么高深，都能一眼看穿它们的本质。</li>
<li>看别人哪里没干成哪里没干好：此时你对这个领域有了系统性认识（可以画成脑图），看看还有什么方向没做，有没有可能扩展，此时就是出<strong>idea</strong>的时候到了。</li>
</ul></li>
</ol>
<h1 id="关于动手">关于动手</h1>
<ol type="1">
<li>读+练。不要只看不练。有代码一定要跑一跑，没代码的决定有意思的，自己尝试去复现。</li>
<li>写文章：写文章在平时要注意培养，每天通过写文章的 summarization，review 来提高自己的写作水平，有空还可以去学习下学术写作课程。</li>
</ol>
<h1 id="关于人脉">关于人脉</h1>
<ol type="1">
<li>大部分讲座，<strong>都不会讲到什么实质的问题</strong>。把自己的目光放在两件事上：（1）听听大牛怎么做讲座的，学习人家演讲的方法；（2）跟大牛走近点，要个联系方式，用段时间给大牛留下好印象。</li>
<li>跟自己的老板好好相处，做到有理有据，不卑不亢。对自己不愿意的事情说 No，人生短暂，不必要浪费自己的时间去做老好人。</li>
</ol>
<h1 id="关于心态">关于心态</h1>
<ol type="1">
<li>写文章要奔着顶会顶刊去。如果投中了为自己增加科研信息；如果没中，可以通过reviewer的意见进行改进，白拿了一些意见岂不挣了，然后再考虑修改重投或者降低一级投。一开始就去投一般水平的会议期刊你可能都没了退路。</li>
<li>科研前一段时间没有成果比较正常，看到别人发了文章，中了顶会，多少会有焦虑，但是<strong>一定要沉住气</strong>，文章早晚会有的，不要因此天天垂头丧气，郁郁寡欢，熬夜加班伤身体。90% 的博士发的文章，扔进shcolar的大海连水花都溅不起来。你会有文章的！</li>
<li>不要期待能得到别人帮助，养成独立习惯。单打独斗也很好，跳出自己的实验室圈子，把自己放到更辽阔的天地里，你会发现不一样的精彩！你的合作人不仅仅只是实验室的人，得到的信息也更加丰富。</li>
<li>找一个人品好、学术成果高的人合作很重要。</li>
</ol>
<h1 id="关于生活">关于生活</h1>
<ol type="1">
<li>一定要每周定期运动，身体是本钱，再高的成就没了命要来干啥。以后要操劳的地方还多着呢，照顾长辈，操心孩子。平时可以坚持跑步，做crossfit，做瑜伽等。</li>
<li>坚持做冥想。冥想能提高自己的专注力，清理大脑的杂念，获得平静心态。关于冥想这件事，请参考《哈佛幸福课》，乔布斯，科比，禅宗等等。</li>
</ol>
<h1 id="references">References</h1>
<ol type="1">
<li><a href="https://www.zhihu.com/question/32210068/answer/264273093">王晋东不在家，中国科学院博士</a></li>
</ol>
]]></content>
      <tags>
        <tag>Research</tag>
      </tags>
  </entry>
  <entry>
    <title>GNN Survey</title>
    <url>/2021/06/23/Paper%20Reading/GNN/GNN-Survey/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><span id="more"></span>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210620095515.png" /></p>
<h1 id="参考-references">参考 (References)</h1>
<ol type="1">
<li><a href="">Graph Neural Networks for Natural Language Processing: A Survey, 2021</a></li>
</ol>
]]></content>
      <categories>
        <category>Paper Reading</category>
        <category>GNN</category>
      </categories>
      <tags>
        <tag>GNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Ontology Learning Review Papers</title>
    <url>/2021/07/13/Paper%20Reading/Ontology/Ontology-Learning-Review-Papers/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><span id="more"></span>
<h1 id="references">References</h1>
]]></content>
  </entry>
  <entry>
    <title>Ontology construction for information classification</title>
    <url>/2021/07/13/Paper%20Reading/Ontology/Ontology-construction-for-information-classification/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="whats-the-problem">What's the Problem?</h1>
<span id="more"></span>
<h1 id="why-they-do-this-work">Why they do this Work?</h1>
<h1 id="how-they-deal-with-the-problem-solve-the-challenges">How they deal with the problem &amp; solve the challenges?</h1>
<h1 id="why-this-method-works-better-any-evidence">Why this method works better &amp; Any evidence?</h1>
<h1 id="any-shortcoming">Any shortcoming?</h1>
<h1 id="further-readings">Further Readings</h1>
<h1 id="references">References</h1>
]]></content>
  </entry>
  <entry>
    <title>[object Object]</title>
    <url>/2021/07/12/Paper%20Reading/Ontology/Simple-Method-for-Ontology-Automatic-Extraction-from-Documents-2012/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="whats-the-problem">What's the Problem?</h1>
<span id="more"></span>
<h1 id="why-they-do-this-work">Why they do this Work?</h1>
<ol type="1">
<li><p>Most literature works are designed for a particular domain or document type. This work can be fitted in different areas and document types.</p></li>
<li><p>Most solutions generate the ontology that can only be manipulated by their tools. This work can generate standardized ontology with OWL languages which can be supported by many tools.</p></li>
</ol>
<p>(3)Solutions from literature require intervention of specialists or algorithms that take much time. This work can offer a simple and relatively quick method to do so.</p>
<h1 id="how-they-deal-with-the-problem-solve-the-challenges">How they deal with the problem &amp; solve the challenges?</h1>
<p>Suppose there exist <span class="math inline">\(d\)</span> documents and <span class="math inline">\(w\)</span> unique words. This work do latent semantic analysis on documents by using a Singular Value Decomposition (SVD). This method decomposes the term-document matrix <span class="math inline">\(A\)</span> (<span class="math inline">\(w\times d\)</span>) into <span class="math inline">\(U\)</span>, <span class="math inline">\(\Sigma\)</span> (<span class="math inline">\(w\times w\)</span>), and <span class="math inline">\(V^T\)</span> (<span class="math inline">\(n\times d\)</span>) matrix, where <span class="math inline">\(V\)</span> provides the relation between concepts and documents, and <span class="math inline">\(U\)</span> offers the relation between terms and concepts. <span class="math inline">\(\Sigma\)</span> is a diagonal matrix where the element in the diagonal specifys the importance of the eigenvectors in <span class="math inline">\(U\)</span>. Suppose that <span class="math inline">\(B=A^TA\)</span>, <span class="math inline">\(C=AA^T\)</span>, <span class="math inline">\(U\)</span> is the matrix of eigenvectors of <span class="math inline">\(B\)</span>(<span class="math inline">\(w\times w\)</span>), <span class="math inline">\(V\)</span> is the matrix of eigenvectors of <span class="math inline">\(C\)</span>(<span class="math inline">\(d\times d\)</span>). <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210712100829.png" /></p>
<p><span class="math inline">\(U\)</span> – the left Eigen vector (orthogonal) matrix, the vectors extract “Strength of Two Different Words Occurring in one Document” (may or may-not be co-occurrence).</p>
<p><span class="math inline">\(V\)</span> – the right Eigen vector (orthogonal) matrix, the vectors extract “Document-to-Document similarity”.</p>
<p><span class="math inline">\(\Sigma\)</span> – the Eigen Values (diagonal) matrix, explains variance ratio</p>
<h1 id="why-this-method-works-better-any-evidence">Why this method works better &amp; Any evidence?</h1>
<h1 id="any-shortcoming">Any shortcoming?</h1>
<h1 id="backgrounds">Backgrounds</h1>
<figure class="highlight mipsasm"><table><tr><td class="code"><pre><span class="line">G. R. <span class="keyword">Maddi, </span>C. S. Velvadapu, S. Strivastava e <span class="keyword">J. </span>G. d. Lamadrid, “Ontology <span class="keyword">Extraction </span>from Text Documents <span class="keyword">by </span>Singular Value Decomposition,” em ADMI <span class="number">2001</span>, <span class="number">2001</span></span><br></pre></td></tr></table></figure>
<p>presents a work using SVD to obtain concepts and terms and represent the obtained ontology by a bipartite graph.</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">B</span>. Fortuna, D. Mladenic e M. Grobelniz, “Semi-automatic Construction of Topic Ontology,” em Lecture Notes in Computer Science, vol. <span class="number">4289</span>, Springer, <span class="number">2005</span>, pp. <span class="number">121</span>-<span class="number">131</span></span><br></pre></td></tr></table></figure>
<p>extract concepts as term sets.</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">J</span>. Yeh e N. Yang, “Ontology Construction <span class="literal">on</span> Latent Topic Extraction in a Digital Library,” em International Conference <span class="literal">on</span> Asian Digital Libraries <span class="number">2008</span>, <span class="number">2008</span></span><br></pre></td></tr></table></figure>
<p>construct ontology from a historial digital library, where the concepts is generated by using latent semantics, and hierarchies among concepts are obtained by using clustering method.</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">Y</span>. Ding e S. Foo, “Ontology Research and Development Part <span class="number">1</span> – A Review of Ontology Generation,” Journal of Information Science, vol. <span class="number">28</span>, pp. <span class="number">123</span>-<span class="number">136</span>, <span class="number">2002</span>.</span><br><span class="line"><span class="attribute">I</span>. Bedini e B. Nguyen, “Automatic ontology generation: State of the art,” <span class="number">2007</span>.</span><br><span class="line"><span class="attribute">A</span>. Zauaq, “A survey of Domain Engineering: Method and Tools,” em Studies in Computational Intelligence, vol. <span class="number">308</span>, <span class="number">2010</span>, pp. <span class="number">103</span>-<span class="number">119</span>.</span><br></pre></td></tr></table></figure>
<p>present a study of concepts generation focused on clustering and latent semantic.</p>
<figure class="highlight css"><table><tr><td class="code"><pre><span class="line">L. Gillam e K. Ahmad, “Automatic Ontology Extraction <span class="selector-tag">from</span> Unstructured Texts,” <span class="selector-tag">em</span> the Move <span class="selector-tag">to</span> Meaningful Internet Systems <span class="number">2005</span>: CoopIS, DOA, and ODBASE, <span class="number">2005</span>.</span><br></pre></td></tr></table></figure>
<p>propose the obtainment of concepts using statistical methods</p>
<h1 id="further-readings">Further Readings</h1>
<h1 id="references">References</h1>
<ol type="1">
<li><a href="https://www.researchgate.net/publication/270554045_Simple_Method_for_Ontology_Automatic_Extraction_from_Documents">Simple Method for Ontology Automatic Extraction from Documents</a></li>
<li><a href="https://www.engr.uvic.ca/~seng474/svd.pdf">Latent Semantic Analysis Tutorial</a></li>
<li><a href="https://www.datajango.com/topic-modeling-and-singular-value-decomposition-svd/">Topic Modeling – Latent Semantic Analysis (LSA) and Singular Value Decomposition (SVD)</a></li>
</ol>
]]></content>
      <tags>
        <tag>Ontology</tag>
      </tags>
  </entry>
  <entry>
    <title>Measuring Fine-Grained Domain Relevance of Terms ACL2021</title>
    <url>/2021/07/09/Paper%20Reading/Term%20Weight/Measuring-Fine-Grained-Domain-Relevance-of-Terms-ACL2021/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="whats-the-problem">What's the Problem?</h1>
<p>This paper is targeted to measure the domain relevance of terms. <span id="more"></span></p>
<h1 id="why-they-do-this-work">Why they do this Work?</h1>
<p>The author mentioned <font color=red>3 challenges</font>:</p>
<ol type="1">
<li>How to measure the domain relevance of a long-tail terms (not frequently used, and lake of descirptive information).</li>
<li>How to measure domain relevance of a term without using domain-specific corpus.</li>
<li>How to reduce human efforts.</li>
</ol>
<h1 id="how-they-deal-with-the-problem-solve-the-challenges">How they deal with the problem &amp; solve the challenges?</h1>
<p>The overview of the framework is described in following picture. They assume that if a term is highly relevant to a target domain, this term should also be highly relevant to some other terms with high domain relevance. <img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210709111925.png" /></p>
<h2 id="core-anchored-semantic-graph-for-challenge-1">1. Core-Anchored Semantic Graph (for challenge <strong>1</strong>)</h2>
<ol type="1">
<li><p>First, the seed terms are provided by a term/phrase extraction method.</p></li>
<li><p>the seed terms can be divided into <em>core terms</em> (which is descibed by a Wikipedia article page) and <em>fringe terms</em> (which can not retrieve any description page from Wikipedia)</p></li>
<li><p>For each query term (a seed term), search it form <a href="https://en.wikipedia.org/w/index.php?search">Wikipedia search engine</a> by extract match. Link those <em>core terms</em> to the query term by checking the top 2k (k=5) returned Wiki pages (build up links with top k <em>core terms</em>). If the number of returned pages is no more k, than use relevance search to get return pages and build up links.</p></li>
<li><p>By searching each seed term from Wikipage search engine and building up links between them, we construct a term graph.</p></li>
</ol>
<p>The idea is using the term relevance between <em>core terms</em> and query term, thereofre, helping identifying the domain relevance of a query term.</p>
<h2 id="hierarchical-core-fringe-learning-for-challenge-2">2. Hierarchical Core-Fringe Learning (for challenge <strong>2</strong>)</h2>
<ol type="1">
<li>For meansuring the doamin relevance with a broad domain, they proposed a Core-Fringe Domain Relevance Learniing (CFL) framework.</li>
</ol>
<p>The graph convolution operation (GCNConv) at <span class="math inline">\(l\)</span>th layer is formulated as:</p>
<p><span class="math inline">\(h_i^{(l+1)}=\phi(\sum_{j\in \mathcal{N}_I\cup \{i\}}\frac{1}{c_{ij}}W_c^{(l)}b_c^{(l)}+b_c^{(l)})\)</span></p>
<p>The loss function is defined as:</p>
<p><span class="math inline">\(\mathcal{L}=-\sum_{i\in \mathcal{V}_{core}}(y_ilog(z_i)+(1-y_i)log(1-z_i))\)</span></p>
<p>where <span class="math inline">\(\mathcal{V}_{core}\)</span> is the nodes of <em>core terms</em>, <span class="math inline">\(y_i\)</span> is the label of node <span class="math inline">\(i\)</span> regarding the target domain (can be obtained in next step 3). The domain relevance is obtained from <span class="math inline">\(z\)</span>.</p>
<ol start="2" type="1">
<li>For a narrow domain, they proposed a Hierarchical CFL (HiCFL) framework.</li>
</ol>
<ul>
<li><p>Get the last GCNConv layer <span class="math inline">\(h_i^{(l_c)}\)</span>, where $l_c $ is the total layer of GCN.</p></li>
<li><p>Obtain the hierarchical global hidden state <span class="math inline">\(a_p\)</span> by</p>
<p><span class="math inline">\(a_p^{(l+1)}=\phi(W_p^{(l)}[a_p^{(i)};h^{(l_c)}]+b_p^{(l)})\)</span>, and <span class="math inline">\(a_p^{(0)}=\phi(W_p^{(0)}h^{l_c}+b_{p}^{(0)})\)</span>, where <span class="math inline">\(l_p\)</span> is the total number of hierarchical level.</p>
<p>The global information is produced by <span class="math inline">\(z_p = \sigma(W_p^{(l_p)}a_p^{(l_p)}+b_p^{(l)})\)</span></p></li>
<li><p>Obtain local hidden state <span class="math inline">\(a_q^{(l)}\)</span> for each level of hierarchy</p>
<p><span class="math inline">\(a_q^{(l)}=\phi(W_t^{(l)}a_p^{(l)}+b_t^{(l)})\)</span>, note this formula has related to global hidden state.</p>
<p>The local information of <span class="math inline">\(l\)</span>th level of hierarchy is <span class="math inline">\(z_q^{(l)}=\sigma(W_q^{(l)}a_q^{(l)}+b_q^{(l)})\)</span></p></li>
<li><p>The loss function is defined as <span class="math inline">\(\mathcal{L}_h=\epsilon(z_p,y^{(l_p)})+\sum_{l=1}^{l_p}\epsilon(z_q^{(l)}, y^{(l)})\)</span>, where the <span class="math inline">\(\epsilon(z,y) = -\sum_{i\in \mathcal{V_{core}}}(y_ilog(z_i)+(1-y_i)log(1-z_i))\)</span></p></li>
<li><p>The final domain relevance can be calculated by <span class="math inline">\(s = \alpha \cdot z_p+(1-\alpha\cdot(z_q^{(1)}\circ z_q^{(2)},..,z_q^{(l_p)})\)</span></p></li>
</ul>
<h2 id="automatic-annotation-and-hierarchical-positive-unlabeled-leraning-for-challenge-3">3. Automatic Annotation and Hierarchical Positive-Unlabeled Leraning (for challenge <strong>3</strong>)</h2>
<ol type="1">
<li><p>If the target domain is general enough to get its sub fields (sub-categories) form wikipedia or other existing domain taxonomies. Then get those sub-categories as the <em>gold subcategories</em> <span class="math inline">\(GSC\)</span> of this domain. Then label those <em>core terms</em> whose Wiki page has a category in <span class="math inline">\(GSC\)</span> with positive label. Otherwise, label it as non-domain terms.</p></li>
<li><p>If the target domain is a low-level category in a domain taxonomy. Then let user offer some terms of this domain and label them as positive. And label other terms which not belong to the parent of this domain to negatives. For example, For a hierarchy CS <span class="math inline">\(\rightarrow\)</span> AI <span class="math inline">\(\rightarrow\)</span> ML <span class="math inline">\(\rightarrow\)</span> DL. The user can offer some terms to be positives. Then other terms in CS but non-ML terms to be automatically labeled as negatives.</p></li>
</ol>
<h1 id="why-this-method-works-better-any-evidence">Why this method works better &amp; Any evidence?</h1>
<h1 id="any-shortcoming">Any shortcoming?</h1>
<ol type="1">
<li>The representation for each node may not elaborate enough, we may provide some embeddings learning form the Wiki page so that representing nodes with more semantic information.</li>
</ol>
<h1 id="further-readings">Further Readings</h1>
<p>About term extraction</p>
<ol type="1">
<li>Bag of what? simple noun phrase extraction for text analysis</li>
<li>Automated phrase mining from massive text corpora</li>
</ol>
<h1 id="references">References</h1>
<ol type="1">
<li>https://arxiv.org/pdf/2105.13255.pdf</li>
<li>https://github.com/jeffhj/domain-relevance</li>
</ol>
]]></content>
      <categories>
        <category>Paper Reading</category>
        <category>Term Weight</category>
      </categories>
      <tags>
        <tag>paper</tag>
      </tags>
  </entry>
  <entry>
    <title>pybind使用</title>
    <url>/2021/05/16/Programming/python/pybind%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="pybind11-主要的思想">Pybind11 主要的思想</h1>
<p><img src="https://cdn.jsdelivr.net/gh/jason-huanghao/PicGoBed/imgs/20210516104650.png" alt="image-20210426165542076" /> <span id="more"></span></p>
<h1 id="pybind11-环境配置">Pybind11 环境配置</h1>
<ol type="1">
<li><p>下载pybind11 https://github.com/pybind/pybind11 解压到 C:-master，解压后就可以直接使用(head-only)</p></li>
<li><p>Windows 软件 Visual Studio 2017 (VS2017), Python3.6</p></li>
<li><p>Python中安装：pip install pybind11</p></li>
<li><p>VS2017 配置:</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="number">1</span>）设置编译输出类型 </span><br><span class="line">      配置属性--常规--常规--目标文件扩展名：.pyd</span><br><span class="line">      配置属性--常规--项目默认值-配置类型：动态库.dll</span><br><span class="line">  </span><br><span class="line"> <span class="number">2</span>）添加include包含： </span><br><span class="line">      配置属性--VC++目录--常规--包含目录：</span><br><span class="line">      C:\pybind11-master\include  <span class="comment">// 这个是pybind的include目录</span></span><br><span class="line">      C:\ProgramData\Anaconda3\envs\python36\indclude  <span class="comment">//这个是python环境的include目录，你也可以用anaconda自带的环境</span></span><br><span class="line"> </span><br><span class="line"> <span class="number">3</span>）链接器配置：</span><br><span class="line">      链接器-常规-附加库目录：C:\ProgramData\envs\python36\indclude\libs  <span class="comment">//这个是python环境的libs目录，你也可以用anaconda自带的环境</span></span><br><span class="line">      链接器-输入-附加依赖项：python3.lib</span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="pybind11-python-调用-c">Pybind11 Python 调用 C++</h1>
<ol type="1">
<li>C++ code</li>
</ol>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;pybind11/pybind11.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;example1.h&quot;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">namespace</span> py = pybind11;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">int</span> j)</span> </span>&#123;<span class="keyword">return</span> i + j;&#125;</span><br><span class="line"> </span><br><span class="line"><span class="built_in">PYBIND11_MODULE</span>(example, m) &#123;	<span class="comment">//&quot;example&quot; is python module name</span></span><br><span class="line">	m.<span class="built_in">doc</span>() = <span class="string">&quot;pybind11 example plugin&quot;</span>; <span class="comment">// optional module docstring</span></span><br><span class="line">	m.<span class="built_in">def</span>(<span class="string">&quot;add&quot;</span>, &amp;add, <span class="string">&quot;A function which adds two numbers&quot;</span>); <span class="comment">// &quot;add&quot; is method name</span></span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>VS2017 compiling...</li>
</ol>
<p>produced a XXX.pyd file in directory “dir” (XXX is the C++ project name)</p>
<p>change XXX to the module name so that can be used in Python</p>
<ol start="3" type="1">
<li>Python use module provided by C++</li>
</ol>
<p>3.1 using with sys.path</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.append(<span class="string">&quot;dir&quot;</span>)	<span class="comment"># dir includes the XXX.pyd file</span></span><br><span class="line"><span class="keyword">import</span> example 					<span class="comment"># defined module name</span></span><br><span class="line">example.add()						<span class="comment"># use the method from the module</span></span><br></pre></td></tr></table></figure>
<p>3.2 use with setuptools</p>
<p>write a setup.py file in the dir of the .cpp file</p>
<figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">from</span> <span class="string">setuptools import setup, Extension</span></span><br><span class="line"></span><br><span class="line"><span class="attr">functions_module</span> = <span class="string">Extension(</span></span><br><span class="line">    <span class="attr">name</span> =<span class="string">&#x27;example&#x27;,</span></span><br><span class="line">    <span class="attr">sources</span> = <span class="string">[&#x27;first_pybind.cpp&#x27;],</span></span><br><span class="line">    <span class="attr">include_dirs</span> = <span class="string">[&#x27;F:\\Anaconda\\Anaconda3_201910\\envs\\env_pybind11\\lib\\site-packages\\pybind11\\include&#x27;,</span></span><br><span class="line">                   <span class="meta">&#x27;F</span>:<span class="string">\\Anaconda\\Anaconda3_201910\\envs\\env_pybind11\\include&#x27;]</span></span><br><span class="line"><span class="comment"># include_dirs 中的路径 更改为自己虚拟环境下相应 pybind11的路径 和 python的include路径</span></span><br><span class="line"><span class="attr">)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">setup(ext_modules</span> = <span class="string">[functions_module])</span></span><br></pre></td></tr></table></figure>
<figure class="highlight cmake"><table><tr><td class="code"><pre><span class="line">cd dir of (.cpp <span class="keyword">file</span> <span class="keyword">and</span> setup.py <span class="keyword">file</span>)</span><br><span class="line">python setup.py build_ext --inplace</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> example</span><br><span class="line"><span class="built_in">print</span>(example.add(<span class="number">1</span>, <span class="number">2</span>))</span><br></pre></td></tr></table></figure>
<h1 id="参考-references">参考 (References)</h1>
]]></content>
      <categories>
        <category>Programming</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>pybind</tag>
        <tag>python</tag>
      </tags>
  </entry>
</search>
